{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7302f239-5aba-4164-8125-86df134c9bd5",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%reload_ext autoreload\n",
    "\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import os\n",
    "from glob import glob\n",
    "import functions as f\n",
    "#import climpredNEW.climpred \n",
    "#from climpredNEW.climpred.options import OPTIONS\n",
    "from mpl_toolkits.basemap import Basemap\n",
    "from numpy import meshgrid\n",
    "from mpl_toolkits.axes_grid1.axes_divider import make_axes_locatable\n",
    "import matplotlib.colors as mcolors\n",
    "import cartopy.feature as cfeature\n",
    "import itertools\n",
    "import cartopy.crs as ccrs\n",
    "from cartopy.mpl.ticker import LongitudeFormatter, LatitudeFormatter, LatitudeLocator\n",
    "import matplotlib.ticker as mticker\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap, TwoSlopeNorm\n",
    "import pandas as pd\n",
    "import math\n",
    "from datetime import datetime\n",
    "import datetime as dt\n",
    "from multiprocessing import Pool\n",
    "from sklearn.metrics import confusion_matrix as CM\n",
    "import preprocessUtils as putils\n",
    "import masks\n",
    "import verifications\n",
    "from scipy import signal\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "import copy\n",
    "import matplotlib.patches as mpatches\n",
    "import caseUtils as cutils\n",
    "import masks\n",
    "from matplotlib.patches import Rectangle\n",
    "\n",
    "global admin_boundaries\n",
    "admin_boundaries = cfeature.NaturalEarthFeature(category='cultural',\n",
    "                                                name='admin_1_states_provinces_lines',\n",
    "                                                scale='50m',\n",
    "                                                facecolor='none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2c17b0f2-e62f-454d-b66a-72e1fc589207",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# def plot_colortable(colors, *, ncols=4, sort_colors=True):\n",
    "\n",
    "#     cell_width = 212\n",
    "#     cell_height = 22\n",
    "#     swatch_width = 48\n",
    "#     margin = 12\n",
    "\n",
    "#     # Sort colors by hue, saturation, value and name.\n",
    "#     if sort_colors is True:\n",
    "#         names = sorted(\n",
    "#             colors, key=lambda c: tuple(mcolors.rgb_to_hsv(mcolors.to_rgb(c))))\n",
    "#     else:\n",
    "#         names = list(colors)\n",
    "\n",
    "#     n = len(names)\n",
    "#     nrows = math.ceil(n / ncols)\n",
    "\n",
    "#     width = cell_width * ncols + 2 * margin\n",
    "#     height = cell_height * nrows + 2 * margin\n",
    "#     dpi = 72\n",
    "\n",
    "#     fig, ax = plt.subplots(figsize=(width / dpi, height / dpi), dpi=dpi)\n",
    "#     fig.subplots_adjust(margin/width, margin/height,\n",
    "#                         (width-margin)/width, (height-margin)/height)\n",
    "#     ax.set_xlim(0, cell_width * ncols)\n",
    "#     ax.set_ylim(cell_height * (nrows-0.5), -cell_height/2.)\n",
    "#     ax.yaxis.set_visible(False)\n",
    "#     ax.xaxis.set_visible(False)\n",
    "#     ax.set_axis_off()\n",
    "\n",
    "#     for i, name in enumerate(names):\n",
    "#         row = i % nrows\n",
    "#         col = i // nrows\n",
    "#         y = row * cell_height\n",
    "\n",
    "#         swatch_start_x = cell_width * col\n",
    "#         text_pos_x = cell_width * col + swatch_width + 7\n",
    "\n",
    "#         ax.text(text_pos_x, y, name, fontsize=14,\n",
    "#                 horizontalalignment='left',\n",
    "#                 verticalalignment='center')\n",
    "\n",
    "#         ax.add_patch(\n",
    "#             Rectangle(xy=(swatch_start_x, y-9), width=swatch_width,\n",
    "#                       height=18, facecolor=colors[name], edgecolor='0.7')\n",
    "#         )\n",
    "\n",
    "#     return fig\n",
    "\n",
    "# xkcd_fig = plot_colortable(mcolors.XKCD_COLORS)\n",
    "# xkcd_fig.savefig(\"XKCD_Colors.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "14a6aade-bd70-49dd-a3a5-3540bc584e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "#For a single week and experiment\n",
    "\n",
    "week_lead = 3 #[1,2,3,4,5]\n",
    "day_num = (week_lead*7) -1\n",
    "\n",
    "#Reforecast source\n",
    "source = 'GEFSv12' #['GEFSv12','ECMWF']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "612950b1-1fcf-4522-b79c-7d85f090e726",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/glade/work/klesinger/FD_RZSM_deep_learning/Data_china/GLEAM/china_mask.nc4'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m/glade/work/klesinger/conda-envs/tf212gpu/lib/python3.10/site-packages/xarray/backends/file_manager.py:211\u001b[0m, in \u001b[0;36mCachingFileManager._acquire_with_cache_info\u001b[0;34m(self, needs_lock)\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 211\u001b[0m     file \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cache\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_key\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    212\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n",
      "File \u001b[0;32m/glade/work/klesinger/conda-envs/tf212gpu/lib/python3.10/site-packages/xarray/backends/lru_cache.py:56\u001b[0m, in \u001b[0;36mLRUCache.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m---> 56\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cache\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     57\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cache\u001b[38;5;241m.\u001b[39mmove_to_end(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: [<class 'netCDF4._netCDF4.Dataset'>, ('/glade/work/klesinger/FD_RZSM_deep_learning/Data_china/GLEAM/china_mask.nc4',), 'r', (('clobber', True), ('diskless', False), ('format', 'NETCDF4'), ('persist', False)), 'f98c13c7-8e3d-4368-9fc1-96e4f919fe4c']",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m region_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mchina\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;66;03m#['CONUS','australia','china']\u001b[39;00m\n\u001b[1;32m      4\u001b[0m test_year \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2019\u001b[39m \u001b[38;5;66;03m# [2019,2012]\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m mask,mask_anom \u001b[38;5;241m=\u001b[39m \u001b[43mcutils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_mask\u001b[49m\u001b[43m(\u001b[49m\u001b[43mregion_name\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m#Load the mask xarry and mask numpy files. Values of 1 = land \u001b[39;00m\n\u001b[1;32m      7\u001b[0m init_date_list \u001b[38;5;241m=\u001b[39m putils\u001b[38;5;241m.\u001b[39mget_init_date_list(forecast_variable_path\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mData/GEFSv12_reforecast/soilw_bgrnd\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m#dates for flash drought event\u001b[39;00m\n",
      "File \u001b[0;32m/glade/work/klesinger/FD_RZSM_deep_learning/caseUtils.py:15\u001b[0m, in \u001b[0;36mload_mask\u001b[0;34m(region_name)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_mask\u001b[39m(region_name):\n\u001b[0;32m---> 15\u001b[0m     mask \u001b[38;5;241m=\u001b[39m \u001b[43mmasks\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_mask\u001b[49m\u001b[43m(\u001b[49m\u001b[43mregion_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;66;03m#Mask with np.nan for non-CONUS land values\u001b[39;00m\n\u001b[1;32m     17\u001b[0m     mask_anom \u001b[38;5;241m=\u001b[39m mask[putils\u001b[38;5;241m.\u001b[39mxarray_varname(mask)][\u001b[38;5;241m0\u001b[39m,:,:]\u001b[38;5;241m.\u001b[39mvalues\n",
      "File \u001b[0;32m/glade/work/klesinger/FD_RZSM_deep_learning/masks.py:33\u001b[0m, in \u001b[0;36mload_mask\u001b[0;34m(region_name)\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m(xr\u001b[38;5;241m.\u001b[39mopen_dataset(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mdir\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/Data_australia/GLEAM/australia_mask.nc4\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m region_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mchina\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m---> 33\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m(\u001b[43mxr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[38;5;28;43mdir\u001b[39;49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/Data_china/GLEAM/china_mask.nc4\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m/glade/work/klesinger/conda-envs/tf212gpu/lib/python3.10/site-packages/xarray/backends/api.py:570\u001b[0m, in \u001b[0;36mopen_dataset\u001b[0;34m(filename_or_obj, engine, chunks, cache, decode_cf, mask_and_scale, decode_times, decode_timedelta, use_cftime, concat_characters, decode_coords, drop_variables, inline_array, chunked_array_type, from_array_kwargs, backend_kwargs, **kwargs)\u001b[0m\n\u001b[1;32m    558\u001b[0m decoders \u001b[38;5;241m=\u001b[39m _resolve_decoders_kwargs(\n\u001b[1;32m    559\u001b[0m     decode_cf,\n\u001b[1;32m    560\u001b[0m     open_backend_dataset_parameters\u001b[38;5;241m=\u001b[39mbackend\u001b[38;5;241m.\u001b[39mopen_dataset_parameters,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    566\u001b[0m     decode_coords\u001b[38;5;241m=\u001b[39mdecode_coords,\n\u001b[1;32m    567\u001b[0m )\n\u001b[1;32m    569\u001b[0m overwrite_encoded_chunks \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moverwrite_encoded_chunks\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m--> 570\u001b[0m backend_ds \u001b[38;5;241m=\u001b[39m \u001b[43mbackend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen_dataset\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    571\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfilename_or_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    572\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdrop_variables\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdrop_variables\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    573\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mdecoders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    574\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    575\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    576\u001b[0m ds \u001b[38;5;241m=\u001b[39m _dataset_from_backend_dataset(\n\u001b[1;32m    577\u001b[0m     backend_ds,\n\u001b[1;32m    578\u001b[0m     filename_or_obj,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    588\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    589\u001b[0m )\n\u001b[1;32m    590\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ds\n",
      "File \u001b[0;32m/glade/work/klesinger/conda-envs/tf212gpu/lib/python3.10/site-packages/xarray/backends/netCDF4_.py:602\u001b[0m, in \u001b[0;36mNetCDF4BackendEntrypoint.open_dataset\u001b[0;34m(self, filename_or_obj, mask_and_scale, decode_times, concat_characters, decode_coords, drop_variables, use_cftime, decode_timedelta, group, mode, format, clobber, diskless, persist, lock, autoclose)\u001b[0m\n\u001b[1;32m    581\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mopen_dataset\u001b[39m(  \u001b[38;5;66;03m# type: ignore[override]  # allow LSP violation, not supporting **kwargs\u001b[39;00m\n\u001b[1;32m    582\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    583\u001b[0m     filename_or_obj: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m|\u001b[39m os\u001b[38;5;241m.\u001b[39mPathLike[Any] \u001b[38;5;241m|\u001b[39m BufferedIOBase \u001b[38;5;241m|\u001b[39m AbstractDataStore,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    599\u001b[0m     autoclose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    600\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Dataset:\n\u001b[1;32m    601\u001b[0m     filename_or_obj \u001b[38;5;241m=\u001b[39m _normalize_path(filename_or_obj)\n\u001b[0;32m--> 602\u001b[0m     store \u001b[38;5;241m=\u001b[39m \u001b[43mNetCDF4DataStore\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    603\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilename_or_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    604\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    605\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    606\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgroup\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    607\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclobber\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclobber\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    608\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdiskless\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdiskless\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    609\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpersist\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpersist\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    610\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlock\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlock\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    611\u001b[0m \u001b[43m        \u001b[49m\u001b[43mautoclose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mautoclose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    612\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    614\u001b[0m     store_entrypoint \u001b[38;5;241m=\u001b[39m StoreBackendEntrypoint()\n\u001b[1;32m    615\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m close_on_error(store):\n",
      "File \u001b[0;32m/glade/work/klesinger/conda-envs/tf212gpu/lib/python3.10/site-packages/xarray/backends/netCDF4_.py:400\u001b[0m, in \u001b[0;36mNetCDF4DataStore.open\u001b[0;34m(cls, filename, mode, format, group, clobber, diskless, persist, lock, lock_maker, autoclose)\u001b[0m\n\u001b[1;32m    394\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(\n\u001b[1;32m    395\u001b[0m     clobber\u001b[38;5;241m=\u001b[39mclobber, diskless\u001b[38;5;241m=\u001b[39mdiskless, persist\u001b[38;5;241m=\u001b[39mpersist, \u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mformat\u001b[39m\n\u001b[1;32m    396\u001b[0m )\n\u001b[1;32m    397\u001b[0m manager \u001b[38;5;241m=\u001b[39m CachingFileManager(\n\u001b[1;32m    398\u001b[0m     netCDF4\u001b[38;5;241m.\u001b[39mDataset, filename, mode\u001b[38;5;241m=\u001b[39mmode, kwargs\u001b[38;5;241m=\u001b[39mkwargs\n\u001b[1;32m    399\u001b[0m )\n\u001b[0;32m--> 400\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmanager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroup\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlock\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlock\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mautoclose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mautoclose\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/glade/work/klesinger/conda-envs/tf212gpu/lib/python3.10/site-packages/xarray/backends/netCDF4_.py:347\u001b[0m, in \u001b[0;36mNetCDF4DataStore.__init__\u001b[0;34m(self, manager, group, mode, lock, autoclose)\u001b[0m\n\u001b[1;32m    345\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_group \u001b[38;5;241m=\u001b[39m group\n\u001b[1;32m    346\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mode \u001b[38;5;241m=\u001b[39m mode\n\u001b[0;32m--> 347\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mformat \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mds\u001b[49m\u001b[38;5;241m.\u001b[39mdata_model\n\u001b[1;32m    348\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_filename \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mds\u001b[38;5;241m.\u001b[39mfilepath()\n\u001b[1;32m    349\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_remote \u001b[38;5;241m=\u001b[39m is_remote_uri(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_filename)\n",
      "File \u001b[0;32m/glade/work/klesinger/conda-envs/tf212gpu/lib/python3.10/site-packages/xarray/backends/netCDF4_.py:409\u001b[0m, in \u001b[0;36mNetCDF4DataStore.ds\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    407\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[1;32m    408\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mds\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 409\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_acquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/glade/work/klesinger/conda-envs/tf212gpu/lib/python3.10/site-packages/xarray/backends/netCDF4_.py:403\u001b[0m, in \u001b[0;36mNetCDF4DataStore._acquire\u001b[0;34m(self, needs_lock)\u001b[0m\n\u001b[1;32m    402\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_acquire\u001b[39m(\u001b[38;5;28mself\u001b[39m, needs_lock\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m--> 403\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_manager\u001b[38;5;241m.\u001b[39macquire_context(needs_lock) \u001b[38;5;28;01mas\u001b[39;00m root:\n\u001b[1;32m    404\u001b[0m         ds \u001b[38;5;241m=\u001b[39m _nc4_require_group(root, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_group, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mode)\n\u001b[1;32m    405\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ds\n",
      "File \u001b[0;32m/glade/work/klesinger/conda-envs/tf212gpu/lib/python3.10/contextlib.py:135\u001b[0m, in \u001b[0;36m_GeneratorContextManager.__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkwds, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc\n\u001b[1;32m    134\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 135\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgen\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[1;32m    137\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgenerator didn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt yield\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/glade/work/klesinger/conda-envs/tf212gpu/lib/python3.10/site-packages/xarray/backends/file_manager.py:199\u001b[0m, in \u001b[0;36mCachingFileManager.acquire_context\u001b[0;34m(self, needs_lock)\u001b[0m\n\u001b[1;32m    196\u001b[0m \u001b[38;5;129m@contextlib\u001b[39m\u001b[38;5;241m.\u001b[39mcontextmanager\n\u001b[1;32m    197\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21macquire_context\u001b[39m(\u001b[38;5;28mself\u001b[39m, needs_lock\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m    198\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Context manager for acquiring a file.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 199\u001b[0m     file, cached \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_acquire_with_cache_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43mneeds_lock\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    200\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    201\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m file\n",
      "File \u001b[0;32m/glade/work/klesinger/conda-envs/tf212gpu/lib/python3.10/site-packages/xarray/backends/file_manager.py:217\u001b[0m, in \u001b[0;36mCachingFileManager._acquire_with_cache_info\u001b[0;34m(self, needs_lock)\u001b[0m\n\u001b[1;32m    215\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m    216\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmode\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mode\n\u001b[0;32m--> 217\u001b[0m file \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_opener\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    218\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    219\u001b[0m     \u001b[38;5;66;03m# ensure file doesn't get overridden when opened again\u001b[39;00m\n\u001b[1;32m    220\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mode \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ma\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32msrc/netCDF4/_netCDF4.pyx:2464\u001b[0m, in \u001b[0;36mnetCDF4._netCDF4.Dataset.__init__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32msrc/netCDF4/_netCDF4.pyx:2027\u001b[0m, in \u001b[0;36mnetCDF4._netCDF4._ensure_nc_success\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/glade/work/klesinger/FD_RZSM_deep_learning/Data_china/GLEAM/china_mask.nc4'"
     ]
    }
   ],
   "source": [
    "#Set script parameters\n",
    "global region_name, test_year\n",
    "region_name = 'china' #['CONUS','australia','china']\n",
    "test_year = 2019 # [2019,2012]\n",
    "\n",
    "mask,mask_anom = cutils.load_mask(region_name) #Load the mask xarry and mask numpy files. Values of 1 = land \n",
    "init_date_list = putils.get_init_date_list(forecast_variable_path=f'Data/GEFSv12_reforecast/soilw_bgrnd')\n",
    "\n",
    "#dates for flash drought event\n",
    "if region_name == 'CONUS':\n",
    "    if test_year == 2019:\n",
    "        start_ = '2019-08-01'\n",
    "        end_ = '2019-09-25'\n",
    "\n",
    "    elif test_year == 2012:\n",
    "        start_ = '2012-05-01'\n",
    "        end_ = '2012-07-15'\n",
    " \n",
    "        \n",
    "    southeast_lat_bottom = 30\n",
    "    southeast_lat_top = 38\n",
    "    \n",
    "    southeast_lon_left  = 267\n",
    "    southeast_lon_right = 282\n",
    "\n",
    "elif region_name == 'australia':\n",
    "    if test_year == 2019:\n",
    "        start_ = '2019-04-06'\n",
    "        end_ = '2019-07-17'\n",
    "\n",
    "elif region_name == 'china':\n",
    "    if test_year == 2019:\n",
    "        start_ = '2019-07-14'\n",
    "        end_ = '2019-08-28'\n",
    "        # end_ = '2019-07-09'\n",
    "\n",
    "\n",
    "#Dates for template\n",
    "global test_start, test_end\n",
    "if test_year == 2019:\n",
    "    test_start = '2018-01-01'\n",
    "    test_end = '2019-12-31'\n",
    "elif test_year == 2012:\n",
    "    test_start = '2011-01-01'\n",
    "    test_end = '2012-12-31'\n",
    "       \n",
    "\n",
    "\n",
    "'''LOAD THE DATA'''\n",
    "global obs_anomaly_SubX_format, baseline_anomaly, baseline_ecmwf, var_OUT, template_testing_only\n",
    "obs_anomaly_SubX_format, baseline_anomaly, baseline_ecmwf, var_OUT, template_testing_only = cutils.open_obs_and_baseline_files(region_name, week_lead, day_num, start_, end_, mask_anom, test_start, test_end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "932c714d-caa5-4064-b9cb-7502228f6596",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def return_array_anomaly(file,date):\n",
    "    vals = file.sel(S=date).RZSM.values\n",
    "    vals[np.isnan(vals)] = 0 #mask ocean values for SSIM\n",
    "    return(vals)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca85e641-882e-410a-8f12-4385bead9c07",
   "metadata": {},
   "source": [
    "### Data (loads the observation anomaly, ECWMF, and GEFSv12 anomaly for only the specified dates when looking at the case study.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3921cf9b-037e-43bf-becd-294c2c76e443",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_min_max_of_files(obs, unet, baseline, ecm, date):\n",
    "    #test \n",
    "    # date = '2019-08-07'\n",
    "    \n",
    "    min_ = []\n",
    "    max_ = []\n",
    "\n",
    "    min_.append(obs.sel(S=date).min().rci.values)\n",
    "    min_.append(unet.sel(S=date).min().rci.values)\n",
    "    min_.append(baseline.sel(S=date).min().rci.values)\n",
    "    min_.append(ecm.sel(S=date).min().rci.values)\n",
    "    \n",
    "    max_.append(obs.sel(S=date).max().rci.values)\n",
    "    max_.append(unet.sel(S=date).max().rci.values)\n",
    "    max_.append(baseline.sel(S=date).max().rci.values)\n",
    "    max_.append(ecm.sel(S=date).max().rci.values)\n",
    "    \n",
    "    return(min(min_),max(max_))\n",
    "\n",
    "def return_array(file,lead,date):\n",
    "    return(file.sel(L=lead,S=date).rci.values)\n",
    "\n",
    "\n",
    "def get_min_max_of_files_anomaly(obs, unet, baseline, ecm, init_dates_all):\n",
    "    #test \n",
    "    # date = '2019-08-07'\n",
    "    \n",
    "    min_ = []\n",
    "    max_ = []\n",
    "    \n",
    "    for date in init_dates_all:\n",
    "\n",
    "    \n",
    "        min_.append(obs.sel(S=date).min().RZSM.values)\n",
    "        min_.append(unet.sel(S=date).min().RZSM.values)\n",
    "        min_.append(baseline.sel(S=date).min().RZSM.values)\n",
    "        min_.append(ecm.sel(S=date).min().RZSM.values)\n",
    "        \n",
    "        max_.append(obs.sel(S=date).max().RZSM.values)\n",
    "        max_.append(unet.sel(S=date).max().RZSM.values)\n",
    "        max_.append(baseline.sel(S=date).max().RZSM.values)\n",
    "        max_.append(ecm.sel(S=date).max().RZSM.values)\n",
    "    \n",
    "    return(min(min_),max(max_))\n",
    "\n",
    "def return_plot_info(region_name):\n",
    "    if region_name == 'china':\n",
    "        text_x = 93\n",
    "        text_y = 26\n",
    "        fig_width = 10\n",
    "        fig_height = 9\n",
    "        \n",
    "    font_size_corr = 9\n",
    "    return(text_x, text_y, fig_width, fig_height, font_size_corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bf8a5094-c878-4a54-90cc-d0b204682d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(exp,mean_or_median):\n",
    "    \n",
    "    #Look at a single plot\n",
    "    unet_anomaly = verifications.create_reforecast_with_predictions_single_lead(template_testing_only = template_testing_only, day_num=day_num, week_lead=week_lead, \n",
    "                                                                                experiment_name=exp, region_name=region_name, mask_anom = mask_anom,\n",
    "                                                                               start_ = start_, end_ = end_, source = source, test_year = test_year)\n",
    "    \n",
    "    # Mask data to LAND\n",
    "    if region_name == 'CONUS':\n",
    "        if mean_or_median == 'mean':\n",
    "            obs = xr.where(mask_anom ==1, obs_anomaly_SubX_format.sel(L=day_num).mean(dim='M').sel(S=slice(start_,end_)),np.nan)\n",
    "            unet = xr.where(mask_anom ==1, unet_anomaly.mean(dim='M'),np.nan)\n",
    "            baseline = xr.where(mask_anom ==1, baseline_anomaly.mean(dim='M').sel(L=day_num).sel(S=slice(start_,end_)),np.nan)\n",
    "            ecm = xr.where(mask_anom ==1, baseline_ecmwf.mean(dim='M').sel(L=day_num).sel(S=slice(start_,end_)),np.nan)\n",
    "        else:\n",
    "            obs = xr.where(mask_anom ==1, obs_anomaly_SubX_format.sel(L=day_num).median(dim='M').sel(S=slice(start_,end_)),np.nan)\n",
    "            unet = xr.where(mask_anom ==1, unet_anomaly.median(dim='M'),np.nan)\n",
    "            baseline = xr.where(mask_anom ==1, baseline_anomaly.median(dim='M').sel(L=day_num).sel(S=slice(start_,end_)),np.nan)\n",
    "            ecm = xr.where(mask_anom ==1, baseline_ecmwf.median(dim='M').sel(L=day_num).sel(S=slice(start_,end_)),np.nan)\n",
    "    else:\n",
    "        obs = xr.where(np.isnan(mask_anom), np.nan, obs_anomaly_SubX_format.sel(L=day_num).mean(dim='M').sel(S=slice(start_,end_)))\n",
    "        unet = xr.where(np.isnan(mask_anom), np.nan, unet_anomaly.mean(dim='M'))\n",
    "        baseline = xr.where(np.isnan(mask_anom), np.nan, baseline_anomaly.mean(dim='M').sel(L=day_num).sel(S=slice(start_,end_)))\n",
    "        ecm = xr.where(np.isnan(mask_anom), np.nan, baseline_ecmwf.mean(dim='M').sel(L=day_num).sel(S=slice(start_,end_)))\n",
    "        \n",
    "    dates_ = obs.S.values\n",
    "    unet = unet.assign_coords({'S':dates_})\n",
    "    baseline = baseline.assign_coords({'S':dates_})\n",
    "    ecm = ecm.assign_coords({'S':dates_})\n",
    "\n",
    "    return(obs,unet,baseline,ecm,dates_)\n",
    "\n",
    "def return_basic_info(obs,unet,baseline,ecm,region_name,week_lead):\n",
    "    lon = obs.X.values\n",
    "    lat = obs.Y.values\n",
    "    \n",
    "    plot_model_names = ['GLEAM','DL_NWP_OBS','GEFSv12','ECMWF']\n",
    "    plot_models = [obs, unet, baseline, ecm]\n",
    "\n",
    "    text_x, text_y, fig_width, fig_height, font_size_corr = return_plot_info(region_name)\n",
    "\n",
    "    cmap = plt.get_cmap('bwr_r')    \n",
    "    \n",
    "    save_dir = f'Outputs/Case_studies/test_other_models/{region_name}/Wk{week_lead}'\n",
    "    os.system(f'mkdir -p {save_dir}')\n",
    "    return(lon,lat,plot_model_names,plot_models,text_x, text_y, fig_width, fig_height, font_size_corr,cmap,save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cb573976-9fc6-44e0-a5b1-215afc94e480",
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_bbox(ref_to_plot_for_region,region_name,plot_models):\n",
    "    obss = plot_models[0]\n",
    "    if region_name == 'australia':\n",
    "        if pd.to_datetime(ref_to_plot_for_region.S.values[0]).year == 2019:\n",
    "            #I had to manually figure out these things for the greeen colored study bbox. \n",
    "            v1,v2,widt,heigt = 140, data_to_plot.Y.values[-2],14,10\n",
    "            ref_bbox = ref_to_plot_for_region.sel(Y=slice(v2+heigt,v2)).sel(X=slice(v1,v1+widt))\n",
    "            obs_bbox = obss.sel(Y=slice(v2+heigt,v2)).sel(X=slice(v1,v1+widt))\n",
    "    elif region_name == 'china':\n",
    "        if pd.to_datetime(ref_to_plot_for_region.S.values[0]).year == 2019:\n",
    "            v1,v2,widt,heigt = 100, 23, 21, 15\n",
    "            ref_bbox = ref_to_plot_for_region.sel(Y=slice(v2+heigt,v2)).sel(X=slice(v1,v1+widt))\n",
    "            obs_bbox = obss.sel(Y=slice(v2+heigt,v2)).sel(X=slice(v1,v1+widt))\n",
    "    elif region_name == 'CONUS':\n",
    "        if pd.to_datetime(ref_to_plot_for_region.S.values[0]).year == 2019:\n",
    "            v1,v2,widt,heigt = -92, 30.5, rightlon-leftlon, toplat-btmlat\n",
    "        elif pd.to_datetime(ref_to_plot_for_region.S.values[0]).year == 2012:\n",
    "            v1,v2,widt,heigt = leftlon-360, btmlat-1, 20, 12\n",
    "        ref_bbox = ref_to_plot_for_region.sel(Y=slice(v2+heigt,v2)).sel(X=slice(v1+360,v1+widt+360))\n",
    "        obs_bbox = obss.sel(Y=slice(v2+heigt,v2)).sel(X=slice(v1+360,v1+widt+360)) \n",
    "\n",
    "    return(ref_bbox, obs_bbox, v1,v2,widt,heigt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eecac49c-3167-494e-ba4a-4a436ca458f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_plot_by_experiment_name_with_boundary_box(obs,unet,baseline,ecm,dates_):\n",
    "\n",
    "    if pd.to_datetime(start_).year == 2019:\n",
    "        leftlon, rightlon, toplat, btmlat = unet.X.values[0], unet.X.values[-1], unet.Y.values[0], unet.Y.values[-1]\n",
    "        \n",
    "    lon,lat,plot_model_names,plot_models,text_x, text_y, fig_width, fig_height, font_size_corr,cmap,save_dir = return_basic_info(obs,unet,baseline,ecm,region_name,week_lead)\n",
    "        \n",
    "    fig, axs = plt.subplots(nrows = len(obs.S.values), ncols= len(plot_models), subplot_kw={'projection': ccrs.PlateCarree()}, figsize=(fig_width,fig_height),layout=\"constrained\")\n",
    "    axs = axs.flatten()\n",
    "    \n",
    "    min_,max_ = get_min_max_of_files_anomaly(obs, unet, baseline, ecm, obs.S.values)\n",
    "    min_,max_ = -0.08,0.08 #manually set this because ECMWF has some very high values\n",
    "    \n",
    "    v = np.linspace(min_, max_, 16, endpoint=True)\n",
    "    #Make sure we have a diverging color at 0\n",
    "    v  = [i for i in v if i <0] + [0] + [i for i in v if i >0]\n",
    "                                        \n",
    "    alphabet = [chr(i) for i in range(ord('A'), ord('Z')+1)]\n",
    "    start_letter = 0\n",
    "    # print(alphabet)\n",
    "    \n",
    "    axs_start = 0\n",
    "    for init_date in obs.S.values:\n",
    "        #for testing\n",
    "        # init_date = obs.S.values[0]\n",
    "        # lead = day_num\n",
    "        # data_to_plot = plot_models[2]\n",
    "        # name = plot_model_names[2]\n",
    "        \n",
    "        init_date = pd.to_datetime(init_date)\n",
    "        date = f'{init_date.year}-{init_date.month:02}-{init_date.day:02}'\n",
    "        # break\n",
    "        for lead in [day_num]:\n",
    "            for data_to_plot,name in zip(plot_models, plot_model_names):\n",
    "                # break\n",
    "                # if name == 'DL_NWP_OBS':\n",
    "                    # break\n",
    "                ref_to_plot_for_region = data_to_plot\n",
    "\n",
    "                data = return_array_anomaly(file=data_to_plot, date=init_date)\n",
    "\n",
    "                if region_name == 'CONUS':\n",
    "                    map = Basemap(projection='cyl', llcrnrlat=btmlat, urcrnrlat=toplat,\n",
    "                                  llcrnrlon=leftlon-360, urcrnrlon=rightlon-360, resolution='l')\n",
    "                elif region_name == 'australia':\n",
    "                    map = Basemap(projection='cyl', llcrnrlat=-37, urcrnrlat=-12,\n",
    "                                  llcrnrlon=110, urcrnrlon=160, resolution='l')\n",
    "                elif region_name == 'china':\n",
    "                    map = Basemap(projection='cyl', llcrnrlat=20.5, urcrnrlat=44,\n",
    "                                  llcrnrlon=74.5, urcrnrlon=122, resolution='l')\n",
    "                    \n",
    "                x, y = map(*np.meshgrid(lon, lat))\n",
    "                # Adjust the text coordinates based on the actual data coordinates\n",
    "                norm = TwoSlopeNorm(vmin=min_, vcenter=0, vmax=max_)\n",
    "                im = axs[axs_start].contourf(x, y, np.where(np.isnan(mask_anom),np.nan,data), levels=v, extend='both',\n",
    "                                      transform=ccrs.PlateCarree(), cmap=cmap,norm=norm)\n",
    "                \n",
    "                # Correct usage of Rectangle to add a box. Assume leftlon, rightlon, toplat, btmlat are defined as per your code.\n",
    "\n",
    "                ref_bbox, obs_bbox, v1,v2,widt,heigt = return_bbox(ref_to_plot_for_region,region_name, plot_models)\n",
    "                rect = mpatches.Rectangle((v1, v2), widt, heigt,\n",
    "                                      edgecolor='gold', facecolor='none', transform=ccrs.PlateCarree(),\n",
    "                                         linewidth = 3)\n",
    "\n",
    "                axs[axs_start].add_patch(rect)\n",
    "                axs[axs_start].add_feature(admin_boundaries, edgecolor='black') #Country/state/province divisions\n",
    "                \n",
    "                # gl = axs[axs_start].gridlines(crs=ccrs.PlateCarree(), draw_labels=True,\n",
    "                #                            linewidth=0.7, color='gray', alpha=0.5, linestyle='--')\n",
    "                # gl.top_labels = False\n",
    "                # gl.right_labels = False\n",
    "                # if lead != 1:\n",
    "                #     gl.left_labels = False\n",
    "                # gl.xformatter = LongitudeFormatter()\n",
    "                # gl.yformatter = LatitudeFormatter()\n",
    "                \n",
    "                axs[axs_start].coastlines()\n",
    "                # plt.colorbar(im)\n",
    "                # axs[idx].set_aspect('auto', adjustable=None)\n",
    "                axs[axs_start].set_aspect('equal')  # this makes the plots better\n",
    "\n",
    "                '''Add date the top of the first plot'''\n",
    "                if axs_start <=len(plot_models)-1:\n",
    "                    if name == 'DL_NWP_OBS':\n",
    "                        exp_split = exp.split('_')[0]\n",
    "                        '''just manually insert the name change here, dont worry about the names because\n",
    "                        no one will ever come back to see this :('''\n",
    "                        # if 'EX24' in exp:\n",
    "                        #     tit_ = f\"{exp_split[0:2]}P{exp_split[2:]}_OBS\"\n",
    "                        # else:\n",
    "                        #     tit_ = f\"{exp_split[0:2]}P{exp_split[2:]}_GEFSv12\"\n",
    "                        tit_ = 'DL-DM_G'\n",
    "                    else:\n",
    "                        tit_ = name\n",
    "                    \n",
    "                    axs[axs_start].set_title(f'{tit_} ',fontsize=12)\n",
    "\n",
    "                if axs_start %4 == 0:\n",
    "                    # print(f\"Condition met for axs_start={axs_start}, setting ylabel\")\n",
    "                    # axs[axs_start].set_ylabel(f'Init\\n{date}',fontsize=22, labelpad=10)\n",
    "                    axs[axs_start].text(-0.37, 0.5, f'       Init\\n{date}', va='center', ha='left', rotation='horizontal', fontsize=10, transform=axs[axs_start].transAxes)\n",
    "                    \n",
    "                # if axs_start <=len(plot_models)-1:\n",
    "                #     axs[axs_start].set_title(f'{name}\\nInit: {date} ',fontsize=10)\n",
    "                # else:\n",
    "                #     axs[axs_start].set_title(f'Init: {date} ',fontsize=9)\n",
    "                    \n",
    "    \n",
    "                if name in ['DL_NWP_OBS','GEFSv12', 'ECMWF']:\n",
    "                    # Calculate the Pearson correlation coefficient\n",
    "                    ref_subset = ref_bbox.RZSM.sel(S=init_date).values\n",
    "                    ref_subset = np.where(np.isnan(ref_subset),0,ref_subset)\n",
    "                    \n",
    "                    obs_subset = obs_bbox.RZSM.sel(S=init_date).values\n",
    "                    obs_subset = np.where(np.isnan(obs_subset),0,obs_subset)\n",
    "\n",
    "                    obs_flat = obs_subset.flatten()\n",
    "                    data_flat = ref_subset.flatten()\n",
    "                    \n",
    "                    data_range = max(np.nanmax(obs_flat), np.nanmax(data_flat)) - min(np.nanmin(obs_flat), np.nanmin(data_flat))\n",
    "                    ssim_index, _ = ssim(obs_subset, ref_subset, full=True, data_range=data_range)\n",
    "\n",
    "                    # Now calculate SSIM\n",
    "                    ssim_index = np.abs(ssim_index)\n",
    "                    rmse = np.nanmean((obs_subset - ref_subset)**2)\n",
    "                    mae =  np.nanmean(np.abs(obs_subset - ref_subset))\n",
    "                    \n",
    "                    if name != 'ECMWF':\n",
    "                        data_flat = data_flat[~np.isnan(obs_flat)]\n",
    "                        np.count_nonzero(np.isnan(data_flat))\n",
    "\n",
    "                        obs_flat = obs_flat[~np.isnan(obs_flat)]\n",
    "                        np.count_nonzero(np.isnan(obs_flat))\n",
    "                    else:\n",
    "                        good_ref_values = [idx for (idx,i) in enumerate(data_flat) if ~np.isnan(i)]\n",
    "                        data_flat = data_flat[good_ref_values]\n",
    "                        obs_flat=obs_flat[good_ref_values]\n",
    "                        np.count_nonzero(np.isnan(obs_flat))\n",
    "                        #Now only grab the indices from obs which have values\n",
    "                        obs_good_values = ~np.isnan(obs_flat)\n",
    "                        data_flat = data_flat[obs_good_values]\n",
    "                        obs_corr = obs_flat[obs_good_values]\n",
    "                        \n",
    "                    correlation_matrix = np.corrcoef(obs_flat, data_flat)\n",
    "                    # The correlation coefficient is in the top right corner of the correlation matrix\n",
    "                    correlation_coefficient = correlation_matrix[0, 1]\n",
    "                    correlation_coefficient = round(correlation_coefficient,4)\n",
    "                    \n",
    "                    #find the correlation coefficient across the dataset\n",
    "                    '''With MAE'''\n",
    "                    axs[axs_start].text(text_x, text_y, f'MAE: {str(mae)[1:5]}\\nSSIM: {str(ssim_index)[1:5]}\\nr: {str(correlation_coefficient)[1:5]}', ha='right', va='bottom', \n",
    "                    fontsize=font_size_corr, color='black', \n",
    "                           bbox=dict(facecolor='white', alpha=1, edgecolor='none', boxstyle='round',pad=0.5))\n",
    "\n",
    "                    if axs_start % 4 == 0:\n",
    "                        axs[axs_start].text(0, 1.05, alphabet[start_letter], transform=ccrs.PlateCarree(), fontsize=20, fontweight='bold',  horizontalalignment='center') # Add letters\n",
    "                        start_letter+=1\n",
    "\n",
    "                axs_start+=1\n",
    "\n",
    "    \n",
    "    #                      [left, bottom, width, height] \n",
    "    cbar_ax = fig.add_axes([0.1, -0.03, .87, .02])\n",
    "    \n",
    "    # Draw the colorbar\n",
    "    cbar = fig.colorbar(im, cax=cbar_ax, orientation='horizontal')\n",
    "    cbar.set_label('Anomaly (m3/m3)')\n",
    "    \n",
    "    # fig.suptitle(f'Week {week_lead}', fontsize=15)\n",
    "    # plt.tight_layout()\n",
    "    \n",
    "    plt.savefig(f'{save_dir}/{exp}_{region_name}_{pd.to_datetime(start_).year}.png',bbox_inches='tight')\n",
    "    plt.show()\n",
    "    return(0)\n",
    "\n",
    "# make_plot_by_experiment_name_with_boundary_box(obs,unet,baseline,ecm,dates_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "852b2ca5-9feb-4245-9cd7-be3619501a42",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'template_testing_only' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m exp \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEX29_regular_RZSM\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m test_year \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2019\u001b[39m:\n\u001b[0;32m----> 4\u001b[0m     obs,unet,baseline,ecm,dates_ \u001b[38;5;241m=\u001b[39m \u001b[43mload_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexp\u001b[49m\u001b[43m,\u001b[49m\u001b[43mmean_or_median\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmean\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m     make_plot_by_experiment_name_with_boundary_box(obs,unet,baseline,ecm,dates_)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m test_year \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2012\u001b[39m:\n",
      "Cell \u001b[0;32mIn[6], line 4\u001b[0m, in \u001b[0;36mload_data\u001b[0;34m(exp, mean_or_median)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_data\u001b[39m(exp,mean_or_median):\n\u001b[1;32m      2\u001b[0m     \n\u001b[1;32m      3\u001b[0m     \u001b[38;5;66;03m#Look at a single plot\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m     unet_anomaly \u001b[38;5;241m=\u001b[39m verifications\u001b[38;5;241m.\u001b[39mcreate_reforecast_with_predictions_single_lead(template_testing_only \u001b[38;5;241m=\u001b[39m \u001b[43mtemplate_testing_only\u001b[49m, day_num\u001b[38;5;241m=\u001b[39mday_num, week_lead\u001b[38;5;241m=\u001b[39mweek_lead, \n\u001b[1;32m      5\u001b[0m                                                                                 experiment_name\u001b[38;5;241m=\u001b[39mexp, region_name\u001b[38;5;241m=\u001b[39mregion_name, mask_anom \u001b[38;5;241m=\u001b[39m mask_anom,\n\u001b[1;32m      6\u001b[0m                                                                                start_ \u001b[38;5;241m=\u001b[39m start_, end_ \u001b[38;5;241m=\u001b[39m end_, source \u001b[38;5;241m=\u001b[39m source, test_year \u001b[38;5;241m=\u001b[39m test_year)\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;66;03m# Mask data to LAND\u001b[39;00m\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m region_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCONUS\u001b[39m\u001b[38;5;124m'\u001b[39m:\n",
      "\u001b[0;31mNameError\u001b[0m: name 'template_testing_only' is not defined"
     ]
    }
   ],
   "source": [
    "exp = 'EX29_regular_RZSM'\n",
    "\n",
    "if test_year == 2019:\n",
    "    obs,unet,baseline,ecm,dates_ = load_data(exp,mean_or_median='mean')\n",
    "    make_plot_by_experiment_name_with_boundary_box(obs,unet,baseline,ecm,dates_)\n",
    "elif test_year == 2012:\n",
    "    exp = f'{exp}_{test_year}'\n",
    "    make_plot_by_experiment_name_with_boundary_box(exp=exp, mean_or_median='mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "785a2db6-a0ec-43c5-9c1e-7a5e1f3fd4c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3795423-6356-49bb-b9b8-09296edab7e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cde65772-fca6-42b8-a522-c50b2b7d0af0",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'predictions/australia/Wk3_testing/Wk3_testing_EX14_regular_RZSM.npy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m exp \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEX14_regular_RZSM\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;66;03m#Testing with 2012 with USA only\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m test_year \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2019\u001b[39m:\n\u001b[0;32m---> 10\u001b[0m     \u001b[43mmake_plot_by_experiment_name_with_boundary_box\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmean_or_median\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmean\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m test_year \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2012\u001b[39m:\n\u001b[1;32m     12\u001b[0m     exp \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexp\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtest_year\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n",
      "Cell \u001b[0;32mIn[6], line 4\u001b[0m, in \u001b[0;36mmake_plot_by_experiment_name_with_boundary_box\u001b[0;34m(exp, mean_or_median)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmake_plot_by_experiment_name_with_boundary_box\u001b[39m(exp, mean_or_median):\n\u001b[1;32m      2\u001b[0m \n\u001b[1;32m      3\u001b[0m     \u001b[38;5;66;03m#Look at a single plot\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m     unet_anomaly \u001b[38;5;241m=\u001b[39m \u001b[43mverifications\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_reforecast_with_predictions_single_lead\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtemplate_testing_only\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtemplate_testing_only\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mday_num\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mday_num\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweek_lead\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweek_lead\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m                                                                                \u001b[49m\u001b[43mexperiment_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mregion_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mregion_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask_anom\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmask_anom\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m                                                                               \u001b[49m\u001b[43mstart_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mstart_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mend_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msource\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_year\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtest_year\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;66;03m# Mask data to LAND\u001b[39;00m\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m region_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCONUS\u001b[39m\u001b[38;5;124m'\u001b[39m:\n",
      "File \u001b[0;32m/glade/work/klesinger/FD_RZSM_deep_learning/verifications.py:122\u001b[0m, in \u001b[0;36mcreate_reforecast_with_predictions_single_lead\u001b[0;34m(template_testing_only, day_num, week_lead, experiment_name, region_name, mask_anom, start_, end_, source, test_year)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate_reforecast_with_predictions_single_lead\u001b[39m(template_testing_only: xr\u001b[38;5;241m.\u001b[39mDataArray, day_num: \u001b[38;5;28mint\u001b[39m, week_lead: \u001b[38;5;28mint\u001b[39m, experiment_name: \u001b[38;5;28mstr\u001b[39m, region_name: \u001b[38;5;28mstr\u001b[39m, mask_anom: np\u001b[38;5;241m.\u001b[39mndarray, start_: \u001b[38;5;28mstr\u001b[39m, end_: \u001b[38;5;28mstr\u001b[39m, source: \u001b[38;5;28mstr\u001b[39m, test_year: \u001b[38;5;28mint\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m xr\u001b[38;5;241m.\u001b[39mDataArray:\n\u001b[1;32m    118\u001b[0m     \u001b[38;5;66;03m#Load previous predictions from experiments\u001b[39;00m\n\u001b[1;32m    119\u001b[0m     temp_cp \u001b[38;5;241m=\u001b[39m template_testing_only\u001b[38;5;241m.\u001b[39mcopy(deep\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\u001b[38;5;241m.\u001b[39msel(L\u001b[38;5;241m=\u001b[39mday_num)\n\u001b[0;32m--> 122\u001b[0m     test \u001b[38;5;241m=\u001b[39m reverse_min_max_scaling(\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpredictions/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mregion_name\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/Wk\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mweek_lead\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m_testing/Wk\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mweek_lead\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m_testing_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mexperiment_name\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m.npy\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;241m2\u001b[39m,:,:,:,\u001b[38;5;241m0\u001b[39m],region_name,day_num,source,test_year)\n\u001b[1;32m    123\u001b[0m     test \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mreshape(test,(test\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m11\u001b[39m,\u001b[38;5;241m11\u001b[39m,test\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m],test\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m2\u001b[39m]))\n\u001b[1;32m    125\u001b[0m     \u001b[38;5;66;03m#Apply mask \u001b[39;00m\n",
      "File \u001b[0;32m/glade/work/klesinger/conda-envs/tf212gpu/lib/python3.10/site-packages/numpy/lib/npyio.py:405\u001b[0m, in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding, max_header_size)\u001b[0m\n\u001b[1;32m    403\u001b[0m     own_fid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    404\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 405\u001b[0m     fid \u001b[38;5;241m=\u001b[39m stack\u001b[38;5;241m.\u001b[39menter_context(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mos_fspath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    406\u001b[0m     own_fid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    408\u001b[0m \u001b[38;5;66;03m# Code to distinguish from NumPy binary files and pickles.\u001b[39;00m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'predictions/australia/Wk3_testing/Wk3_testing_EX14_regular_RZSM.npy'"
     ]
    }
   ],
   "source": [
    "if source == 'GEFSv12':\n",
    "    exp='EX27_regular_RZSM' #When trained on GEFSv12\n",
    "    # exp='EX6_regular_RZSM' #When trained on GEFSv12\n",
    "elif source == 'ECMWF':\n",
    "    exp='EX27_ECMWF_regular_RZSM' #When trained on ECMWF\n",
    "\n",
    "# exp = 'EX27_regular_RZSM' #Testing with 2012 with USA only\n",
    "\n",
    "if test_year == 2019:\n",
    "    make_plot_by_experiment_name_with_boundary_box(exp=exp, mean_or_median='mean')\n",
    "elif test_year == 2012:\n",
    "    exp = f'{exp}_{test_year}'\n",
    "    make_plot_by_experiment_name_with_boundary_box(exp=exp, mean_or_median='mean')\n",
    "\n",
    "STOP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c380dd50-9716-4ffc-820f-ab10a7c168b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_plot_by_experiment_name_just_single_area(exp, mean_or_median):\n",
    "\n",
    "\n",
    "    #Look at a single plot\n",
    "    unet_anomaly = verifications.create_reforecast_with_predictions_single_lead(template_testing_only = template_testing_only, day_num=day_num, week_lead=week_lead, \n",
    "                                                                                experiment_name=exp, region_name=region_name, mask_anom = mask_anom,\n",
    "                                                                               start_ = start_, end_ = end_, source = source, test_year = test_year)\n",
    "    \n",
    "    # Mask data to LAND\n",
    "    if region_name == 'CONUS':\n",
    "        if mean_or_median == 'mean':\n",
    "            obs = xr.where(mask_anom ==1, obs_anomaly_SubX_format.sel(L=day_num).mean(dim='M').sel(S=slice(start_,end_)),np.nan)\n",
    "            unet = xr.where(mask_anom ==1, unet_anomaly.mean(dim='M'),np.nan)\n",
    "            baseline = xr.where(mask_anom ==1, baseline_anomaly.mean(dim='M').sel(L=day_num).sel(S=slice(start_,end_)),np.nan)\n",
    "            ecm = xr.where(mask_anom ==1, baseline_ecmwf.mean(dim='M').sel(L=day_num).sel(S=slice(start_,end_)),np.nan)\n",
    "        else:\n",
    "            obs = xr.where(mask_anom ==1, obs_anomaly_SubX_format.sel(L=day_num).median(dim='M').sel(S=slice(start_,end_)),np.nan)\n",
    "            unet = xr.where(mask_anom ==1, unet_anomaly.median(dim='M'),np.nan)\n",
    "            baseline = xr.where(mask_anom ==1, baseline_anomaly.median(dim='M').sel(L=day_num).sel(S=slice(start_,end_)),np.nan)\n",
    "            ecm = xr.where(mask_anom ==1, baseline_ecmwf.median(dim='M').sel(L=day_num).sel(S=slice(start_,end_)),np.nan)\n",
    "            \n",
    "    elif region_name == 'australia':\n",
    "        obs = xr.where(np.isnan(mask_anom), np.nan, obs_anomaly_SubX_format.sel(L=day_num).mean(dim='M').sel(S=slice(start_,end_)))\n",
    "        unet = xr.where(np.isnan(mask_anom), np.nan, unet_anomaly.mean(dim='M'))\n",
    "        baseline = xr.where(np.isnan(mask_anom), np.nan, baseline_anomaly.mean(dim='M').sel(L=day_num).sel(S=slice(start_,end_)))\n",
    "        ecm = xr.where(np.isnan(mask_anom), np.nan, baseline_ecmwf.mean(dim='M').sel(L=day_num).sel(S=slice(start_,end_)))\n",
    "        \n",
    "    dates_ = obs.S.values\n",
    "    unet = unet.assign_coords({'S':dates_})\n",
    "    baseline = baseline.assign_coords({'S':dates_})\n",
    "    ecm = ecm.assign_coords({'S':dates_})\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "       \n",
    "    # cmap = 'coolwarm'\n",
    "    def plot_case_study_anomaly(obs, unet, baseline, ecm):\n",
    "\n",
    "        if region_name == 'CONUS':\n",
    "            text_x = -83.5\n",
    "            text_y = 27\n",
    "            fig_width = 10\n",
    "            fig_height = 15\n",
    "        elif region_name == 'australia':\n",
    "            text_x = 136\n",
    "            text_y = -36\n",
    "            fig_width = 10\n",
    "            fig_height = 30\n",
    "            \n",
    "        font_size_corr = 9\n",
    "        \n",
    "        cmap = plt.get_cmap('bwr')    \n",
    "        \n",
    "        save_dir = f'timeseries/Outputs/Case_studies/test_other_models/{region_name}/Wk{week_lead}'\n",
    "        os.system(f'mkdir -p {save_dir}')\n",
    "            \n",
    "        fig, axs = plt.subplots(\n",
    "            nrows = len(obs.S.values), ncols= 4, subplot_kw={'projection': ccrs.PlateCarree()}, figsize=(fig_width,fig_height))\n",
    "        axs = axs.flatten()\n",
    "        \n",
    "        \n",
    "        min_,max_ = get_min_max_of_files_anomaly(obs, unet, baseline, ecm, obs.S.values)\n",
    "        v = np.linspace(min_, max_, 20, endpoint=True)\n",
    "        #Make sure we have a diverging color at 0\n",
    "        v  = [i for i in v if i <0] + [0] + [i for i in v if i >0]\n",
    "\n",
    "        \n",
    "        # test_file = mae_rzsm_keys\n",
    "        # for Subx original data\n",
    "    \n",
    "        # min_,max_ = -0.5,1\n",
    "        \n",
    "        lon = obs.X.values\n",
    "        lat = obs.Y.values\n",
    "        \n",
    "        axs_start = 0\n",
    "        for init_date in obs.S.values:\n",
    "            init_date = pd.to_datetime(init_date)\n",
    "            date = f'{init_date.year}-{init_date.month:02}-{init_date.day:02}'\n",
    "            # break\n",
    "            for lead in [day_num]:\n",
    "                for data_to_plot,name in zip([obs, unet, baseline, ecm], ['GLEAM','UNET','GEFSv12', 'ECMWF']):\n",
    "                    # break\n",
    "                    data = return_array_anomaly(file=data_to_plot, date=init_date)\n",
    "\n",
    "                    if region_name == 'CONUS':\n",
    "                        map = Basemap(projection='cyl', llcrnrlat=25, urcrnrlat=50,\n",
    "                                      llcrnrlon=-128, urcrnrlon=-60, resolution='l')\n",
    "                    elif region_name == 'australia':\n",
    "                        map = Basemap(projection='cyl', llcrnrlat=-37, urcrnrlat=-12,\n",
    "                                      llcrnrlon=110, urcrnrlon=160, resolution='l')\n",
    "                        \n",
    "                    x, y = map(*np.meshgrid(lon, lat))\n",
    "                    # Adjust the text coordinates based on the actual data coordinates\n",
    "                \n",
    "                    norm = TwoSlopeNorm(vmin=min_, vcenter=0, vmax=max_)\n",
    "                \n",
    "                    im = axs[axs_start].contourf(x, y, data, levels=v, extend='both',\n",
    "                                          transform=ccrs.PlateCarree(), cmap=cmap,norm=norm)\n",
    "            \n",
    "            \n",
    "                    # axs[idx].title.set_text(f'SubX Lead {lead*7}')\n",
    "                    gl = axs[axs_start].gridlines(crs=ccrs.PlateCarree(), draw_labels=True,\n",
    "                                               linewidth=0.7, color='gray', alpha=0.5, linestyle='--')\n",
    "                    gl.top_labels = False\n",
    "                    gl.right_labels = False\n",
    "                    if lead != 1:\n",
    "                        gl.left_labels = False\n",
    "                    gl.xformatter = LongitudeFormatter()\n",
    "                    gl.yformatter = LatitudeFormatter()\n",
    "                    axs[axs_start].coastlines()\n",
    "                    # plt.colorbar(im)\n",
    "                    # axs[idx].set_aspect('auto', adjustable=None)\n",
    "                    axs[axs_start].set_aspect('equal')  # this makes the plots better\n",
    "                    axs[axs_start].set_title(f'{name} \\nLead {lead} Init: {date} ',fontsize=12)\n",
    "        \n",
    "                    if name in ['UNET','GEFSv12', 'ECMWF']:\n",
    "                        # Calculate the Pearson correlation coefficient\n",
    "                        obs_corr = return_array_anomaly(file=obs, date=init_date).flatten()\n",
    "                        data_corr = data.flatten()\n",
    "\n",
    "                        if name != 'ECMWF':\n",
    "                            data_corr = data_corr[~np.isnan(obs_corr)]\n",
    "                            np.count_nonzero(np.isnan(data_corr))\n",
    "    \n",
    "                            obs_corr = obs_corr[~np.isnan(obs_corr)]\n",
    "                            np.count_nonzero(np.isnan(obs_corr))\n",
    "                        else:\n",
    "                            good_ref_values = [idx for (idx,i) in enumerate(data_corr) if ~np.isnan(i)]\n",
    "                            data_corr = data_corr[good_ref_values]\n",
    "                            obs_corr=obs_corr[good_ref_values]\n",
    "                            np.count_nonzero(np.isnan(obs_corr))\n",
    "                            #Now only grab the indices from obs which have values\n",
    "                            obs_good_values = ~np.isnan(obs_corr)\n",
    "                            data_corr = data_corr[obs_good_values]\n",
    "                            obs_corr = obs_corr[obs_good_values]\n",
    "                            \n",
    "                        \n",
    "                            \n",
    "                        correlation_matrix = np.corrcoef(obs_corr, data_corr)\n",
    "                        # The correlation coefficient is in the top right corner of the correlation matrix\n",
    "                        correlation_coefficient = correlation_matrix[0, 1]\n",
    "                        correlation_coefficient = round(correlation_coefficient,4)\n",
    "                        #find the correlation coefficient across the dataset\n",
    "                        axs[axs_start].text(text_x, text_y, f'Corr: {correlation_coefficient}', ha='right', va='bottom', fontsize=font_size_corr, color='blue', weight = 'bold')\n",
    "                    \n",
    "                    \n",
    "                    axs_start+=1\n",
    "                \n",
    "        cbar_ax = fig.add_axes([0.05, -0.05, .9, .04])\n",
    "        \n",
    "        # Draw the colorbar\n",
    "        cbar = fig.colorbar(im, cax=cbar_ax, orientation='horizontal')\n",
    "        fig.suptitle(f'{exp}', fontsize=30)\n",
    "        fig.tight_layout()\n",
    "        \n",
    "        plt.savefig(f'{save_dir}/{exp}_.png',bbox_inches='tight')\n",
    "        plt.show()\n",
    "\n",
    "    #Call plot function\n",
    "    plot_case_study_anomaly(obs=obs, unet=unet, baseline=baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5ebc1de-2cd0-49c0-8794-6ea0cc1ec907",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1644aa71-fc3a-4d95-8a2a-4bb2032d48cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d03d93b-882d-4c94-8e0e-9726e0d50d82",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tf212gpu]",
   "language": "python",
   "name": "conda-env-tf212gpu-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "toc-autonumbering": true,
  "toc-showcode": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
