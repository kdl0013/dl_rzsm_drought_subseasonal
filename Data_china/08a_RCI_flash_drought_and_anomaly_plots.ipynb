{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7302f239-5aba-4164-8125-86df134c9bd5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-02 10:17:20.329615: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-02 10:17:22.911102: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-03-02 10:17:25.671970: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/glade/work/klesinger/conda-envs/tf212gpu/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%reload_ext autoreload\n",
    "\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import os\n",
    "from glob import glob\n",
    "import functions as f\n",
    "#import climpredNEW.climpred \n",
    "#from climpredNEW.climpred.options import OPTIONS\n",
    "from mpl_toolkits.basemap import Basemap\n",
    "from numpy import meshgrid\n",
    "from mpl_toolkits.axes_grid1.axes_divider import make_axes_locatable\n",
    "import matplotlib.colors as mcolors\n",
    "import cartopy.feature as cfeature\n",
    "import itertools\n",
    "import cartopy.crs as ccrs\n",
    "from cartopy.mpl.ticker import LongitudeFormatter, LatitudeFormatter, LatitudeLocator\n",
    "import matplotlib.ticker as mticker\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap, TwoSlopeNorm\n",
    "import pandas as pd\n",
    "import math\n",
    "from scipy.stats import percentileofscore as pos\n",
    "from datetime import datetime\n",
    "import datetime as dt\n",
    "from multiprocessing import Pool\n",
    "from sklearn.metrics import confusion_matrix as CM\n",
    "import masks\n",
    "import preprocessUtils as putils\n",
    "import verifications\n",
    "import warnings\n",
    "\n",
    "\n",
    "\n",
    "# Ignore specific RuntimeWarning\n",
    "warnings.filterwarnings(\"ignore\", message=\"invalid value encountered in sqrt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c43618dd-e586-47fa-b90f-5439ce9e3e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set script parameters\n",
    "global region_name\n",
    "region_name = 'CONUS' #['CONUS','australia', 'china']\n",
    "\n",
    "if region_name == 'CONUS':\n",
    "    source = 'Data'\n",
    "else:\n",
    "    source = f'{Data}_{region_name}'\n",
    "\n",
    "mask = masks.load_mask(region_name)\n",
    "\n",
    "\n",
    "#Mask with np.nan for non-CONUS land values\n",
    "mask_anom = mask[putils.xarray_varname(mask)][0,:,:].values\n",
    "\n",
    "\n",
    "#leads to select\n",
    "leads_ = [6,13,20,27,34]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "612950b1-1fcf-4522-b79c-7d85f090e726",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "#For RCI week differencing\n",
    "global week_differencing\n",
    "week_differencing = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42762c4a-b6c6-4895-9afd-1cc842efcd01",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "14358283-7f2f-4853-bc59-6aef5bdea455",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading GLEAM RZSM anomalies\n"
     ]
    }
   ],
   "source": [
    "\n",
    "obs_anomaly = xr.open_dataset(f'{source}/GLEAM/RZSM_anomaly.nc')\n",
    "\n",
    "obs_anomaly = obs_anomaly.rename({'longitude':'X','latitude':'Y'})\n",
    "\n",
    "print(f'Loading GLEAM RZSM anomalies')\n",
    "obs_anomaly_SubX_format = xr.open_mfdataset(f'Data/GLEAM/RZSM_anomaly_reformat_SubX_format/{region_name}/RZSM_anomaly*.n*').sel(L=leads_).load()\n",
    "\n",
    "init_date_list = [pd.to_datetime(i) for i in obs_anomaly_SubX_format.S.values] #Use for later reformatting the files\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2d31366f-1112-4d01-bd53-5ca0515f5a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reforecast baseline files\n",
    "#######################################   Reforecast baseline files   ###########################################################################\n",
    "baseline_anomaly_file_list = sorted(glob(f'{source}/GEFSv12_reforecast/soilw_bgrnd/baseline_RZSM_anomaly/soil*.n*'))\n",
    "gefs_anom = xr.open_mfdataset(baseline_anomaly_file_list).sel(L=leads_).load()\n",
    "\n",
    "ecmwf_anom = verifications.load_ECMWF_baseline_anomaly(region_name).sel(L=leads_).load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e5626547-7cfc-4960-8bba-ca5787f98ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# baseline_percentile_file_list = sorted(glob(f'{source}/GEFSv12_reforecast/soilw_bgrnd/percentiles_baseline/RZSM_percentiles_2*.nc'))\n",
    "# baseline_percentile_MEM_file_list = sorted(glob(f'{source}/GEFSv12_reforecast/soilw_bgrnd/percentiles_baseline/RZSM_percentiles_MEM_2*.nc'))\n",
    "\n",
    "# baseline_percentile = xr.open_mfdataset(baseline_percentile_file_list,combine='nested',concat_dim=['S']).sel(L=[0,6,13,20,27,34]).astype(np.float32).load()\n",
    "# baseline_percentile_MEM = xr.open_mfdataset(baseline_percentile_MEM_file_list,combine='nested',concat_dim=['S']).sel(L=[0,6,13,20,27,34]).astype(np.float32).load()\n",
    "\n",
    "# #########################################   Prediction (UNET) files   ######################################################################################\n",
    "# unet_anomaly_file_list = sorted(glob(f'predictions/no_julian_dates/{experiment_name}_*.nc'))\n",
    "# unet_percentile_file_list = sorted(glob(f'predictions/UNET/percentiles/{experiment_name}/RZSM_percentiles_2*.nc'))\n",
    "# unet_percentile_MEM_file_list = sorted(glob(f'predictions/UNET/percentiles/{experiment_name}/RZSM_percentiles_MEM_2*.nc'))\n",
    "\n",
    "# unet_percentile = xr.open_mfdataset(unet_percentile_file_list,combine='nested',concat_dim=['S']).sel(L=[0,6,13,20,27,34]).astype(np.float32).load()\n",
    "# unet_percentile_MEM = xr.open_mfdataset(unet_percentile_MEM_file_list,combine='nested',concat_dim=['S']).sel(L=[0,6,13,20,27,34]).astype(np.float32).load()\n",
    "\n",
    "# #Test\n",
    "# # anomaly_file_list=baseline_anomaly_file_list\n",
    "# # percentile_file_list = baseline_percentile_file_list\n",
    "# # percentile_file_list_MEM=baseline_percentile_MEM_file_list\n",
    "# # obs_anomaly=obs_anomaly\n",
    "# # save_dir='Data/GEFSv12_reforecast/soilw_bgrnd/SMVI'\n",
    "# # MEM_or_by_model='MEM'\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d701cacb-6d6d-4751-8b3c-885c1da8ebde",
   "metadata": {},
   "source": [
    "# Rapid change index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8dd85f5e-c5ea-4fbb-8b21-921bc8de5ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a time series to later iterate through for dates\n",
    "time_index_short = pd.to_datetime(obs_anomaly.sel(time=slice('2000-01-01','2000-12-31')).time.values)\n",
    "time_index_full = pd.to_datetime(obs_anomaly.time.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21519943-e984-4646-b02b-4b5853d7de1a",
   "metadata": {},
   "source": [
    "# Step 1, compute the mean weekly difference across all years for the same dates (OBSERVATIONS ONLY). \n",
    "\n",
    "## We are first applying a rolling mean equal to $Week_differencing (3 weeks right now)\n",
    "\n",
    "## Also compute the standard deviation of the weekly differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d54ba266-6586-4fb3-8269-27cb11f730d1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/glade/derecho/scratch/klesinger/tmp/ipykernel_55082/2075687811.py:45: RuntimeWarning: Mean of empty slice\n",
      "  mean_diff_across_years = np.nanmean(selected_data[putils.xarray_varname(selected_data)][:,:,:].values - selected_data_previous[putils.xarray_varname(selected_data)][:,:,:].values,axis=0)\n",
      "/glade/work/klesinger/conda-envs/tf212gpu/lib/python3.10/site-packages/numpy/lib/nanfunctions.py:1878: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = nanvar(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n"
     ]
    }
   ],
   "source": [
    "#Can change the difference weeks based on if we want to look at longer (or shorter) differenceing intervals\n",
    "\n",
    "\n",
    "def return_std_and_mean_diff_across_years():\n",
    "\n",
    "    std_daily_dict = {}\n",
    "    mean_diff_dict = {}\n",
    "    \n",
    "    #First compute the rolling average based on the week differencing\n",
    "    rolling_average = obs_anomaly.rolling(time=7*week_differencing, min_periods=7*week_differencing,center=False).mean()\n",
    "    \n",
    "    for idx,date in enumerate(time_index_short):\n",
    "        # break\n",
    "        #Grab all the same month and day values across all years\n",
    "        \n",
    "        #Need to add this because the leap year dates don't have enough values\n",
    "        if date == pd.to_datetime('2000-02-29'):\n",
    "            new_date = pd.to_datetime('2000-02-28')\n",
    "        else:\n",
    "            new_date = date\n",
    "        \n",
    "        #Select all the days across all years with the same month and day\n",
    "        mask_current_week = (time_index_full.month == new_date.month) & (time_index_full.day == new_date.day)\n",
    "        selected_data = obs_anomaly.isel(time=mask_current_week)\n",
    "\n",
    "        #Now find the data from the previous week for each of those days\n",
    "        if new_date == pd.to_datetime('2000-03-07'):\n",
    "            leap_date = pd.to_datetime('2000-02-28')\n",
    "        else:\n",
    "            leap_date = new_date\n",
    "\n",
    "        previous_week = leap_date - np.timedelta64(week_differencing,'W')\n",
    "        mask_previous_week = (time_index_full.month == previous_week.month) & (time_index_full.day == previous_week.day)\n",
    "        \n",
    "        selected_data_previous = obs_anomaly.isel(time=mask_previous_week)\n",
    "\n",
    "        #Sometimes we have a mis-match between years (specifically the number of data points, they must be equal!), so this fixes it\n",
    "        if len(selected_data_previous.time.values) > len(selected_data.time.values):\n",
    "            selected_data_previous = selected_data_previous.isel(time = slice(0,len(selected_data.time.values)))\n",
    "        elif len(selected_data_previous.time.values) < len(selected_data.time.values):\n",
    "            selected_data = selected_data.isel(time = slice(0,len(selected_data_previous.time.values)))\n",
    "\n",
    "\n",
    "        #Now find the mean difference across all years and average\n",
    "        mean_diff_across_years = np.nanmean(selected_data[putils.xarray_varname(selected_data)][:,:,:].values - selected_data_previous[putils.xarray_varname(selected_data)][:,:,:].values,axis=0)\n",
    "        mean_diff_dict[f'{pd.to_datetime(date).year}-{pd.to_datetime(date).month:02}-{pd.to_datetime(date).day:02}'] = mean_diff_across_years\n",
    "        \n",
    "        # rv1_data = selected_data.RZSM[:,:,:].values\n",
    "        # rv2_data = selected_data_previous.RZSM[:,:,:].values\n",
    "        # std_combined = xr.concat([selected_data, selected_data_previous], dim='RZSM_2').std(dim='time')\n",
    "        \n",
    "        # Calculate the covariance between rv1 and rv2 along the third dimension\n",
    "        # covariance_rv1_rv2 = np.nancov(rv1_data.reshape(-1, rv1_data.shape[-1]), rv2_data.reshape(-1, rv2_data.shape[-1]))[0, 1]\n",
    "        # Calculate the standard deviation of the difference between rv1 and rv2\n",
    "        # std_dev_diff = np.sqrt(std_dev_rv1**2 + std_dev_rv2**2 - 2 * covariance_rv1_rv2)\n",
    "        \n",
    "        diff_across_years = selected_data[putils.xarray_varname(selected_data)][:,:,:].values - selected_data_previous[putils.xarray_varname(selected_data)][:,:,:].values\n",
    "        \n",
    "        std_ = np.nanstd(diff_across_years,axis=0)\n",
    "                \n",
    "        std_daily_dict[f'{pd.to_datetime(date).year}-{pd.to_datetime(date).month:02}-{pd.to_datetime(date).day:02}'] = std_\n",
    "        \n",
    "    return(std_daily_dict,mean_diff_dict)\n",
    "\n",
    "\n",
    "std_daily_dict,mean_diff_dict =return_std_and_mean_diff_across_years()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6378f277-5420-4b4c-8693-274428b5d448",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def get_current_and_previous_values_difference(date,file,week_differencing):\n",
    "    #test \n",
    "    # file = obs_anomaly\n",
    "\n",
    "    selected_data = obs_anomaly.sel(time=date)\n",
    "    \n",
    "    #Now find the data from the previous week for each of those days\n",
    "    if (pd.to_datetime(date).month == 3) and (pd.to_datetime(date).day == 7):\n",
    "        leap_date = pd.to_datetime(f'{pd.to_datetime(date).year}-02-28')\n",
    "    else:\n",
    "        leap_date = date\n",
    "\n",
    "    previous_week = leap_date - np.timedelta64(week_differencing,'W')\n",
    "    selected_data_previous = obs_anomaly.sel(time=previous_week)\n",
    "    \n",
    "    return(selected_data - selected_data_previous)\n",
    "\n",
    "def rci_function_OBS_only(obs_anomaly,week_differencing):\n",
    "    #Now we need to calculate the weekly difference betweeen weeks, then substract the mean, and divide by standard deviation\n",
    "    rci = xr.zeros_like(obs_anomaly)\n",
    "\n",
    "    for idx,date in enumerate(obs_anomaly.time.values):\n",
    "        # break\n",
    "        \n",
    "        #We must begin only at MARCH\n",
    "        if (pd.to_datetime(date).month == 3) and (pd.to_datetime(date).day <=7):\n",
    "            # print(f'Working on date {date}')\n",
    "            start_of_year = True\n",
    "            #We don't have any weeks to work with before the 7th of MARCH\n",
    "            rci[putils.xarray_varname(rci)][idx,:,:] = 0\n",
    "        elif (pd.to_datetime(date).month in [3, 4, 5, 6, 7, 8, 9, 10, 11]) and (pd.to_datetime(date).year >=2000):\n",
    "            # print(f'Working on date {date}')\n",
    "            start_of_year = False\n",
    "            # break\n",
    "\n",
    "            diff_weeks = get_current_and_previous_values_difference(date,obs_anomaly,week_differencing)\n",
    "            #Now standardize\n",
    "            rci_standardized = (diff_weeks - mean_diff_dict[f'2000-{pd.to_datetime(date).month:02}-{pd.to_datetime(date).day:02}']) / std_daily_dict[f'2000-{pd.to_datetime(date).month:02}-{pd.to_datetime(date).day:02}']\n",
    "            # plt.hist(rci_standardized.RZSM.values.flatten(),bins=30)\n",
    "            # plt.show()\n",
    "            \n",
    "            #Now update RCI value\n",
    "            subtract_ = xr.where(rci_standardized < -0.75,1,0)\n",
    "            add_ = xr.where(rci_standardized > 0.75,1,0)\n",
    "            \n",
    "            #If the signs switch between postive and negative with RCI, then we reset rci to 0\n",
    "            switch1 = np.where((rci_standardized[putils.xarray_varname(rci_standardized)] > 0) & (rci[putils.xarray_varname(rci)][idx - 7,:,:] < 0),2,0)\n",
    "            switch2 = np.where((rci_standardized[putils.xarray_varname(rci_standardized)] < 0) & (rci[putils.xarray_varname(rci)][idx - 7,:,:] > 0),2,0)\n",
    "            \n",
    "            sub = np.where(subtract_[putils.xarray_varname(subtract_)] == 1, rci[putils.xarray_varname(rci)][idx-7,:,:] - np.sqrt(np.abs(rci_standardized[putils.xarray_varname(rci_standardized)])-0.75),0)\n",
    "            add = np.where(add_[putils.xarray_varname(add_)] == 1, rci[putils.xarray_varname(rci)][idx-7,:,:] + np.sqrt(rci_standardized[putils.xarray_varname(rci_standardized)]-0.75),0)\n",
    "            \n",
    "            final = sub + add\n",
    "            \n",
    "            #Now switch back the data if the signs are oppositve\n",
    "            final = np.where(switch1 != 2, final,0)\n",
    "            final = np.where(switch2 != 2, final,0)\n",
    "            \n",
    "            rci[putils.xarray_varname(rci)][idx,:,:] = final\n",
    "            \n",
    "            # plt.hist(rci.RZSM[idx,:,:].values.flatten(),bins=30)\n",
    "            # plt.show()\n",
    "            \n",
    "    return(rci)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ef5f7ade-9cca-4a28-95a7-3b01cbb96acf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><svg style=\"position: absolute; width: 0; height: 0; overflow: hidden\">\n",
       "<defs>\n",
       "<symbol id=\"icon-database\" viewBox=\"0 0 32 32\">\n",
       "<path d=\"M16 0c-8.837 0-16 2.239-16 5v4c0 2.761 7.163 5 16 5s16-2.239 16-5v-4c0-2.761-7.163-5-16-5z\"></path>\n",
       "<path d=\"M16 17c-8.837 0-16-2.239-16-5v6c0 2.761 7.163 5 16 5s16-2.239 16-5v-6c0 2.761-7.163 5-16 5z\"></path>\n",
       "<path d=\"M16 26c-8.837 0-16-2.239-16-5v6c0 2.761 7.163 5 16 5s16-2.239 16-5v-6c0 2.761-7.163 5-16 5z\"></path>\n",
       "</symbol>\n",
       "<symbol id=\"icon-file-text2\" viewBox=\"0 0 32 32\">\n",
       "<path d=\"M28.681 7.159c-0.694-0.947-1.662-2.053-2.724-3.116s-2.169-2.030-3.116-2.724c-1.612-1.182-2.393-1.319-2.841-1.319h-15.5c-1.378 0-2.5 1.121-2.5 2.5v27c0 1.378 1.122 2.5 2.5 2.5h23c1.378 0 2.5-1.122 2.5-2.5v-19.5c0-0.448-0.137-1.23-1.319-2.841zM24.543 5.457c0.959 0.959 1.712 1.825 2.268 2.543h-4.811v-4.811c0.718 0.556 1.584 1.309 2.543 2.268zM28 29.5c0 0.271-0.229 0.5-0.5 0.5h-23c-0.271 0-0.5-0.229-0.5-0.5v-27c0-0.271 0.229-0.5 0.5-0.5 0 0 15.499-0 15.5 0v7c0 0.552 0.448 1 1 1h7v19.5z\"></path>\n",
       "<path d=\"M23 26h-14c-0.552 0-1-0.448-1-1s0.448-1 1-1h14c0.552 0 1 0.448 1 1s-0.448 1-1 1z\"></path>\n",
       "<path d=\"M23 22h-14c-0.552 0-1-0.448-1-1s0.448-1 1-1h14c0.552 0 1 0.448 1 1s-0.448 1-1 1z\"></path>\n",
       "<path d=\"M23 18h-14c-0.552 0-1-0.448-1-1s0.448-1 1-1h14c0.552 0 1 0.448 1 1s-0.448 1-1 1z\"></path>\n",
       "</symbol>\n",
       "</defs>\n",
       "</svg>\n",
       "<style>/* CSS stylesheet for displaying xarray objects in jupyterlab.\n",
       " *\n",
       " */\n",
       "\n",
       ":root {\n",
       "  --xr-font-color0: var(--jp-content-font-color0, rgba(0, 0, 0, 1));\n",
       "  --xr-font-color2: var(--jp-content-font-color2, rgba(0, 0, 0, 0.54));\n",
       "  --xr-font-color3: var(--jp-content-font-color3, rgba(0, 0, 0, 0.38));\n",
       "  --xr-border-color: var(--jp-border-color2, #e0e0e0);\n",
       "  --xr-disabled-color: var(--jp-layout-color3, #bdbdbd);\n",
       "  --xr-background-color: var(--jp-layout-color0, white);\n",
       "  --xr-background-color-row-even: var(--jp-layout-color1, white);\n",
       "  --xr-background-color-row-odd: var(--jp-layout-color2, #eeeeee);\n",
       "}\n",
       "\n",
       "html[theme=dark],\n",
       "body[data-theme=dark],\n",
       "body.vscode-dark {\n",
       "  --xr-font-color0: rgba(255, 255, 255, 1);\n",
       "  --xr-font-color2: rgba(255, 255, 255, 0.54);\n",
       "  --xr-font-color3: rgba(255, 255, 255, 0.38);\n",
       "  --xr-border-color: #1F1F1F;\n",
       "  --xr-disabled-color: #515151;\n",
       "  --xr-background-color: #111111;\n",
       "  --xr-background-color-row-even: #111111;\n",
       "  --xr-background-color-row-odd: #313131;\n",
       "}\n",
       "\n",
       ".xr-wrap {\n",
       "  display: block !important;\n",
       "  min-width: 300px;\n",
       "  max-width: 700px;\n",
       "}\n",
       "\n",
       ".xr-text-repr-fallback {\n",
       "  /* fallback to plain text repr when CSS is not injected (untrusted notebook) */\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-header {\n",
       "  padding-top: 6px;\n",
       "  padding-bottom: 6px;\n",
       "  margin-bottom: 4px;\n",
       "  border-bottom: solid 1px var(--xr-border-color);\n",
       "}\n",
       "\n",
       ".xr-header > div,\n",
       ".xr-header > ul {\n",
       "  display: inline;\n",
       "  margin-top: 0;\n",
       "  margin-bottom: 0;\n",
       "}\n",
       "\n",
       ".xr-obj-type,\n",
       ".xr-array-name {\n",
       "  margin-left: 2px;\n",
       "  margin-right: 10px;\n",
       "}\n",
       "\n",
       ".xr-obj-type {\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-sections {\n",
       "  padding-left: 0 !important;\n",
       "  display: grid;\n",
       "  grid-template-columns: 150px auto auto 1fr 20px 20px;\n",
       "}\n",
       "\n",
       ".xr-section-item {\n",
       "  display: contents;\n",
       "}\n",
       "\n",
       ".xr-section-item input {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-section-item input + label {\n",
       "  color: var(--xr-disabled-color);\n",
       "}\n",
       "\n",
       ".xr-section-item input:enabled + label {\n",
       "  cursor: pointer;\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-section-item input:enabled + label:hover {\n",
       "  color: var(--xr-font-color0);\n",
       "}\n",
       "\n",
       ".xr-section-summary {\n",
       "  grid-column: 1;\n",
       "  color: var(--xr-font-color2);\n",
       "  font-weight: 500;\n",
       "}\n",
       "\n",
       ".xr-section-summary > span {\n",
       "  display: inline-block;\n",
       "  padding-left: 0.5em;\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:disabled + label {\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-section-summary-in + label:before {\n",
       "  display: inline-block;\n",
       "  content: '►';\n",
       "  font-size: 11px;\n",
       "  width: 15px;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:disabled + label:before {\n",
       "  color: var(--xr-disabled-color);\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:checked + label:before {\n",
       "  content: '▼';\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:checked + label > span {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-section-summary,\n",
       ".xr-section-inline-details {\n",
       "  padding-top: 4px;\n",
       "  padding-bottom: 4px;\n",
       "}\n",
       "\n",
       ".xr-section-inline-details {\n",
       "  grid-column: 2 / -1;\n",
       "}\n",
       "\n",
       ".xr-section-details {\n",
       "  display: none;\n",
       "  grid-column: 1 / -1;\n",
       "  margin-bottom: 5px;\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:checked ~ .xr-section-details {\n",
       "  display: contents;\n",
       "}\n",
       "\n",
       ".xr-array-wrap {\n",
       "  grid-column: 1 / -1;\n",
       "  display: grid;\n",
       "  grid-template-columns: 20px auto;\n",
       "}\n",
       "\n",
       ".xr-array-wrap > label {\n",
       "  grid-column: 1;\n",
       "  vertical-align: top;\n",
       "}\n",
       "\n",
       ".xr-preview {\n",
       "  color: var(--xr-font-color3);\n",
       "}\n",
       "\n",
       ".xr-array-preview,\n",
       ".xr-array-data {\n",
       "  padding: 0 5px !important;\n",
       "  grid-column: 2;\n",
       "}\n",
       "\n",
       ".xr-array-data,\n",
       ".xr-array-in:checked ~ .xr-array-preview {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-array-in:checked ~ .xr-array-data,\n",
       ".xr-array-preview {\n",
       "  display: inline-block;\n",
       "}\n",
       "\n",
       ".xr-dim-list {\n",
       "  display: inline-block !important;\n",
       "  list-style: none;\n",
       "  padding: 0 !important;\n",
       "  margin: 0;\n",
       "}\n",
       "\n",
       ".xr-dim-list li {\n",
       "  display: inline-block;\n",
       "  padding: 0;\n",
       "  margin: 0;\n",
       "}\n",
       "\n",
       ".xr-dim-list:before {\n",
       "  content: '(';\n",
       "}\n",
       "\n",
       ".xr-dim-list:after {\n",
       "  content: ')';\n",
       "}\n",
       "\n",
       ".xr-dim-list li:not(:last-child):after {\n",
       "  content: ',';\n",
       "  padding-right: 5px;\n",
       "}\n",
       "\n",
       ".xr-has-index {\n",
       "  font-weight: bold;\n",
       "}\n",
       "\n",
       ".xr-var-list,\n",
       ".xr-var-item {\n",
       "  display: contents;\n",
       "}\n",
       "\n",
       ".xr-var-item > div,\n",
       ".xr-var-item label,\n",
       ".xr-var-item > .xr-var-name span {\n",
       "  background-color: var(--xr-background-color-row-even);\n",
       "  margin-bottom: 0;\n",
       "}\n",
       "\n",
       ".xr-var-item > .xr-var-name:hover span {\n",
       "  padding-right: 5px;\n",
       "}\n",
       "\n",
       ".xr-var-list > li:nth-child(odd) > div,\n",
       ".xr-var-list > li:nth-child(odd) > label,\n",
       ".xr-var-list > li:nth-child(odd) > .xr-var-name span {\n",
       "  background-color: var(--xr-background-color-row-odd);\n",
       "}\n",
       "\n",
       ".xr-var-name {\n",
       "  grid-column: 1;\n",
       "}\n",
       "\n",
       ".xr-var-dims {\n",
       "  grid-column: 2;\n",
       "}\n",
       "\n",
       ".xr-var-dtype {\n",
       "  grid-column: 3;\n",
       "  text-align: right;\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-var-preview {\n",
       "  grid-column: 4;\n",
       "}\n",
       "\n",
       ".xr-index-preview {\n",
       "  grid-column: 2 / 5;\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-var-name,\n",
       ".xr-var-dims,\n",
       ".xr-var-dtype,\n",
       ".xr-preview,\n",
       ".xr-attrs dt {\n",
       "  white-space: nowrap;\n",
       "  overflow: hidden;\n",
       "  text-overflow: ellipsis;\n",
       "  padding-right: 10px;\n",
       "}\n",
       "\n",
       ".xr-var-name:hover,\n",
       ".xr-var-dims:hover,\n",
       ".xr-var-dtype:hover,\n",
       ".xr-attrs dt:hover {\n",
       "  overflow: visible;\n",
       "  width: auto;\n",
       "  z-index: 1;\n",
       "}\n",
       "\n",
       ".xr-var-attrs,\n",
       ".xr-var-data,\n",
       ".xr-index-data {\n",
       "  display: none;\n",
       "  background-color: var(--xr-background-color) !important;\n",
       "  padding-bottom: 5px !important;\n",
       "}\n",
       "\n",
       ".xr-var-attrs-in:checked ~ .xr-var-attrs,\n",
       ".xr-var-data-in:checked ~ .xr-var-data,\n",
       ".xr-index-data-in:checked ~ .xr-index-data {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       ".xr-var-data > table {\n",
       "  float: right;\n",
       "}\n",
       "\n",
       ".xr-var-name span,\n",
       ".xr-var-data,\n",
       ".xr-index-name div,\n",
       ".xr-index-data,\n",
       ".xr-attrs {\n",
       "  padding-left: 25px !important;\n",
       "}\n",
       "\n",
       ".xr-attrs,\n",
       ".xr-var-attrs,\n",
       ".xr-var-data,\n",
       ".xr-index-data {\n",
       "  grid-column: 1 / -1;\n",
       "}\n",
       "\n",
       "dl.xr-attrs {\n",
       "  padding: 0;\n",
       "  margin: 0;\n",
       "  display: grid;\n",
       "  grid-template-columns: 125px auto;\n",
       "}\n",
       "\n",
       ".xr-attrs dt,\n",
       ".xr-attrs dd {\n",
       "  padding: 0;\n",
       "  margin: 0;\n",
       "  float: left;\n",
       "  padding-right: 10px;\n",
       "  width: auto;\n",
       "}\n",
       "\n",
       ".xr-attrs dt {\n",
       "  font-weight: normal;\n",
       "  grid-column: 1;\n",
       "}\n",
       "\n",
       ".xr-attrs dt:hover span {\n",
       "  display: inline-block;\n",
       "  background: var(--xr-background-color);\n",
       "  padding-right: 10px;\n",
       "}\n",
       "\n",
       ".xr-attrs dd {\n",
       "  grid-column: 2;\n",
       "  white-space: pre-wrap;\n",
       "  word-break: break-all;\n",
       "}\n",
       "\n",
       ".xr-icon-database,\n",
       ".xr-icon-file-text2,\n",
       ".xr-no-icon {\n",
       "  display: inline-block;\n",
       "  vertical-align: middle;\n",
       "  width: 1em;\n",
       "  height: 1.5em !important;\n",
       "  stroke-width: 0;\n",
       "  stroke: currentColor;\n",
       "  fill: currentColor;\n",
       "}\n",
       "</style><pre class='xr-text-repr-fallback'>&lt;xarray.Dataset&gt;\n",
       "Dimensions:  (time: 7731, Y: 48, X: 96)\n",
       "Coordinates:\n",
       "  * time     (time) datetime64[ns] 1999-01-01 1999-01-02 ... 2020-03-01\n",
       "  * X        (X) float64 238.0 238.5 239.0 239.5 ... 284.0 284.5 285.0 285.5\n",
       "  * Y        (Y) float64 50.0 49.5 49.0 48.5 48.0 ... 28.5 28.0 27.5 27.0 26.5\n",
       "    season   (time) object ...\n",
       "Data variables:\n",
       "    SMsurf   (time, Y, X) float32 0.0 0.0 0.0 0.0 0.0 ... 0.0 0.0 0.0 0.0 0.0</pre><div class='xr-wrap' style='display:none'><div class='xr-header'><div class='xr-obj-type'>xarray.Dataset</div></div><ul class='xr-sections'><li class='xr-section-item'><input id='section-883d3665-6932-48e7-b844-0b0cac3626aa' class='xr-section-summary-in' type='checkbox' disabled ><label for='section-883d3665-6932-48e7-b844-0b0cac3626aa' class='xr-section-summary'  title='Expand/collapse section'>Dimensions:</label><div class='xr-section-inline-details'><ul class='xr-dim-list'><li><span class='xr-has-index'>time</span>: 7731</li><li><span class='xr-has-index'>Y</span>: 48</li><li><span class='xr-has-index'>X</span>: 96</li></ul></div><div class='xr-section-details'></div></li><li class='xr-section-item'><input id='section-a6ad7ff7-b55e-4388-bf66-ef3d7a5714c1' class='xr-section-summary-in' type='checkbox'  checked><label for='section-a6ad7ff7-b55e-4388-bf66-ef3d7a5714c1' class='xr-section-summary' >Coordinates: <span>(4)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><ul class='xr-var-list'><li class='xr-var-item'><div class='xr-var-name'><span class='xr-has-index'>time</span></div><div class='xr-var-dims'>(time)</div><div class='xr-var-dtype'>datetime64[ns]</div><div class='xr-var-preview xr-preview'>1999-01-01 ... 2020-03-01</div><input id='attrs-c513e78a-17ca-48fb-901e-9b99bc4c80e1' class='xr-var-attrs-in' type='checkbox' ><label for='attrs-c513e78a-17ca-48fb-901e-9b99bc4c80e1' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-ab8f85dc-5293-4631-a145-765455aada52' class='xr-var-data-in' type='checkbox'><label for='data-ab8f85dc-5293-4631-a145-765455aada52' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'><dt><span>standard_name :</span></dt><dd>time</dd><dt><span>axis :</span></dt><dd>T</dd></dl></div><div class='xr-var-data'><pre>array([&#x27;1999-01-01T00:00:00.000000000&#x27;, &#x27;1999-01-02T00:00:00.000000000&#x27;,\n",
       "       &#x27;1999-01-03T00:00:00.000000000&#x27;, ..., &#x27;2020-02-28T00:00:00.000000000&#x27;,\n",
       "       &#x27;2020-02-29T00:00:00.000000000&#x27;, &#x27;2020-03-01T00:00:00.000000000&#x27;],\n",
       "      dtype=&#x27;datetime64[ns]&#x27;)</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span class='xr-has-index'>X</span></div><div class='xr-var-dims'>(X)</div><div class='xr-var-dtype'>float64</div><div class='xr-var-preview xr-preview'>238.0 238.5 239.0 ... 285.0 285.5</div><input id='attrs-93e1912c-1914-4257-a32e-f06aff141214' class='xr-var-attrs-in' type='checkbox' ><label for='attrs-93e1912c-1914-4257-a32e-f06aff141214' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-c5f0a3a4-907e-4551-9f4e-597cbc1e3199' class='xr-var-data-in' type='checkbox'><label for='data-c5f0a3a4-907e-4551-9f4e-597cbc1e3199' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'><dt><span>standard_name :</span></dt><dd>longitude</dd><dt><span>long_name :</span></dt><dd>longitude</dd><dt><span>units :</span></dt><dd>degrees_east</dd><dt><span>axis :</span></dt><dd>X</dd></dl></div><div class='xr-var-data'><pre>array([238. , 238.5, 239. , 239.5, 240. , 240.5, 241. , 241.5, 242. , 242.5,\n",
       "       243. , 243.5, 244. , 244.5, 245. , 245.5, 246. , 246.5, 247. , 247.5,\n",
       "       248. , 248.5, 249. , 249.5, 250. , 250.5, 251. , 251.5, 252. , 252.5,\n",
       "       253. , 253.5, 254. , 254.5, 255. , 255.5, 256. , 256.5, 257. , 257.5,\n",
       "       258. , 258.5, 259. , 259.5, 260. , 260.5, 261. , 261.5, 262. , 262.5,\n",
       "       263. , 263.5, 264. , 264.5, 265. , 265.5, 266. , 266.5, 267. , 267.5,\n",
       "       268. , 268.5, 269. , 269.5, 270. , 270.5, 271. , 271.5, 272. , 272.5,\n",
       "       273. , 273.5, 274. , 274.5, 275. , 275.5, 276. , 276.5, 277. , 277.5,\n",
       "       278. , 278.5, 279. , 279.5, 280. , 280.5, 281. , 281.5, 282. , 282.5,\n",
       "       283. , 283.5, 284. , 284.5, 285. , 285.5])</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span class='xr-has-index'>Y</span></div><div class='xr-var-dims'>(Y)</div><div class='xr-var-dtype'>float64</div><div class='xr-var-preview xr-preview'>50.0 49.5 49.0 ... 27.5 27.0 26.5</div><input id='attrs-8a3ecaa7-211f-41d3-99e7-0b49bbc99d86' class='xr-var-attrs-in' type='checkbox' ><label for='attrs-8a3ecaa7-211f-41d3-99e7-0b49bbc99d86' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-a338df80-0129-408d-b3df-c3e16083edef' class='xr-var-data-in' type='checkbox'><label for='data-a338df80-0129-408d-b3df-c3e16083edef' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'><dt><span>standard_name :</span></dt><dd>latitude</dd><dt><span>long_name :</span></dt><dd>latitude</dd><dt><span>units :</span></dt><dd>degrees_north</dd><dt><span>axis :</span></dt><dd>Y</dd></dl></div><div class='xr-var-data'><pre>array([50. , 49.5, 49. , 48.5, 48. , 47.5, 47. , 46.5, 46. , 45.5, 45. , 44.5,\n",
       "       44. , 43.5, 43. , 42.5, 42. , 41.5, 41. , 40.5, 40. , 39.5, 39. , 38.5,\n",
       "       38. , 37.5, 37. , 36.5, 36. , 35.5, 35. , 34.5, 34. , 33.5, 33. , 32.5,\n",
       "       32. , 31.5, 31. , 30.5, 30. , 29.5, 29. , 28.5, 28. , 27.5, 27. , 26.5])</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span>season</span></div><div class='xr-var-dims'>(time)</div><div class='xr-var-dtype'>object</div><div class='xr-var-preview xr-preview'>...</div><input id='attrs-662f13db-7aeb-42ec-b69d-5e30103af804' class='xr-var-attrs-in' type='checkbox' disabled><label for='attrs-662f13db-7aeb-42ec-b69d-5e30103af804' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-e575b790-153e-40b7-bda3-49f8eab64590' class='xr-var-data-in' type='checkbox'><label for='data-e575b790-153e-40b7-bda3-49f8eab64590' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'></dl></div><div class='xr-var-data'><pre>[7731 values with dtype=object]</pre></div></li></ul></div></li><li class='xr-section-item'><input id='section-2e93b93c-7860-427e-a1e9-9181a872ca69' class='xr-section-summary-in' type='checkbox'  checked><label for='section-2e93b93c-7860-427e-a1e9-9181a872ca69' class='xr-section-summary' >Data variables: <span>(1)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><ul class='xr-var-list'><li class='xr-var-item'><div class='xr-var-name'><span>SMsurf</span></div><div class='xr-var-dims'>(time, Y, X)</div><div class='xr-var-dtype'>float32</div><div class='xr-var-preview xr-preview'>0.0 0.0 0.0 0.0 ... 0.0 0.0 0.0 0.0</div><input id='attrs-11178e4c-ae47-4629-b4d4-702cabd2c7fd' class='xr-var-attrs-in' type='checkbox' disabled><label for='attrs-11178e4c-ae47-4629-b4d4-702cabd2c7fd' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-0173e29a-6155-443e-ae2b-5bac1814ea7f' class='xr-var-data-in' type='checkbox'><label for='data-0173e29a-6155-443e-ae2b-5bac1814ea7f' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'></dl></div><div class='xr-var-data'><pre>array([[[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "...\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]]], dtype=float32)</pre></div></li></ul></div></li><li class='xr-section-item'><input id='section-0c503d3d-84ba-4409-aa1b-66cfacead513' class='xr-section-summary-in' type='checkbox'  ><label for='section-0c503d3d-84ba-4409-aa1b-66cfacead513' class='xr-section-summary' >Indexes: <span>(3)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><ul class='xr-var-list'><li class='xr-var-item'><div class='xr-index-name'><div>time</div></div><div class='xr-index-preview'>PandasIndex</div><div></div><input id='index-61f6a9fc-1b09-4574-a9f0-e963c7f7466c' class='xr-index-data-in' type='checkbox'/><label for='index-61f6a9fc-1b09-4574-a9f0-e963c7f7466c' title='Show/Hide index repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-index-data'><pre>PandasIndex(DatetimeIndex([&#x27;1999-01-01&#x27;, &#x27;1999-01-02&#x27;, &#x27;1999-01-03&#x27;, &#x27;1999-01-04&#x27;,\n",
       "               &#x27;1999-01-05&#x27;, &#x27;1999-01-06&#x27;, &#x27;1999-01-07&#x27;, &#x27;1999-01-08&#x27;,\n",
       "               &#x27;1999-01-09&#x27;, &#x27;1999-01-10&#x27;,\n",
       "               ...\n",
       "               &#x27;2020-02-21&#x27;, &#x27;2020-02-22&#x27;, &#x27;2020-02-23&#x27;, &#x27;2020-02-24&#x27;,\n",
       "               &#x27;2020-02-25&#x27;, &#x27;2020-02-26&#x27;, &#x27;2020-02-27&#x27;, &#x27;2020-02-28&#x27;,\n",
       "               &#x27;2020-02-29&#x27;, &#x27;2020-03-01&#x27;],\n",
       "              dtype=&#x27;datetime64[ns]&#x27;, name=&#x27;time&#x27;, length=7731, freq=None))</pre></div></li><li class='xr-var-item'><div class='xr-index-name'><div>X</div></div><div class='xr-index-preview'>PandasIndex</div><div></div><input id='index-dbb8fdc6-6674-4be4-a2ca-968b88e39897' class='xr-index-data-in' type='checkbox'/><label for='index-dbb8fdc6-6674-4be4-a2ca-968b88e39897' title='Show/Hide index repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-index-data'><pre>PandasIndex(Index([238.0, 238.5, 239.0, 239.5, 240.0, 240.5, 241.0, 241.5, 242.0, 242.5,\n",
       "       243.0, 243.5, 244.0, 244.5, 245.0, 245.5, 246.0, 246.5, 247.0, 247.5,\n",
       "       248.0, 248.5, 249.0, 249.5, 250.0, 250.5, 251.0, 251.5, 252.0, 252.5,\n",
       "       253.0, 253.5, 254.0, 254.5, 255.0, 255.5, 256.0, 256.5, 257.0, 257.5,\n",
       "       258.0, 258.5, 259.0, 259.5, 260.0, 260.5, 261.0, 261.5, 262.0, 262.5,\n",
       "       263.0, 263.5, 264.0, 264.5, 265.0, 265.5, 266.0, 266.5, 267.0, 267.5,\n",
       "       268.0, 268.5, 269.0, 269.5, 270.0, 270.5, 271.0, 271.5, 272.0, 272.5,\n",
       "       273.0, 273.5, 274.0, 274.5, 275.0, 275.5, 276.0, 276.5, 277.0, 277.5,\n",
       "       278.0, 278.5, 279.0, 279.5, 280.0, 280.5, 281.0, 281.5, 282.0, 282.5,\n",
       "       283.0, 283.5, 284.0, 284.5, 285.0, 285.5],\n",
       "      dtype=&#x27;float64&#x27;, name=&#x27;X&#x27;))</pre></div></li><li class='xr-var-item'><div class='xr-index-name'><div>Y</div></div><div class='xr-index-preview'>PandasIndex</div><div></div><input id='index-7e3f50a3-b634-4185-8195-60d3ea8482fd' class='xr-index-data-in' type='checkbox'/><label for='index-7e3f50a3-b634-4185-8195-60d3ea8482fd' title='Show/Hide index repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-index-data'><pre>PandasIndex(Index([50.0, 49.5, 49.0, 48.5, 48.0, 47.5, 47.0, 46.5, 46.0, 45.5, 45.0, 44.5,\n",
       "       44.0, 43.5, 43.0, 42.5, 42.0, 41.5, 41.0, 40.5, 40.0, 39.5, 39.0, 38.5,\n",
       "       38.0, 37.5, 37.0, 36.5, 36.0, 35.5, 35.0, 34.5, 34.0, 33.5, 33.0, 32.5,\n",
       "       32.0, 31.5, 31.0, 30.5, 30.0, 29.5, 29.0, 28.5, 28.0, 27.5, 27.0, 26.5],\n",
       "      dtype=&#x27;float64&#x27;, name=&#x27;Y&#x27;))</pre></div></li></ul></div></li><li class='xr-section-item'><input id='section-b0864efa-fdb4-48ea-bc8a-fc538058e240' class='xr-section-summary-in' type='checkbox' disabled ><label for='section-b0864efa-fdb4-48ea-bc8a-fc538058e240' class='xr-section-summary'  title='Expand/collapse section'>Attributes: <span>(0)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><dl class='xr-attrs'></dl></div></li></ul></div></div>"
      ],
      "text/plain": [
       "<xarray.Dataset>\n",
       "Dimensions:  (time: 7731, Y: 48, X: 96)\n",
       "Coordinates:\n",
       "  * time     (time) datetime64[ns] 1999-01-01 1999-01-02 ... 2020-03-01\n",
       "  * X        (X) float64 238.0 238.5 239.0 239.5 ... 284.0 284.5 285.0 285.5\n",
       "  * Y        (Y) float64 50.0 49.5 49.0 48.5 48.0 ... 28.5 28.0 27.5 27.0 26.5\n",
       "    season   (time) object ...\n",
       "Data variables:\n",
       "    SMsurf   (time, Y, X) float32 0.0 0.0 0.0 0.0 0.0 ... 0.0 0.0 0.0 0.0 0.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#RCI save \n",
    "save_rci = f'{source}/GLEAM/RCI_index_{week_differencing}_week.nc'\n",
    "\n",
    "if os.path.exists(save_rci):\n",
    "    rci_output = xr.open_dataset(save_rci).load()\n",
    "else:\n",
    "    rci_output = rci_function_OBS_only(obs_anomaly,week_differencing)\n",
    "    rci_output.to_netcdf(save_rci)\n",
    "\n",
    "\n",
    "#Plot the distribution for the RCI file\n",
    "rci_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f00a56f-4050-41fb-a4fe-6ce2d320fcb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def convert_OBS_to_SubX_format(_date):  \n",
    "# for _date in init_date_list:\n",
    "    # var='RZSM_weighted'\n",
    "    # _date=init_date_list[0]\n",
    "    \n",
    "    '''We are going to create new leads that are different than reforecast. The reasoning for this is that we want the actual weekly lags (and 1 day lag) and this will\n",
    "    assist with future predictions within the deep learning model'''\n",
    "    \n",
    "    save_dir = f'{source}/GLEAM/RCI_reformat_SubX_format'\n",
    "    os.system(f'mkdir -p {save_dir}')\n",
    "    \n",
    "    # for var in ['geopotential']:\n",
    "    ref_dir = f'{source}/GEFSv12_reforecast/soilw_bgrnd' #Just use a single reference directory to serve as the template for file creation\n",
    "  \n",
    "    #Grab a single SubX to use as the template. Doesn't matter if it is the same variable or not or the same date\n",
    "    fcst_file = glob(f'{ref_dir}/*soil*2000-01-05*')[0]\n",
    "    op = xr.open_dataset(fcst_file)\n",
    "    \n",
    "    if region_name == 'CONUS':\n",
    "        new_X_coords = [i+360 if i < 0 else i for i in op.X.values]\n",
    "        op = op.assign_coords({'X':new_X_coords})\n",
    "    \n",
    "    open_date_SubX = putils.restrict_to_bounding_box(op,mask)\n",
    "    out_file = xr.zeros_like(open_date_SubX)\n",
    "    \n",
    "    '''We are going to create a new lead day that represents the previous day before the forecast was initialized\n",
    "    #New shape will be (1x11x48x48x96)\n",
    "    This will include the day lag 1, and weekly lags 1-12'''\n",
    "    \n",
    "    file_shape = out_file[list(out_file.keys())[0]].shape\n",
    "\n",
    "    save_date = f'{_date.year}-{_date.month:02}-{_date.day:02}'\n",
    "    \n",
    "    obs_file_name = f'RCI_{week_differencing}week_reformat_{save_date}.nc4'\n",
    "    save_file = f'{save_dir}/{obs_file_name}'\n",
    "    \n",
    "    # if os.path.exists(save_file):\n",
    "    if os.path.exists('this.out'):\n",
    "        pass\n",
    "    else:\n",
    "        # os.system(f'rm {save_file}') #Just to avoid getting random duplicates\n",
    "        print(f'Working on initialized day {_date} to find values integrating with SubX models, leads, & coordinates and saving data into {save_dir}.')\n",
    "        \n",
    "        for idx,i_lead in enumerate(out_file.L.values):\n",
    "            # break\n",
    "\n",
    "            date_val = pd.to_datetime(pd.to_datetime(_date) + dt.timedelta(days=int(i_lead)+0)) #Adding +1 may be suitable for other forecasts which predict the next day. But GEFSv12 predicts lead 0 as 12 UTC on the same date it is initialized\n",
    "            #But be careful if you adapt this code to a new script. We are looking backwards in time from the first date.\n",
    "                \n",
    "            date_val = f'{date_val.year}-{date_val.month:02}-{date_val.day:02}'\n",
    "\n",
    "            out_file[putils.xarray_varname(out_file)][0,:, idx, :, :] = \\\n",
    "                rci_output[putils.xarray_varname(rci_output)].sel(time = date_val).values\n",
    "\n",
    "        var_OUT = xr.Dataset(\n",
    "            data_vars = dict(\n",
    "                rci = (['S','M','L','Y','X'],    out_file[list(out_file.keys())[0]].values),\n",
    "            ),\n",
    "            coords = dict(\n",
    "                S = np.atleast_1d(_date),\n",
    "                X = open_date_SubX.X.values,\n",
    "                Y = open_date_SubX.Y.values,\n",
    "                L = out_file.L.values,\n",
    "                M = open_date_SubX.M.values,\n",
    "\n",
    "            ),\n",
    "            attrs = dict(\n",
    "                Description = f'RCI values on the exact same date and grid \\\n",
    "                cell as EMC reforecast data. '),\n",
    "        )                    \n",
    "\n",
    "        var_OUT = var_OUT.astype(np.float32)\n",
    "        \n",
    "        var_OUT.to_netcdf(save_file)\n",
    "\n",
    "    return(0)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "####### RUN FUNCTION #######\n",
    "for date in init_date_list:\n",
    "    convert_OBS_to_SubX_format(date)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe2efd46-54ce-4e0d-9b42-76fd7a776141",
   "metadata": {},
   "source": [
    "# Now re-open the RCI files to analyze by lead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "24e0c72d-99fd-45d9-9de3-61586b5cf8bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the Observation RCI index file already computed.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#open the RCI file in subx format\n",
    "print('Loading the Observation RCI index file already computed.')\n",
    "obs_rci = xr.open_mfdataset(f'{source}/GLEAM/RCI_reformat_SubX_format/RCI*{week_differencing}week*').sel(L=leads_).load()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94c42133-5c5c-4a0d-91a2-ae21cb448bc4",
   "metadata": {},
   "source": [
    "# Now construct the RCI values for each of the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fc8a8b32-e69b-4701-ab66-025b4df2f546",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data\n",
    "\n",
    "#Unet final experiment name (week 5)\n",
    "experiment_name='EX27_regular_RZSM'\n",
    "\n",
    "\n",
    "#######################################   UNET prediction   ###########################################################################\n",
    "unet_anomaly_file_list = sorted(glob(f'predictions/{region_name}/anomaly_no_julian_dates/{experiment_name}_*.nc'))\n",
    "unet_anomaly = xr.open_mfdataset(unet_anomaly_file_list).sel(L=leads_).load()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a14d6d2-0628-4eee-b94d-544a6e32e66a",
   "metadata": {},
   "source": [
    "# Now calculate the RCI value based on previous observation differencing of standard deviation and day of year\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "05f3b2f5-76a3-4279-af6b-7e4eb5b09166",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def rci_reforecast_MEM(std_daily_dict, mean_diff_dict,week_differencing, reforecast_anomaly_MEM, obs_file, save_dir):\n",
    "\n",
    "    os.system(f'mkdir -p {save_dir}')\n",
    "    \n",
    "    #testing\n",
    "    # reforecast_anomaly_MEM = unet_anomaly\n",
    "                        # Lead   0   ,    1,    ,   2      ,      3    ,     4     ,      5\n",
    "    # output shape array([       nan, 0.0111007 , 0.01243984, 0.00984243, 0.01684886, 0.0191455 ])\n",
    "    \n",
    "    # obs_file = obs_rci.mean(dim='M')\n",
    "    # save_dir = f'predictions/UNET/RCI/{experiment_name}'\n",
    "\n",
    "    #Now go through each init day \n",
    "\n",
    "    #Take the mean\n",
    "    \n",
    "    \n",
    "    # reforecast_anomaly_MEM = reforecast_anomaly_MEM.mean(dim='M').rolling(L=2,min_periods=2,center=False).mean() #this is for the 1-week RCI calculation\n",
    "    # reforecast_anomaly_MEM.RZSM[0,:,10,10].values\n",
    "    \n",
    "    for idx,date in enumerate(reforecast_anomaly_MEM.S.values):\n",
    "        # break\n",
    "                \n",
    "        datetime_dt = pd.to_datetime(date)\n",
    "        save_date = f'{datetime_dt.year}-{datetime_dt.month:02}-{datetime_dt.day:02}'\n",
    "\n",
    "        date_within_mean_std_dicts = f'2000-{datetime_dt.month:02}-{datetime_dt.day:02}'\n",
    "\n",
    "        save_name_out = f'{save_dir}/RCI_MEM_{week_differencing}week_{save_date}.nc'\n",
    "        #We need the very first lead as our beginning point with the RCI values from the observations\n",
    "        rci_obs_to_save_over = obs_file.sel(S=date).copy(deep=True)\n",
    "        rci_obs_to_save_over.rci[1:,:,:] = 0\n",
    "        \n",
    "        #Index only starts in March of every year and we must have it after the 7th bevcause that's when accumulation begins\n",
    "        if (pd.to_datetime(date).month == 3) and (pd.to_datetime(date).day <=7):\n",
    "            rci_obs_to_save_over.rci[0,:,:] = 0\n",
    "            rci_obs_to_save_over = rci_obs_to_save_over.expand_dims({'S':1})\n",
    "            rci_obs_to_save_over.to_netcdf(f'{save_name_out}')\n",
    "            \n",
    "        elif (datetime_dt.month in [3, 4, 5, 6, 7, 8, 9, 10, 11]):\n",
    "            # break\n",
    "            \n",
    "            for idx2,lead in enumerate([6,13,20,27,34]):\n",
    "                # break\n",
    "                len_week_diff = np.arange(week_differencing)\n",
    "                \n",
    "                if idx2 in len_week_diff:\n",
    "                    #We want to grab N weeks of the observations before the init date\n",
    "                    obs_date_select = date - np.timedelta64(lead+1,'D')\n",
    "                    week_diff = (reforecast_anomaly_MEM.sel(S=date, L=lead) - obs_anomaly.rename({'SMsurf':'RZSM'}).drop('season').sel(time=obs_date_select))\n",
    "                    \n",
    "                else:\n",
    "                    #Now find the difference between the 2 weeks. The difference between the current week's forecast and the observation\n",
    "                                   #Current day                                #Previous week\n",
    "                    week_diff = reforecast_anomaly_MEM.sel(S=date, L=lead) - rci_obs_to_save_over.isel(L=idx2-week_differencing).rename({'rci':'RZSM'})\n",
    "                    \n",
    "                    #Now compute RCI\n",
    "                    rci_standardized = (week_diff - mean_diff_dict[date_within_mean_std_dicts])/ std_daily_dict[date_within_mean_std_dicts]\n",
    "                    rci_standardized.min()\n",
    "                    rci_standardized.max()\n",
    "                    rci_standardized.mean()\n",
    "                    \n",
    "                    #Now update RCI value\n",
    "                    subtract_ = xr.where(rci_standardized < -0.75,1,0)\n",
    "                    add_ = xr.where(rci_standardized > 0.75,1,0)\n",
    "                    \n",
    "                    #If the signs switch between postive and negative with RCI, then we reset rci to 0\n",
    "                    switch1 = np.where((rci_standardized.RZSM > 0) & (rci_obs_to_save_over.isel(L=idx2-1).rci.values < 0),2,0)\n",
    "                    switch2 = np.where((rci_standardized.RZSM < 0) & (rci_obs_to_save_over.isel(L=idx2-1).rci.values  > 0),2,0)\n",
    "                    \n",
    "                    sub = np.where(subtract_.RZSM.values == 1, rci_obs_to_save_over.isel(L=idx2-1).rci.values - (np.sqrt(np.abs(rci_standardized.RZSM.values) - 0.75)),0)\n",
    "                    add = np.where(add_.RZSM.values == 1,  rci_obs_to_save_over.isel(L=idx2-1).rci.values + (np.sqrt(rci_standardized.RZSM.values-0.75)),0)\n",
    "\n",
    "                    final = sub + add\n",
    "            \n",
    "                    #Now switch back the data if the signs are oppositve\n",
    "                    final = np.where(switch1 != 2, final,0)\n",
    "                    final = np.where(switch2 != 2, final,0)\n",
    "                    \n",
    "                    rci_obs_to_save_over.rci[idx2,:,:] = final\n",
    "                    \n",
    "            rci_obs_to_save_over = rci_obs_to_save_over.expand_dims({'S':1})\n",
    "            rci_obs_to_save_over.to_netcdf(f'{save_name_out}')\n",
    "                \n",
    "        else:\n",
    "            #don't need to update any dates that aren't between March through November\n",
    "            rci_obs_to_save_over.rci[0,:,:] = 0\n",
    "            rci_obs_to_save_over = rci_obs_to_save_over.expand_dims({'S':1})\n",
    "            rci_obs_to_save_over.to_netcdf(f'{save_name_out}')\n",
    "\n",
    "    return('Completed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c3bdd5de-90b1-4ab0-9436-f38eff598890",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Completed'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# UNET\n",
    "rci_reforecast_MEM(std_daily_dict=std_daily_dict, mean_diff_dict=mean_diff_dict, \n",
    "                   week_differencing = week_differencing, reforecast_anomaly_MEM=unet_anomaly.mean(dim='M'), obs_file=obs_rci.mean(dim='M'), save_dir= f'predictions/{region_name}/UNET/RCI/{experiment_name}')\n",
    "\n",
    "# Baseline reforecast GEFSv12\n",
    "rci_reforecast_MEM(std_daily_dict=std_daily_dict, mean_diff_dict=mean_diff_dict, \n",
    "                   week_differencing = week_differencing, reforecast_anomaly_MEM=gefs_anom.mean(dim='M'), obs_file=obs_rci.mean(dim='M'), save_dir= f'{source}/GEFSv12_reforecast/soilw_bgrnd/RCI')\n",
    "\n",
    "# Baseline reforecast ECMWF\n",
    "rci_reforecast_MEM(std_daily_dict=std_daily_dict, mean_diff_dict=mean_diff_dict, \n",
    "                   week_differencing = week_differencing, reforecast_anomaly_MEM=ecmwf_anom.mean(dim='M'), obs_file=obs_rci.mean(dim='M'), save_dir= f'Data/ECMWF/soilw_bgrnd_processed/{region_name}/RCI')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d201c27-7313-43f3-a64b-3556ef6e820d",
   "metadata": {},
   "source": [
    "# Now to it for each model realization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5de45763-72ac-4caa-9826-4231c24abf17",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Now calculate the RCI value based on previous observation differencing of standard deviation and day of year\n",
    "\n",
    "def rci_reforecast(std_daily_dict, mean_diff_dict,week_differencing, reforecast_anomaly, obs_file, save_dir):\n",
    "\n",
    "    os.system(f'mkdir -p {save_dir}')\n",
    "    #testing\n",
    "    # reforecast_anomaly = unet_anomaly\n",
    "                        # Lead   0   ,    1,    ,   2      ,      3    ,     4     ,      5\n",
    "    # output shape array([       nan, 0.0111007 , 0.01243984, 0.00984243, 0.01684886, 0.0191455 ])\n",
    "    \n",
    "    # obs_file = obs_rci\n",
    "    # save_dir = f'predictions/UNET/RCI/{experiment_name}'\n",
    "\n",
    "    #Now go through each init day \n",
    "\n",
    "    # reforecast_anomaly = reforecast_anomaly.rolling(L=2,min_periods=2,center=False).mean() #this is for the 1-week RCI calculation\n",
    "    # reforecast_anomaly_MEM.RZSM[0,:,10,10].values\n",
    "    \n",
    "    for idx,date in enumerate(reforecast_anomaly.S.values):\n",
    "        # break\n",
    "                \n",
    "        datetime_dt = pd.to_datetime(date)\n",
    "        save_date = f'{datetime_dt.year}-{datetime_dt.month:02}-{datetime_dt.day:02}'\n",
    "\n",
    "        date_within_mean_std_dicts = f'2000-{datetime_dt.month:02}-{datetime_dt.day:02}'\n",
    "\n",
    "        save_name_out = f'{save_dir}/RCI_{week_differencing}week_{save_date}.nc'\n",
    "        #We need the very first lead as our beginning point with the RCI values from the observations\n",
    "        rci_obs_to_save_over = obs_file.sel(S=date).copy(deep=True)\n",
    "        \n",
    "        rci_obs_to_save_over.rci[:,:,:,:] = 0\n",
    "        \n",
    "        #Index only starts in March of every year and we must have it after the 7th bevcause that's when accumulation begins\n",
    "        if (pd.to_datetime(date).month == 3) and (pd.to_datetime(date).day <=7):\n",
    "            rci_obs_to_save_over.rci[:,0,:,:] = 0\n",
    "            rci_obs_to_save_over = rci_obs_to_save_over.expand_dims({'S':1})\n",
    "            rci_obs_to_save_over.to_netcdf(f'{save_name_out}')\n",
    "            \n",
    "        elif (datetime_dt.month in [3, 4, 5, 6, 7, 8, 9, 10, 11]):\n",
    "            # break\n",
    "            \n",
    "            for idx2,lead in enumerate([6,13,20,27,34]):\n",
    "                # break\n",
    "                len_week_diff = np.arange(week_differencing)\n",
    "                \n",
    "                if idx2 in len_week_diff:\n",
    "                    #We want to grab N weeks of the observations before the init date\n",
    "                    obs_date_select = date - np.timedelta64(lead+1,'D')\n",
    "                    week_diff = (reforecast_anomaly.sel(S=date, L=lead) - obs_anomaly.rename({'SMsurf':'RZSM'}).drop('season').sel(time=obs_date_select))\n",
    "                    \n",
    "                else:\n",
    "                    #Now find the difference between the 2 weeks. The difference between the current week's forecast and the observation\n",
    "                                   #Current day                                #Previous week\n",
    "                    week_diff = reforecast_anomaly.sel(S=date, L=lead) - rci_obs_to_save_over.rci.isel(L=idx2-week_differencing)\n",
    "                    \n",
    "                #Now compute RCI\n",
    "                rci_standardized = (week_diff - mean_diff_dict[date_within_mean_std_dicts])/ std_daily_dict[date_within_mean_std_dicts]\n",
    "                rci_standardized.min()\n",
    "                rci_standardized.max()\n",
    "                rci_standardized.mean()\n",
    "                \n",
    "                try:\n",
    "                    rci_standardized = rci_standardized.drop(['L','S'])\n",
    "                except ValueError:\n",
    "                    pass\n",
    "                    \n",
    "                #Now update RCI value\n",
    "                subtract_ = xr.where(rci_standardized < -0.75,1,0)\n",
    "                add_ = xr.where(rci_standardized > 0.75,1,0)\n",
    "                \n",
    "                #If the signs switch between postive and negative with RCI, then we reset rci to 0\n",
    "                switch1 = np.where((rci_standardized[putils.xarray_varname(rci_standardized)] > 0) & (rci_obs_to_save_over.isel(L=idx2-1).rci.values < 0),2,0)\n",
    "                switch2 = np.where((rci_standardized[putils.xarray_varname(rci_standardized)]< 0) & (rci_obs_to_save_over.isel(L=idx2-1).rci.values  > 0),2,0)\n",
    "                \n",
    "                sub = np.where(subtract_.RZSM.values == 1, rci_obs_to_save_over.isel(L=idx2-1).rci.values - (np.sqrt(np.abs(rci_standardized.RZSM.values) - 0.75)),0)\n",
    "                add = np.where(add_.RZSM.values == 1,  rci_obs_to_save_over.isel(L=idx2-1).rci.values + (np.sqrt(rci_standardized.RZSM.values-0.75)),0)\n",
    "\n",
    "                final = sub + add\n",
    "        \n",
    "                #Now switch back the data if the signs are oppositve\n",
    "                final = np.where(switch1 != 2, final,0)\n",
    "                final = np.where(switch2 != 2, final,0)\n",
    "                \n",
    "                rci_obs_to_save_over.rci[:,idx2,:,:] = final\n",
    "                \n",
    "            rci_obs_to_save_over = rci_obs_to_save_over.expand_dims({'S':1})\n",
    "            rci_obs_to_save_over.to_netcdf(f'{save_name_out}')\n",
    "                    \n",
    "        else:\n",
    "            #don't need to update any dates that aren't between March through November\n",
    "            rci_obs_to_save_over.rci[:,0,:,:] = 0\n",
    "            rci_obs_to_save_over = rci_obs_to_save_over.expand_dims({'S':1})\n",
    "            rci_obs_to_save_over.to_netcdf(f'{save_name_out}')\n",
    "\n",
    "    return('Completed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "23230e40-c8f5-488d-b629-52872af61523",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Completed'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# UNET - Good for CONUS\n",
    "rci_reforecast(std_daily_dict=std_daily_dict, mean_diff_dict=mean_diff_dict, \n",
    "                   week_differencing = week_differencing, reforecast_anomaly=unet_anomaly, obs_file=obs_rci, save_dir= f'predictions/{region_name}/UNET/RCI/{experiment_name}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9aa9658c-b03b-4d6b-aca5-90bdce4dc9ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Completed'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Baseline reforecast GEFS - Good for CONUS\n",
    "rci_reforecast(std_daily_dict=std_daily_dict, mean_diff_dict=mean_diff_dict, \n",
    "                   week_differencing = week_differencing, reforecast_anomaly=gefs_anom, obs_file=obs_rci, save_dir= f'{source}/GEFSv12_reforecast/soilw_bgrnd/RCI')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "872f84df-04c4-4d4d-a241-1dc3b707d387",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Completed'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Baseline reforecast ECMWF\n",
    "rci_reforecast(std_daily_dict=std_daily_dict, mean_diff_dict=mean_diff_dict, \n",
    "                   week_differencing = week_differencing, reforecast_anomaly=ecmwf_anom, obs_file=obs_rci, save_dir= f'Data/ECMWF/soilw_bgrnd_processed/{region_name}/RCI')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c241f88-7831-4ffc-9ec2-73dc215db752",
   "metadata": {},
   "source": [
    "# Now do a case study of 2019 Southeast Flash Drought (ensemble mean only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "32036abc-517d-44e3-883a-755aaac88da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_rci\n",
    "\n",
    "unet_rci = xr.open_mfdataset(f'predictions/{region_name}/UNET/RCI/{experiment_name}/RCI_MEM_{week_differencing}*').sel(L=[20,27,34]).load()\n",
    "baseline_rci = xr.open_mfdataset(f'{source}/GEFSv12_reforecast/soilw_bgrnd/RCI/RCI_MEM_{week_differencing}*').sel(L=[20,27,34]).load()\n",
    "ecmwf_rci = xr.open_mfdataset(f'Data/ECMWF/soilw_bgrnd_processed/{region_name}/RCI/RCI_MEM_{week_differencing}*').sel(L=[20,27,34]).load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8a6216ba-fb41-441c-9a9e-06bdfe9de8a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dates\n",
    "start_ = '2019-08-01'\n",
    "end_ = '2019-10-30'\n",
    "\n",
    "obs = obs_rci.sel(S=slice(start_,end_)).mean(dim='M')\n",
    "unet = unet_rci.sel(S=slice(start_,end_))\n",
    "baseline = baseline_rci.sel(S=slice(start_,end_))\n",
    "ecmwf = ecmwf_rci.sel(S=slice(start_,end_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "654c50f7-d74e-4197-9f73-b4a4c8d1fe81",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Mask with np.nan for non-CONUS land values\n",
    "mask_anom = mask['NCA-LDAS_mask'][0,:,:].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "05171fed-6c3b-4efa-a08d-b64439e446e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "if region_name == 'CONUS':\n",
    "    obs = xr.where(mask_anom ==1, obs,np.nan).sel(L=[20,27,34])\n",
    "    unet = xr.where(mask_anom ==1, unet,np.nan)\n",
    "    baseline = xr.where(mask_anom ==1, baseline,np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "93d91159-e655-4f49-9c98-c3b4b9630eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_min_max_of_files(obs, unet, baseline, ecmwf, date):\n",
    "    #test \n",
    "    # date = '2019-08-07'\n",
    "    \n",
    "    min_ = []\n",
    "    max_ = []\n",
    "\n",
    "    min_.append(np.nanmin(obs.sel(S=date).rci.values))\n",
    "    min_.append(np.nanmin(unet.sel(S=date).rci.values))\n",
    "    min_.append(np.nanmin(baseline.sel(S=date).rci.values))\n",
    "    min_.append(np.nanmin(ecmwf.sel(S=date).rci.values))\n",
    "    \n",
    "    max_.append(np.nanmax(obs.sel(S=date).rci.values))\n",
    "    max_.append(np.nanmax(unet.sel(S=date).rci.values))\n",
    "    max_.append(np.nanmax(baseline.sel(S=date).rci.values))\n",
    "    max_.append(np.nanmax(ecmwf.sel(S=date).rci.values))\n",
    "    \n",
    "    return(min(min_),max(max_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9e1c365e-e15c-4451-8374-f583a85360dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_array(file,lead,date):\n",
    "    return(file.isel(L=lead).sel(S=date).rci.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9309d37f-b99a-4f2b-baec-f280b46e74b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "   \n",
    "# cmap = 'coolwarm'\n",
    "def plot_case_study_rci(obs, unet, baseline, ecmwf, init_date):\n",
    "    cmap = plt.get_cmap('bwr')    \n",
    "    \n",
    "    save_dir = f'Outputs/Case_studies/Southeast_US/RCI'\n",
    "    os.system(f'mkdir -p {save_dir}')\n",
    "        \n",
    "    fig, axs = plt.subplots(\n",
    "        nrows = 3, ncols= 4, subplot_kw={'projection': ccrs.PlateCarree()}, figsize=(15, 10))\n",
    "    axs = axs.flatten()\n",
    "    \n",
    "    init_date = pd.to_datetime(init_date)\n",
    "    date = f'{init_date.year}-{init_date.month:02}-{init_date.day:02}'\n",
    "    \n",
    "    min_,max_ = get_min_max_of_files(obs, unet, baseline, ecmwf,date)\n",
    "    # test_file = mae_rzsm_keys\n",
    "    # for Subx original data\n",
    "    v = np.linspace(-3, 3, 20, endpoint=True)\n",
    "\n",
    "    pos = [i for i in v if i > 0]\n",
    "    neg = [i for i in v if i < 0]\n",
    "\n",
    "    neg.append(0)\n",
    "    v = neg + pos\n",
    "    \n",
    "    lon = obs.X.values\n",
    "    lat = obs.Y.values\n",
    "    \n",
    "    axs_start = 0\n",
    "    for index_, lead in enumerate([20,27,34]):\n",
    "        for data_to_plot,name in zip([obs, unet, baseline,ecmwf], ['GLEAM','UNET','GEFSv12','ECMWF']):\n",
    "            # break\n",
    "            data = return_array(file=data_to_plot,lead=index_, date=date)\n",
    "        \n",
    "            map = Basemap(projection='cyl', llcrnrlat=25, urcrnrlat=50,\n",
    "                          llcrnrlon=-128, urcrnrlon=-60, resolution='l')\n",
    "            x, y = map(*np.meshgrid(lon, lat))\n",
    "            # Adjust the text coordinates based on the actual data coordinates\n",
    "        \n",
    "            norm = TwoSlopeNorm(vmin=v[0], vcenter=0, vmax=v[-1])\n",
    "        \n",
    "            im = axs[axs_start].contourf(x, y, data, levels=v, extend='both',\n",
    "                                  transform=ccrs.PlateCarree(), cmap=cmap,norm=norm)\n",
    "    \n",
    "    \n",
    "            # axs[idx].title.set_text(f'SubX Lead {lead*7}')\n",
    "            gl = axs[axs_start].gridlines(crs=ccrs.PlateCarree(), draw_labels=True,\n",
    "                                       linewidth=0.7, color='gray', alpha=0.5, linestyle='--')\n",
    "            gl.xlabels_top = False\n",
    "            gl.ylabels_right = False\n",
    "            if lead != 1:\n",
    "                gl.ylabels_left = False\n",
    "            gl.xformatter = LongitudeFormatter()\n",
    "            gl.yformatter = LatitudeFormatter()\n",
    "            axs[axs_start].coastlines()\n",
    "            # plt.colorbar(im)\n",
    "            # axs[idx].set_aspect('auto', adjustable=None)\n",
    "            axs[axs_start].set_aspect('equal')  # this makes the plots better\n",
    "            axs[axs_start].set_title(f'{name} Lead {lead}',fontsize=15)\n",
    "            axs_start+=1\n",
    "    cbar_ax = fig.add_axes([0.05, -0.05, .9, .04])\n",
    "    \n",
    "    # Draw the colorbar\n",
    "    cbar = fig.colorbar(im, cax=cbar_ax, orientation='horizontal')\n",
    "    fig.suptitle(f'Init date: {date}', fontsize=30)\n",
    "    fig.tight_layout()\n",
    "    \n",
    "    plt.savefig(f'{save_dir}/Southeast_{week_differencing}week_RCI_init{date}.png',bbox_inches='tight')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a8f5c16-5212-4017-86c4-b18741bff1e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for init_date in obs.S.values:\n",
    "    plot_case_study_rci(obs, unet, baseline, ecmwf, init_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ea687f36-b937-4efa-aaad-8f99d20d0614",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1610507816.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[28], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    End script here\u001b[0m\n\u001b[0m        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "End script here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "900253c8-c1c0-4da9-9b70-3386dfebd7fc",
   "metadata": {},
   "source": [
    "# Plot anomaly for 2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1066045-7934-4406-9df6-ee43bcd2923e",
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_anomaly_mf = xr.open_mfdataset('Data/GLEAM/RZSM_anomaly_reformat_SubX_format/RZSM_anomaly*.nc4').sel(L=[20,27,34]).load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53e7782c-ebd1-405f-8b07-5233e296417d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae561a1b-40c5-4933-bc50-c591e9217140",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_min_max_of_files_anomaly(obs, unet, baseline, date):\n",
    "    #test \n",
    "    # date = '2019-08-07'\n",
    "    \n",
    "    min_ = []\n",
    "    max_ = []\n",
    "\n",
    "    min_.append(obs.sel(S=date).min().RZSM.values)\n",
    "    min_.append(unet.sel(S=date).min().RZSM.values)\n",
    "    min_.append(baseline.sel(S=date).min().RZSM.values)\n",
    "\n",
    "    max_.append(obs.sel(S=date).max().RZSM.values)\n",
    "    max_.append(unet.sel(S=date).max().RZSM.values)\n",
    "    max_.append(baseline.sel(S=date).max().RZSM.values)\n",
    "\n",
    "    return(min(min_),max(max_))\n",
    "\n",
    "def return_array_anomaly(file,lead,date):\n",
    "    return(file.sel(L=lead,S=date).RZSM.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d38a710f-3228-4a0c-b1a1-64f09ec6921a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "   \n",
    "# cmap = 'coolwarm'\n",
    "def plot_case_study_anomaly(obs, unet, baseline, init_date, year):\n",
    "\n",
    "    text_x = -83.5\n",
    "    text_y = 27\n",
    "    font_size_corr = 12\n",
    "    \n",
    "    cmap = plt.get_cmap('bwr')    \n",
    "    # Create a diverging color scale using RdBu colormap\n",
    "    cmap = plt.get_cmap('RdBu')\n",
    "    if year == 2019:\n",
    "        save_dir = f'Outputs/Case_studies/Southeast_US/anomaly'\n",
    "    elif year == 2017:\n",
    "        save_dir = f'Outputs/Case_studies/High_Plains/anomaly'\n",
    "    elif year == 2012:\n",
    "        save_dir = f'Outputs/Case_studies/Central_US/anomaly'\n",
    "        \n",
    "    os.system(f'mkdir -p {save_dir}')\n",
    "        \n",
    "    fig, axs = plt.subplots(\n",
    "        nrows = 3, ncols= 3, subplot_kw={'projection': ccrs.PlateCarree()}, figsize=(15, 10))\n",
    "    axs = axs.flatten()\n",
    "    \n",
    "    init_date = pd.to_datetime(init_date)\n",
    "    date = f'{init_date.year}-{init_date.month:02}-{init_date.day:02}'\n",
    "    \n",
    "    min_,max_ = get_min_max_of_files_anomaly(obs, unet, baseline, date)\n",
    "    # test_file = mae_rzsm_keys\n",
    "    # for Subx original data\n",
    "    \n",
    "    lon = obs.X.values\n",
    "    lat = obs.Y.values\n",
    "    \n",
    "    axs_start = 0\n",
    "    for lead in [20,27,34]:\n",
    "        for data_to_plot,name in zip([obs, unet, baseline], ['GLEAM','UNET','Baseline']):\n",
    "            # break\n",
    "            data = return_array_anomaly(file=data_to_plot,lead=lead, date=date)\n",
    "    \n",
    "            v = np.linspace(min_, max_, 20, endpoint=True)\n",
    "        \n",
    "            map = Basemap(projection='cyl', llcrnrlat=25, urcrnrlat=50,\n",
    "                          llcrnrlon=-128, urcrnrlon=-60, resolution='l')\n",
    "            x, y = map(*np.meshgrid(lon, lat))\n",
    "            # Adjust the text coordinates based on the actual data coordinates\n",
    "        \n",
    "            norm = TwoSlopeNorm(vmin=min_, vcenter=0, vmax=max_)\n",
    "        \n",
    "            im = axs[axs_start].contourf(x, y, data, levels=v, extend='both',\n",
    "                                  transform=ccrs.PlateCarree(), cmap=cmap,norm=norm)\n",
    "    \n",
    "    \n",
    "            # axs[idx].title.set_text(f'SubX Lead {lead*7}')\n",
    "            gl = axs[axs_start].gridlines(crs=ccrs.PlateCarree(), draw_labels=True,\n",
    "                                       linewidth=0.7, color='gray', alpha=0.5, linestyle='--')\n",
    "            gl.xlabels_top = False\n",
    "            gl.ylabels_right = False\n",
    "            if lead != 1:\n",
    "                gl.ylabels_left = False\n",
    "            gl.xformatter = LongitudeFormatter()\n",
    "            gl.yformatter = LatitudeFormatter()\n",
    "            axs[axs_start].coastlines()\n",
    "            # plt.colorbar(im)\n",
    "            # axs[idx].set_aspect('auto', adjustable=None)\n",
    "            axs[axs_start].set_aspect('equal')  # this makes the plots better\n",
    "            axs[axs_start].set_title(f'{name} Lead {lead}',fontsize=15)\n",
    "\n",
    "            if name in ['UNET','Baseline']:\n",
    "                # Calculate the Pearson correlation coefficient\n",
    "                obs_corr = return_array_anomaly(file=obs,lead=lead, date=date).flatten()\n",
    "                data_corr = data.flatten()\n",
    "\n",
    "                data_corr = data_corr[~np.isnan(obs_corr)]\n",
    "                obs_corr = obs_corr[~np.isnan(obs_corr)]\n",
    "                \n",
    "                correlation_matrix = np.corrcoef(obs_corr, data_corr)\n",
    "                # The correlation coefficient is in the top right corner of the correlation matrix\n",
    "                correlation_coefficient = correlation_matrix[0, 1]\n",
    "                correlation_coefficient = round(correlation_coefficient,4)\n",
    "                #find the correlation coefficient across the dataset\n",
    "                axs[axs_start].text(text_x, text_y, f'Corr: {correlation_coefficient}', ha='right', va='bottom', fontsize=font_size_corr, color='blue', weight = 'bold')\n",
    "            \n",
    "            \n",
    "            axs_start+=1\n",
    "            \n",
    "    cbar_ax = fig.add_axes([0.05, -0.05, .9, .04])\n",
    "    \n",
    "    # Draw the colorbar\n",
    "    cbar = fig.colorbar(im, cax=cbar_ax, orientation='horizontal')\n",
    "    fig.suptitle(f'Init date: {date}', fontsize=30)\n",
    "    fig.tight_layout()\n",
    "\n",
    "    plt.savefig(f'{save_dir}/init_{date}_anomaly.png',bbox_inches='tight')\n",
    "    \n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffa97f09-5c26-4510-9a35-b89de9cf5150",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8efc376b-16da-41b1-a306-647be5dc78bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dates\n",
    "start_ = '2019-08-01'\n",
    "end_ = '2019-10-30'\n",
    "\n",
    "\n",
    "obs_anom = obs_anomaly_mf.sel(S=slice(start_,end_)).mean(dim='M')\n",
    "unet_anom = unet_anomaly.sel(S=slice(start_,end_)).mean(dim='M')\n",
    "baseline_anom = baseline_anomaly.sel(S=slice(start_,end_)).mean(dim='M')\n",
    "\n",
    "obs_anom = xr.where(mask_anom ==1, obs_anom,np.nan).sel(L=[20,27,34])\n",
    "unet_anom = xr.where(mask_anom ==1, unet_anom,np.nan).sel(L=[20,27,34])\n",
    "baseline_anom = xr.where(mask_anom ==1, baseline_anom,np.nan).sel(L=[20,27,34])\n",
    "\n",
    "unet_anom = xr.where(~np.isnan(obs_anom), unet_anom,np.nan)\n",
    "baseline_anom = xr.where(~np.isnan(obs_anom), baseline_anom,np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "440cf6ad-56ca-4b1f-94f6-9595ccda8093",
   "metadata": {},
   "outputs": [],
   "source": [
    "for init_date in obs_anom.S.values:\n",
    "    plot_case_study_anomaly(obs=obs_anom, unet=unet_anom, baseline=baseline_anom, init_date=init_date, year=2019)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b83a870f-5bc3-4e80-ac2f-64d45f13098f",
   "metadata": {},
   "source": [
    "# 2017 Flash Drought"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80b072e7-a415-463c-bd1d-5466665c0d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dates\n",
    "start_ = '2017-04-01'\n",
    "end_ = '2017-08-30'\n",
    "\n",
    "\n",
    "obs_anom = obs_anomaly_mf.sel(S=slice(start_,end_)).mean(dim='M')\n",
    "unet_anom = unet_anomaly.sel(S=slice(start_,end_)).mean(dim='M')\n",
    "baseline_anom = baseline_anomaly.sel(S=slice(start_,end_)).mean(dim='M')\n",
    "\n",
    "#Masking on ocean areas\n",
    "obs_anom = xr.where(mask_anom ==1, obs_anom,np.nan).sel(L=[20,27,34])\n",
    "unet_anom = xr.where(mask_anom ==1, unet_anom,np.nan).sel(L=[20,27,34])\n",
    "baseline_anom = xr.where(mask_anom ==1, baseline_anom,np.nan).sel(L=[20,27,34])\n",
    "\n",
    "#Further masking of grid cells within CONUS that aren't in GlEAM\n",
    "unet_anom = xr.where(~np.isnan(obs_anom), unet_anom,np.nan)\n",
    "baseline_anom = xr.where(~np.isnan(obs_anom), baseline_anom,np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb654d16-3503-4382-b778-edd2a5029abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "for init_date in obs_anom.S.values:\n",
    "    plot_case_study_anomaly(obs=obs_anom, unet=unet_anom, baseline=baseline_anom, init_date=init_date, year = 2017)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "580fa655-3278-4f2f-8a18-1605d8340d6d",
   "metadata": {},
   "source": [
    "# 2012 Flash Drought"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33590834-493c-4f76-94ec-10964a9d95d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dates\n",
    "start_ = '2012-04-01'\n",
    "end_ = '2012-06-30'\n",
    "\n",
    "\n",
    "obs_anom = obs_anomaly_mf.sel(S=slice(start_,end_)).mean(dim='M')\n",
    "unet_anom = unet_anomaly.sel(S=slice(start_,end_)).mean(dim='M')\n",
    "baseline_anom = baseline_anomaly.sel(S=slice(start_,end_)).mean(dim='M')\n",
    "\n",
    "#Masking on ocean areas\n",
    "obs_anom = xr.where(mask_anom ==1, obs_anom,np.nan).sel(L=[20,27,34])\n",
    "unet_anom = xr.where(mask_anom ==1, unet_anom,np.nan).sel(L=[20,27,34])\n",
    "baseline_anom = xr.where(mask_anom ==1, baseline_anom,np.nan).sel(L=[20,27,34])\n",
    "\n",
    "#Further masking of grid cells within CONUS that aren't in GlEAM\n",
    "unet_anom = xr.where(~np.isnan(obs_anom), unet_anom,np.nan)\n",
    "baseline_anom = xr.where(~np.isnan(obs_anom), baseline_anom,np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89e1cba7-ac82-4cbf-be5b-af34e5d6f779",
   "metadata": {},
   "outputs": [],
   "source": [
    "for init_date in obs_anom.S.values:\n",
    "    plot_case_study_anomaly(obs=obs_anom, unet=unet_anom, baseline=baseline_anom, init_date=init_date, year = 2012)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e47d545-38f5-4af7-81ba-fc612080c939",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tf212gpu]",
   "language": "python",
   "name": "conda-env-tf212gpu-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "toc-autonumbering": true,
  "toc-showcode": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
