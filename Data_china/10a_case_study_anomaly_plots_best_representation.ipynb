{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7302f239-5aba-4164-8125-86df134c9bd5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-25 07:39:12.631091: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-01-25 07:39:15.252652: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-01-25 07:39:33.120345: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/glade/work/klesinger/conda-envs/tf212gpu/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%reload_ext autoreload\n",
    "\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import os\n",
    "from glob import glob\n",
    "import functions as f\n",
    "#import climpredNEW.climpred \n",
    "#from climpredNEW.climpred.options import OPTIONS\n",
    "from mpl_toolkits.basemap import Basemap\n",
    "from numpy import meshgrid\n",
    "from mpl_toolkits.axes_grid1.axes_divider import make_axes_locatable\n",
    "import matplotlib.colors as mcolors\n",
    "import cartopy.feature as cfeature\n",
    "import itertools\n",
    "import cartopy.crs as ccrs\n",
    "from cartopy.mpl.ticker import LongitudeFormatter, LatitudeFormatter, LatitudeLocator\n",
    "import matplotlib.ticker as mticker\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap, TwoSlopeNorm\n",
    "import pandas as pd\n",
    "import math\n",
    "from scipy.stats import percentileofscore as pos\n",
    "from datetime import datetime\n",
    "import datetime as dt\n",
    "from multiprocessing import Pool\n",
    "from sklearn.metrics import confusion_matrix as CM\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "612950b1-1fcf-4522-b79c-7d85f090e726",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Set script parameters\n",
    "CONUS_mask = f.load_CONUS_mask() #Mask of CONUS which serves as our bounding box. Can later change this to a larger file but then we would have to edit the data from the previous scripts. \n",
    "\n",
    "max_RZSM_reforecast, min_RZSM_reforecast = f.load_reforecast_min_max_RZSM()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42762c4a-b6c6-4895-9afd-1cc842efcd01",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4f22a301-ea93-4430-ba3f-1e2578b4132a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dates\n",
    "start_ = '2019-08-01'\n",
    "end_ = '2019-10-30'\n",
    "\n",
    "southeast_lat_bottom  = 30\n",
    "southeast_lat_top = 38\n",
    "\n",
    "southeast_lon_left  = 267\n",
    "southeast_lon_right = 282\n",
    "\n",
    "#Mask with np.nan for non-CONUS land values\n",
    "mask_anom = CONUS_mask['NCA-LDAS_mask'][0,:,:].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a3b92cbf-1ad7-404f-9023-7afc6cffd989",
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_anomaly_SubX_format =xr.open_mfdataset('Data/GLEAM/RZSM_anomaly_reformat_SubX_format/RZSM_anomaly*.nc4').sel(L=[0,6,13,20,27,34]).astype(np.float32).load()\n",
    "\n",
    "obs_anomaly_SubX_format_subset = obs_anomaly_SubX_format.sel(S=slice(start_,end_)).sel(X=slice(southeast_lon_left,southeast_lon_right)).sel(Y=slice(southeast_lat_top,southeast_lat_bottom)).mean(dim='M')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "018264b1-cba8-471f-b594-58ec3695f281",
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################################   Reforecast baseline files   ###########################################################################\n",
    "baseline_anomaly_file_list = sorted(glob('Data/GEFSv12_reforecast/soilw_bgrnd/baseline_RZSM_anomaly/RZSM*.nc'))\n",
    "baseline_anomaly = xr.open_mfdataset(baseline_anomaly_file_list).sel(L=[0,6,13,20,27,34]).astype(np.float32).load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2b077ad-64b1-4a61-9c59-e537a02157f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = xr.open_mfdataset('Data/GLEAM/reformat_to_reforecast_shape/RZSM_weighted/*.nc4').sel(L=[0,6,13,20,27,34]).astype(np.float32).load()\n",
    "\n",
    "template_testing_only = template.sel(S=slice('2018-01-01','2019-12-31'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "519c2a8a-7be0-4b47-abd5-daa174832de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_anomaly_SubX_format_lead20 = obs_anomaly_SubX_format_subset.sel(L=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "c380dd50-9716-4ffc-820f-ab10a7c168b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_reforecast_with_predictions_week3(experiment_list,lead_day):\n",
    "    #Load previous predictions from experiments\n",
    "    temp_cp = template_testing_only.copy(deep=True).sel(L=lead_day)\n",
    "    \n",
    "    for idx,lead in enumerate([3]):\n",
    "\n",
    "        test = f.reverse_min_max_scaling(np.load(f'predictions/Wk_{lead}_testing/Wk{lead}_testing_{experiment_list[idx]}.npy')[2,:,:,:,0],max_RZSM_reforecast, min_RZSM_reforecast)\n",
    "        test = np.reshape(test,(test.shape[0]//11,11,test.shape[1],test.shape[2]))\n",
    "\n",
    "        #Apply CONUS mask \n",
    "        test = np.where(mask_anom == 1, test, np.nan)\n",
    "        \n",
    "        #Add data to file\n",
    "        temp_cp.RZSM[:,:,:,:] = test\n",
    "\n",
    "    #Mask the Southeast \n",
    "    temp_cp = temp_cp.sel(X=slice(southeast_lon_left,southeast_lon_right)).sel(Y=slice(southeast_lat_top,southeast_lat_bottom)).mean(dim='M')\n",
    "    temp_cp = temp_cp.sel(S=slice(start_,end_))\n",
    "    \n",
    "    return(temp_cp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5efae0b1-c567-432e-9eae-1be410aea545",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create the UNET prediction dataset to do other functions\n",
    "experiment_list = ['EX10_denseLossRZSM','EX20_RZSM','EX20_RZSM','EX20_RZSM','EX20_RZSM','EX26_RZSM'] #Best model outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4daa2128-7bb7-441e-a1f6-677834541590",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Different configurations\n",
    "\n",
    "wk0 = [f'EX{i}_RZSM' for i in range(13)]\n",
    "wk1 = [f'EX{i}_RZSM' for i in range(26)]\n",
    "wk2 = [f'EX{i}_RZSM' for i in range(26)]\n",
    "wk3 = [f'EX{i}_RZSM' for i in range(26)]\n",
    "wk4a = [f'EX{i}_RZSM' for i in range(12)]\n",
    "wk4b = [f'EX{i}_RZSM' for i in range(13,26)]\n",
    "wk4 = wk4a + wk4b\n",
    "wk5 = ['EX26_RZSM']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "2e49bca1-25db-4ac7-8db8-3f8a24b0e7a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "mae_unet_out = {}\n",
    "for d in wk3:\n",
    "    experiment_list = [d]\n",
    "    unet = create_reforecast_with_predictions_week3(experiment_list)\n",
    "    unet = unet.assign_coords({'S':obs_anomaly_SubX_format_lead20.S.values})\n",
    "    one_init_date = obs_anomaly_SubX_format_lead20.S.values[4]\n",
    "    \n",
    "    obs_corr = obs_anomaly_SubX_format_lead20.sel(S=one_init_date).RZSM.values\n",
    "    unet_corr = unet.sel(S=one_init_date).RZSM.values\n",
    "\n",
    "    \n",
    "\n",
    "    mae = np.nanmean(np.abs(obs_corr - unet_corr))\n",
    "    mae_unet_out[d] = mae\n",
    "\n",
    "##Baseline GEFSv12 forecast\n",
    "base_corr = baseline_anomaly.sel(S=one_init_date).mean(dim='M').sel(L=20).sel(X=slice(southeast_lon_left,southeast_lon_right)).sel(Y=slice(southeast_lat_top,southeast_lat_bottom)).RZSM.values\n",
    "base_corr = np.where(~np.isnan(obs_corr),base_corr,np.nan)\n",
    "\n",
    "mae = np.nanmean(np.abs(obs_corr - base_corr))\n",
    "mae_unet_out['Baseline']=mae\n",
    "\n",
    "#final  results for week 3:. Baseline is still better than UNET for extreme flash drought events (single day forecasts from \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "728e67ef-e3f8-4b13-900f-7ec7b862eba3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "a6e6870c-2a92-4ba8-bc46-0ce63e0fdd83",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[152], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m f1 \u001b[38;5;129;01min\u001b[39;00m wk5:\n\u001b[1;32m      8\u001b[0m     experiment_list \u001b[38;5;241m=\u001b[39m [a,b,c,d,e,f1]\n\u001b[0;32m----> 9\u001b[0m     unet \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_reforecast_with_predictions\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexperiment_list\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m     unet \u001b[38;5;241m=\u001b[39m unet\u001b[38;5;241m.\u001b[39massign_coords({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mS\u001b[39m\u001b[38;5;124m'\u001b[39m:obs_anomaly_SubX_format_lead20\u001b[38;5;241m.\u001b[39mS\u001b[38;5;241m.\u001b[39mvalues})\n\u001b[1;32m     11\u001b[0m     one_init_date \u001b[38;5;241m=\u001b[39m obs_anomaly_SubX_format_lead20\u001b[38;5;241m.\u001b[39mS\u001b[38;5;241m.\u001b[39mvalues[\u001b[38;5;241m4\u001b[39m]\n",
      "Cell \u001b[0;32mIn[136], line 11\u001b[0m, in \u001b[0;36mcreate_reforecast_with_predictions\u001b[0;34m(experiment_list)\u001b[0m\n\u001b[1;32m      8\u001b[0m test \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mreshape(test,(test\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m11\u001b[39m,\u001b[38;5;241m11\u001b[39m,test\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m],test\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m2\u001b[39m]))\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m#Apply CONUS mask \u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m test \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwhere\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmask_anom\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnan\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m#Add data to file\u001b[39;00m\n\u001b[1;32m     14\u001b[0m temp_cp\u001b[38;5;241m.\u001b[39mRZSM[:,:,lead,:,:] \u001b[38;5;241m=\u001b[39m test\n",
      "File \u001b[0;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mwhere\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#This would be for all the experiments. ~5 milion combinations. But we only need a single week\n",
    "\n",
    "mae_min = 0\n",
    "for a in wk0:\n",
    "    for b in wk1:\n",
    "        for c in wk2:\n",
    "            for d in wk3:\n",
    "                for e in wk4:\n",
    "                    for f1 in wk5:\n",
    "                        experiment_list = [a,b,c,d,e,f1]\n",
    "                        unet = create_reforecast_with_predictions(experiment_list)\n",
    "                        unet = unet.assign_coords({'S':obs_anomaly_SubX_format_lead20.S.values})\n",
    "                        one_init_date = obs_anomaly_SubX_format_lead20.S.values[4]\n",
    "                        obs_corr = obs_anomaly_SubX_format_lead20.sel(S=one_init_date).RZSM.values\n",
    "                        unet_corr = unet.sel(S=one_init_date).RZSM.values\n",
    "\n",
    "                        mae = np.nanmean(np.abs(obs_corr - unet_corr))\n",
    "\n",
    "                        # #Mask np.nan values\n",
    "                        # data_corr = obs_corr[~np.isnan(obs_corr)]\n",
    "                        # unet_corr = unet_corr[~np.isnan(obs_corr)]\n",
    "\n",
    "                        # unet_corr1 = unet_corr[~np.isnan(unet_corr)]\n",
    "                        # data_corr1 = data_corr[~np.isnan(unet_corr)]\n",
    "                        \n",
    "                        # correlation_matrix = np.corrcoef(data_corr1, unet_corr1)\n",
    "                        # # The correlation coefficient is in the top right corner of the correlation matrix\n",
    "                        # correlation_coefficient = correlation_matrix[0, 1]\n",
    "                        # correlation_coefficient = round(correlation_coefficient,4)\n",
    "\n",
    "                        if mae < mae_min:\n",
    "                            mae_min = mae\n",
    "                            best_experiment_list = [a,b,c,d,e,f1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08d30a78-e51b-4437-9c0f-10741cf412a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_experiment_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c520e29-0e2c-4817-87a0-f728f9d94fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "mae_min"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c241f88-7831-4ffc-9ec2-73dc215db752",
   "metadata": {},
   "source": [
    "# Now do a case study of 2019 Southeast Flash Drought (ensemble mean only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "654c50f7-d74e-4197-9f73-b4a4c8d1fe81",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "id": "05171fed-6c3b-4efa-a08d-b64439e446e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "obs = xr.where(mask_anom ==1, obs,np.nan).sel(L=[20,27,34])\n",
    "unet = xr.where(mask_anom ==1, unet,np.nan)\n",
    "baseline = xr.where(mask_anom ==1, baseline,np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "id": "93d91159-e655-4f49-9c98-c3b4b9630eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_min_max_of_files(obs, unet, baseline, date):\n",
    "    #test \n",
    "    # date = '2019-08-07'\n",
    "    \n",
    "    min_ = []\n",
    "    max_ = []\n",
    "\n",
    "    min_.append(obs.sel(S=date).min().rci.values)\n",
    "    min_.append(unet.sel(S=date).min().rci.values)\n",
    "    min_.append(baseline.sel(S=date).min().rci.values)\n",
    "\n",
    "    max_.append(obs.sel(S=date).max().rci.values)\n",
    "    max_.append(unet.sel(S=date).max().rci.values)\n",
    "    max_.append(baseline.sel(S=date).max().rci.values)\n",
    "\n",
    "    return(min(min_),max(max_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "id": "9e1c365e-e15c-4451-8374-f583a85360dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_array(file,lead,date):\n",
    "    return(file.sel(L=lead,S=date).rci.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "900253c8-c1c0-4da9-9b70-3386dfebd7fc",
   "metadata": {},
   "source": [
    "# Plot anomaly for 2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a1066045-7934-4406-9df6-ee43bcd2923e",
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_anomaly_mf = xr.open_mfdataset('Data/GLEAM/RZSM_anomaly_reformat_SubX_format/RZSM_anomaly*.nc4').sel(L=[20,27,34]).load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "53e7782c-ebd1-405f-8b07-5233e296417d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "obs_anom = obs_anomaly_mf.sel(S=slice(start_,end_)).mean(dim='M')\n",
    "unet_anom = unet_anomaly.sel(S=slice(start_,end_)).mean(dim='M')\n",
    "baseline_anom = baseline_anomaly.sel(S=slice(start_,end_)).mean(dim='M')\n",
    "\n",
    "obs_anom = xr.where(mask_anom ==1, obs_anom,np.nan).sel(L=[20,27,34])\n",
    "unet_anom = xr.where(mask_anom ==1, unet_anom,np.nan).sel(L=[20,27,34])\n",
    "baseline_anom = xr.where(mask_anom ==1, baseline_anom,np.nan).sel(L=[20,27,34])\n",
    "\n",
    "unet_anom = xr.where(~np.isnan(obs_anom), unet_anom,np.nan)\n",
    "baseline_anom = xr.where(~np.isnan(obs_anom), baseline_anom,np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ae561a1b-40c5-4933-bc50-c591e9217140",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_min_max_of_files_anomaly(obs, unet, baseline, date):\n",
    "    #test \n",
    "    # date = '2019-08-07'\n",
    "    \n",
    "    min_ = []\n",
    "    max_ = []\n",
    "\n",
    "    min_.append(obs.sel(S=date).min().RZSM.values)\n",
    "    min_.append(unet.sel(S=date).min().RZSM.values)\n",
    "    min_.append(baseline.sel(S=date).min().RZSM.values)\n",
    "\n",
    "    max_.append(obs.sel(S=date).max().RZSM.values)\n",
    "    max_.append(unet.sel(S=date).max().RZSM.values)\n",
    "    max_.append(baseline.sel(S=date).max().RZSM.values)\n",
    "\n",
    "    return(min(min_),max(max_))\n",
    "\n",
    "def return_array_anomaly(file,lead,date):\n",
    "    return(file.sel(L=lead,S=date).RZSM.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "718ae27e-241c-4f65-8e2a-7fadd48859c9",
   "metadata": {},
   "source": [
    "# Loop over each experiment to find the best ones which represent only the Southeast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d38a710f-3228-4a0c-b1a1-64f09ec6921a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "   \n",
    "# cmap = 'coolwarm'\n",
    "def plot_case_study_anomaly(obs, unet, baseline, init_date):\n",
    "\n",
    "    text_x = -83.5\n",
    "    text_y = 27\n",
    "    font_size_corr = 12\n",
    "    \n",
    "    cmap = plt.get_cmap('bwr')    \n",
    "    \n",
    "    save_dir = f'Outputs/Case_studies/Southeast_US/anomaly'\n",
    "    os.system(f'mkdir -p {save_dir}')\n",
    "        \n",
    "    fig, axs = plt.subplots(\n",
    "        nrows = 3, ncols= 3, subplot_kw={'projection': ccrs.PlateCarree()}, figsize=(15, 10))\n",
    "    axs = axs.flatten()\n",
    "    \n",
    "    init_date = pd.to_datetime(init_date)\n",
    "    date = f'{init_date.year}-{init_date.month:02}-{init_date.day:02}'\n",
    "    \n",
    "    min_,max_ = get_min_max_of_files_anomaly(obs, unet, baseline, date)\n",
    "    # test_file = mae_rzsm_keys\n",
    "    # for Subx original data\n",
    "    \n",
    "    lon = obs.X.values\n",
    "    lat = obs.Y.values\n",
    "    \n",
    "    axs_start = 0\n",
    "    for lead in [20,27,34]:\n",
    "        for data_to_plot,name in zip([obs, unet, baseline], ['GLEAM','UNET','Baseline']):\n",
    "            # break\n",
    "            data = return_array_anomaly(file=data_to_plot,lead=lead, date=date)\n",
    "    \n",
    "            v = np.linspace(min_, max_, 20, endpoint=True)\n",
    "        \n",
    "            map = Basemap(projection='cyl', llcrnrlat=25, urcrnrlat=50,\n",
    "                          llcrnrlon=-128, urcrnrlon=-60, resolution='l')\n",
    "            x, y = map(*np.meshgrid(lon, lat))\n",
    "            # Adjust the text coordinates based on the actual data coordinates\n",
    "        \n",
    "            norm = TwoSlopeNorm(vmin=min_, vcenter=0, vmax=max_)\n",
    "        \n",
    "            im = axs[axs_start].contourf(x, y, data, levels=v, extend='both',\n",
    "                                  transform=ccrs.PlateCarree(), cmap=cmap,norm=norm)\n",
    "    \n",
    "    \n",
    "            # axs[idx].title.set_text(f'SubX Lead {lead*7}')\n",
    "            gl = axs[axs_start].gridlines(crs=ccrs.PlateCarree(), draw_labels=True,\n",
    "                                       linewidth=0.7, color='gray', alpha=0.5, linestyle='--')\n",
    "            gl.xlabels_top = False\n",
    "            gl.ylabels_right = False\n",
    "            if lead != 1:\n",
    "                gl.ylabels_left = False\n",
    "            gl.xformatter = LongitudeFormatter()\n",
    "            gl.yformatter = LatitudeFormatter()\n",
    "            axs[axs_start].coastlines()\n",
    "            # plt.colorbar(im)\n",
    "            # axs[idx].set_aspect('auto', adjustable=None)\n",
    "            axs[axs_start].set_aspect('equal')  # this makes the plots better\n",
    "            axs[axs_start].set_title(f'{name} Lead {lead}',fontsize=15)\n",
    "\n",
    "            if name in ['UNET','Baseline']:\n",
    "                # Calculate the Pearson correlation coefficient\n",
    "                obs_corr = return_array_anomaly(file=obs,lead=lead, date=date).flatten()\n",
    "                data_corr = data.flatten()\n",
    "\n",
    "                data_corr = data_corr[~np.isnan(obs_corr)]\n",
    "                obs_corr = obs_corr[~np.isnan(obs_corr)]\n",
    "                \n",
    "                correlation_matrix = np.corrcoef(obs_corr, data_corr)\n",
    "                # The correlation coefficient is in the top right corner of the correlation matrix\n",
    "                correlation_coefficient = correlation_matrix[0, 1]\n",
    "                correlation_coefficient = round(correlation_coefficient,4)\n",
    "                #find the correlation coefficient across the dataset\n",
    "                axs[axs_start].text(text_x, text_y, f'Corr: {correlation_coefficient}', ha='right', va='bottom', fontsize=font_size_corr, color='blue', weight = 'bold')\n",
    "            \n",
    "            \n",
    "            axs_start+=1\n",
    "            \n",
    "    cbar_ax = fig.add_axes([0.05, -0.05, .9, .04])\n",
    "    \n",
    "    # Draw the colorbar\n",
    "    cbar = fig.colorbar(im, cax=cbar_ax, orientation='horizontal')\n",
    "    fig.suptitle(f'Init date: {date}', fontsize=30)\n",
    "    fig.tight_layout()\n",
    "    \n",
    "    plt.savefig(f'{save_dir}/Southeast_anomaly_init{date}.png',bbox_inches='tight')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e450bc7-4710-4e48-9060-c1b63d5d9a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_case_study_anomaly(obs=obs_anom, unet=unet_anom, baseline=baseline_anom, init_date=obs_anom.S.values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "874d5047-e4d1-4482-bac0-620815a53971",
   "metadata": {},
   "outputs": [],
   "source": [
    "for init_date in obs_anom.S.values:\n",
    "    plot_case_study_anomaly(obs=obs_anom, unet=unet_anom, baseline=baseline_anom, init_date=init_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "875edd05-b677-4f61-ad2d-bb81053170e3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tf212gpu]",
   "language": "python",
   "name": "conda-env-tf212gpu-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "toc-autonumbering": true,
  "toc-showcode": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
