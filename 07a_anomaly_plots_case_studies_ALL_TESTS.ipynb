{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7302f239-5aba-4164-8125-86df134c9bd5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-11 05:52:00.893226: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-02-11 05:52:01.022084: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-02-11 05:52:03.549502: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/glade/work/klesinger/conda-envs/tf212gpu/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%reload_ext autoreload\n",
    "\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import os\n",
    "from glob import glob\n",
    "import functions as f\n",
    "from mpl_toolkits.basemap import Basemap\n",
    "from numpy import meshgrid\n",
    "from mpl_toolkits.axes_grid1.axes_divider import make_axes_locatable\n",
    "import matplotlib.colors as mcolors\n",
    "import cartopy.feature as cfeature\n",
    "import itertools\n",
    "import cartopy.crs as ccrs\n",
    "from cartopy.mpl.ticker import LongitudeFormatter, LatitudeFormatter, LatitudeLocator\n",
    "import matplotlib.ticker as mticker\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap, TwoSlopeNorm\n",
    "import pandas as pd\n",
    "import math\n",
    "from datetime import datetime\n",
    "import datetime as dt\n",
    "from multiprocessing import Pool\n",
    "from sklearn.metrics import confusion_matrix as CM\n",
    "import masks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63c73293-14c6-4887-a3ad-f5e7c3980d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_anomaly_mf = xr.open_mfdataset('Data/GLEAM/RZSM_anomaly_reformat_SubX_format/RZSM_anomaly*.nc4').sel(L=[6,13,20,27,34]).load()\n",
    "\n",
    "#######################################   Reforecast baseline files   ###########################################################################\n",
    "baseline_anomaly_file_list = sorted(glob('Data/GEFSv12_reforecast/soilw_bgrnd/baseline_RZSM_anomaly/RZSM*.nc'))\n",
    "baseline_anomaly = xr.open_mfdataset(baseline_anomaly_file_list).sel(L=[6,13,20,27,34]).load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "612950b1-1fcf-4522-b79c-7d85f090e726",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Set script parameters\n",
    "CONUS_mask = f.load_CONUS_mask() #Mask of CONUS which serves as our bounding box. Can later change this to a larger file but then we would have to edit the data from the previous scripts. \n",
    "\n",
    "#Used for later masking with np.nan\n",
    "CONUS_array = CONUS_mask['NCA-LDAS_mask'].values.squeeze()\n",
    "CONUS_array.shape\n",
    "\n",
    "#Mask with np.nan for non-CONUS land values\n",
    "mask_anom = CONUS_mask['NCA-LDAS_mask'][0,:,:].values\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee4a2a02-5063-437c-bc6a-043c384d6084",
   "metadata": {},
   "source": [
    "# Data (observation and baseline reforecast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f33cb06b-b19a-40c7-88bc-e9f0c49632bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We have run several different experiments\n",
    "def load_unet_prediction(experiment_name, bias_correction_season_or_init_or_None):\n",
    "    unet_anomaly_file_list = sorted(glob(f'predictions/anomaly_no_julian_dates/{experiment_name}_{bias_correction_season_or_init_or_None}*.nc'))\n",
    "    unet_anomaly_conus_min_max = xr.open_mfdataset(unet_anomaly_file_list).sel(L=[6,13,20,27,34]).load()\n",
    "    return(unet_anomaly_conus_min_max)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "900253c8-c1c0-4da9-9b70-3386dfebd7fc",
   "metadata": {},
   "source": [
    "# Plot anomaly for 2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ae561a1b-40c5-4933-bc50-c591e9217140",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_min_max_of_files_anomaly(obs, unet, baseline, date):\n",
    "    #test \n",
    "    # date = '2019-08-07'\n",
    "    \n",
    "    min_ = []\n",
    "    max_ = []\n",
    "\n",
    "    min_.append(obs.sel(S=date).min().RZSM.values)\n",
    "    min_.append(unet.sel(S=date).min().RZSM.values)\n",
    "    min_.append(baseline.sel(S=date).min().RZSM.values)\n",
    "\n",
    "    max_.append(obs.sel(S=date).max().RZSM.values)\n",
    "    max_.append(unet.sel(S=date).max().RZSM.values)\n",
    "    max_.append(baseline.sel(S=date).max().RZSM.values)\n",
    "\n",
    "    #for some reason it is not allowing the max\n",
    "    max_out = 0\n",
    "    for i in max_:\n",
    "        if i > max_out:\n",
    "            max_out = i\n",
    "\n",
    "    min_out = 0\n",
    "    for i in min_:\n",
    "        if i < min_out:\n",
    "            min_out = i\n",
    "    \n",
    "    return(min_out,max_out)\n",
    "\n",
    "def return_array_anomaly(file,lead,date):\n",
    "    return(file.sel(L=lead,S=date).RZSM.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "d38a710f-3228-4a0c-b1a1-64f09ec6921a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "   \n",
    "# cmap = 'coolwarm'\n",
    "def plot_case_study_anomaly(obs, unet, baseline, init_date, year, file_name_out):\n",
    "\n",
    "    text_x = -83.5\n",
    "    text_y = 27\n",
    "    font_size_corr = 12\n",
    "    \n",
    "    cmap = plt.get_cmap('bwr')    \n",
    "    # Create a diverging color scale using RdBu colormap\n",
    "    cmap = plt.get_cmap('RdBu')\n",
    "    # Create a diverging color palette centered at 0\n",
    "    # palette = sns.diverging_palette(220, 20, as_cmap=True)\n",
    "    \n",
    "    if year == 2019:\n",
    "        save_dir = f'Outputs/Case_studies/Southeast_US/anomaly'\n",
    "    elif year == 2017:\n",
    "        save_dir = f'Outputs/Case_studies/High_Plains/anomaly'\n",
    "    elif year == 2012:\n",
    "        save_dir = f'Outputs/Case_studies/Central_US/anomaly'\n",
    "        \n",
    "    os.system(f'mkdir -p {save_dir}')\n",
    "        \n",
    "    fig, axs = plt.subplots(\n",
    "        nrows = 5, ncols= 3, subplot_kw={'projection': ccrs.PlateCarree()}, figsize=(20, 15))\n",
    "    axs = axs.flatten()\n",
    "    \n",
    "    init_date = pd.to_datetime(init_date)\n",
    "    date = f'{init_date.year}-{init_date.month:02}-{init_date.day:02}'\n",
    "    \n",
    "    min_,max_ = get_min_max_of_files_anomaly(obs, unet, baseline, date)\n",
    "    # test_file = mae_rzsm_keys\n",
    "    # for Subx original data\n",
    "    \n",
    "    lon = obs.X.values\n",
    "    lat = obs.Y.values\n",
    "    \n",
    "    axs_start = 0\n",
    "    for lead in [6,13,20,27,34]:\n",
    "        for data_to_plot,name in zip([obs, unet, baseline], ['GLEAM','UNET','Baseline']):\n",
    "            # break\n",
    "            data = return_array_anomaly(file=data_to_plot,lead=lead, date=date)\n",
    "    \n",
    "            v = np.linspace(min_, max_, 20, endpoint=True)\n",
    "\n",
    "            #Make sure it diverges at 0\n",
    "            neg = [i for i in v if i <0]\n",
    "            pos = [i for i in v if i >0]\n",
    "            v = np.array(neg +[0] + pos)\n",
    "            \n",
    "        \n",
    "            map = Basemap(projection='cyl', llcrnrlat=25, urcrnrlat=50,\n",
    "                          llcrnrlon=-128, urcrnrlon=-60, resolution='l')\n",
    "            x, y = map(*np.meshgrid(lon, lat))\n",
    "            # Adjust the text coordinates based on the actual data coordinates\n",
    "        \n",
    "            norm = TwoSlopeNorm(vmin=min_, vcenter=0, vmax=max_)\n",
    "        \n",
    "            im = axs[axs_start].contourf(x, y, data, levels=v, extend='both',\n",
    "                                  transform=ccrs.PlateCarree(), cmap=cmap,norm=norm)\n",
    "    \n",
    "    \n",
    "            # axs[idx].title.set_text(f'SubX Lead {lead*7}')\n",
    "            gl = axs[axs_start].gridlines(crs=ccrs.PlateCarree(), draw_labels=True,\n",
    "                                       linewidth=0.7, color='gray', alpha=0.5, linestyle='--')\n",
    "            gl.xlabels_top = False\n",
    "            gl.ylabels_right = False\n",
    "            if lead != 1:\n",
    "                gl.ylabels_left = False\n",
    "            gl.xformatter = LongitudeFormatter()\n",
    "            gl.yformatter = LatitudeFormatter()\n",
    "            axs[axs_start].coastlines()\n",
    "            # plt.colorbar(im)\n",
    "            # axs[idx].set_aspect('auto', adjustable=None)\n",
    "            axs[axs_start].set_aspect('equal')  # this makes the plots better\n",
    "            axs[axs_start].set_title(f'{name} Lead {lead}',fontsize=15)\n",
    "\n",
    "            if name in ['UNET','Baseline']:\n",
    "                # Calculate the Pearson correlation coefficient\n",
    "                obs_corr = return_array_anomaly(file=obs,lead=lead, date=date).flatten()\n",
    "                data_corr = data.flatten()\n",
    "\n",
    "                data_corr = data_corr[~np.isnan(obs_corr)]\n",
    "                obs_corr = obs_corr[~np.isnan(obs_corr)]\n",
    "                \n",
    "                correlation_matrix = np.corrcoef(obs_corr, data_corr)\n",
    "                # The correlation coefficient is in the top right corner of the correlation matrix\n",
    "                correlation_coefficient = correlation_matrix[0, 1]\n",
    "                correlation_coefficient = round(correlation_coefficient,4)\n",
    "                #find the correlation coefficient across the dataset\n",
    "                axs[axs_start].text(text_x, text_y, f'Corr: {correlation_coefficient}', ha='right', va='bottom', fontsize=font_size_corr, color='blue', weight = 'bold')\n",
    "            \n",
    "            \n",
    "            axs_start+=1\n",
    "            \n",
    "    cbar_ax = fig.add_axes([0.05, -0.05, .9, .04])\n",
    "    \n",
    "    # Draw the colorbar\n",
    "    cbar = fig.colorbar(im, cax=cbar_ax, orientation='horizontal')\n",
    "    fig.suptitle(f'Init date: {date}\\n{file_name_out}', fontsize=30)\n",
    "    fig.tight_layout()\n",
    "\n",
    "    plt.savefig(f'{save_dir}/init_{date}_{file_name_out}.png',bbox_inches='tight')\n",
    "    \n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffa97f09-5c26-4510-9a35-b89de9cf5150",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dates\n",
    "start_ = '2019-07-25'\n",
    "end_ =  '2019-09-14'\n",
    "\n",
    "obs_anom = obs_anomaly_mf.sel(S=slice(start_,end_)).mean(dim='M').astype(np.float32)\n",
    "baseline_anom = baseline_anomaly.sel(S=slice(start_,end_)).mean(dim='M').astype(np.float32)\n",
    "\n",
    "for experiment_name in ['EX26_RZSM', 'EX10_grid_cell_standardization_RZSM']:\n",
    "    for bias_correction_season_or_init_or_None in ['No','season','init']:\n",
    "        # break\n",
    "        unet_anomaly = load_unet_prediction(experiment_name, bias_correction_season_or_init_or_None)\n",
    "\n",
    "        #Now plot the data\n",
    "        unet_anom = unet_anomaly.sel(S=slice(start_,end_)).mean(dim='M')\n",
    "        \n",
    "        obs_anom = xr.where(mask_anom ==1, obs_anom,np.nan).sel(L=[6,13,20,27,34])\n",
    "        unet_anom = xr.where(mask_anom ==1, unet_anom,np.nan).sel(L=[6,13,20,27,34])\n",
    "        baseline_anom = xr.where(mask_anom ==1, baseline_anom,np.nan).sel(L=[6,13,20,27,34])\n",
    "        \n",
    "        unet_anom = xr.where(~np.isnan(obs_anom), unet_anom,np.nan)\n",
    "        baseline_anom = xr.where(~np.isnan(obs_anom), baseline_anom,np.nan)\n",
    "        \n",
    "        for init_date in obs_anom.S.values:\n",
    "            plot_case_study_anomaly(obs=obs_anom, unet=unet_anom, baseline=baseline_anom, init_date=init_date, \n",
    "                                    year=2019, file_name_out = f'{experiment_name}_{bias_correction_season_or_init_or_None}_bias_correction_anomaly')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "57994545-b88c-4098-a357-e0f97b6de77f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_array_anomaly_lead(file,date):\n",
    "    return(file.sel(S=date).RZSM.values)\n",
    "    \n",
    "def get_min_max_of_files_anomaly_lead(obs,  unet_select):\n",
    "    #test \n",
    "    # date = '2019-08-07'\n",
    "    \n",
    "    min_ = []\n",
    "    max_ = []\n",
    "\n",
    "    min_.append(obs.min().RZSM.values)\n",
    "    # min_.append(unet.sel(S=date).min().RZSM.values)\n",
    "    min_.append(unet_select.min().RZSM.values)\n",
    "\n",
    "    max_.append(obs.max().RZSM.values)\n",
    "    # max_.append(unet.sel(S=date).max().RZSM.values)\n",
    "    max_.append(unet_select.max().RZSM.values)\n",
    "\n",
    "    #for some reason it is not allowing the max\n",
    "    max_out = 0\n",
    "    for i in max_:\n",
    "        if i > max_out:\n",
    "            max_out = i\n",
    "\n",
    "    min_out = 0\n",
    "    for i in min_:\n",
    "        if i < min_out:\n",
    "            min_out = i\n",
    "    \n",
    "    return(min_out,max_out)\n",
    "\n",
    "def get_min_max_of_files_anomaly_leadN_2(obs, baseline, date):\n",
    "    #test \n",
    "    # date = '2019-08-07'\n",
    "    \n",
    "    min_ = []\n",
    "    max_ = []\n",
    "\n",
    "    min_.append(obs.sel(S=date).min().RZSM.values)\n",
    "    # min_.append(unet.sel(S=date).min().RZSM.values)\n",
    "    min_.append(baseline.sel(S=date).min().RZSM.values)\n",
    "\n",
    "    max_.append(obs.sel(S=date).max().RZSM.values)\n",
    "    # max_.append(unet.sel(S=date).max().RZSM.values)\n",
    "    max_.append(baseline.sel(S=date).max().RZSM.values)\n",
    "\n",
    "    #for some reason it is not allowing the max\n",
    "    max_out = 0\n",
    "    for i in max_:\n",
    "        if i > max_out:\n",
    "            max_out = i\n",
    "\n",
    "    min_out = 0\n",
    "    for i in min_:\n",
    "        if i < min_out:\n",
    "            min_out = i\n",
    "    \n",
    "    return(min_out,max_out)\n",
    "\n",
    "# cmap = 'coolwarm'\n",
    "\n",
    "def plot_unet_experiments(obs, baseline, init_date, \n",
    "                            year, file_name_out , experiment_list, lead):\n",
    "\n",
    "    text_x = -83.5\n",
    "    text_y = 27\n",
    "    font_size_corr = 12\n",
    "    \n",
    "    cmap = plt.get_cmap('bwr')    \n",
    "    # Create a diverging color scale using RdBu colormap\n",
    "    cmap = plt.get_cmap('RdBu')\n",
    "    # Create a diverging color palette centered at 0\n",
    "    # palette = sns.diverging_palette(220, 20, as_cmap=True)\n",
    "    \n",
    "    if year == 2019:\n",
    "        save_dir = f'Outputs/Case_studies/Southeast_US/anomaly/specific_UNETs'\n",
    "    elif year == 2017:\n",
    "        save_dir = f'Outputs/Case_studies/High_Plains/anomaly/specific_UNETs'\n",
    "    elif year == 2012:\n",
    "        save_dir = f'Outputs/Case_studies/Central_US/anomaly/specific_UNETs'\n",
    "        \n",
    "    os.system(f'mkdir -p {save_dir}')\n",
    "        \n",
    "    fig, axs = plt.subplots(\n",
    "        nrows = 5, ncols= 6, subplot_kw={'projection': ccrs.PlateCarree()}, figsize=(20, 15))\n",
    "    axs = axs.flatten()\n",
    "    \n",
    "    init_date = pd.to_datetime(init_date)\n",
    "    date = f'{init_date.year}-{init_date.month:02}-{init_date.day:02}'\n",
    "    \n",
    "    min_,max_ = get_min_max_of_files_anomaly_leadN_2(obs, baseline, date)\n",
    "    # test_file = mae_rzsm_keys\n",
    "    # for Subx original data\n",
    "    \n",
    "    lon = obs.X.values\n",
    "    lat = obs.Y.values\n",
    "    \n",
    "    axs_start = 0\n",
    "    for data_to_plot,name in zip([obs, baseline], ['GLEAM','Baseline']):\n",
    "        # break\n",
    "        data = return_array_anomaly_lead(file=data_to_plot, date=date)\n",
    "\n",
    "        v = np.linspace(min_, max_, 20, endpoint=True)\n",
    "\n",
    "        #Make sure it diverges at 0\n",
    "        neg = [i for i in v if i <0]\n",
    "        pos = [i for i in v if i >0]\n",
    "        v = np.array(neg +[0] + pos)\n",
    "        \n",
    "    \n",
    "        map = Basemap(projection='cyl', llcrnrlat=25, urcrnrlat=50,\n",
    "                      llcrnrlon=-128, urcrnrlon=-60, resolution='l')\n",
    "        x, y = map(*np.meshgrid(lon, lat))\n",
    "        # Adjust the text coordinates based on the actual data coordinates\n",
    "    \n",
    "        norm = TwoSlopeNorm(vmin=min_, vcenter=0, vmax=max_)\n",
    "    \n",
    "        im = axs[axs_start].contourf(x, y, data, levels=v, extend='both',\n",
    "                              transform=ccrs.PlateCarree(), cmap=cmap,norm=norm)\n",
    "\n",
    "\n",
    "        # axs[idx].title.set_text(f'SubX Lead {lead*7}')\n",
    "        gl = axs[axs_start].gridlines(crs=ccrs.PlateCarree(), draw_labels=True,\n",
    "                                   linewidth=0.7, color='gray', alpha=0.5, linestyle='--')\n",
    "        gl.xlabels_top = False\n",
    "        gl.ylabels_right = False\n",
    "        if lead != 1:\n",
    "            gl.ylabels_left = False\n",
    "        gl.xformatter = LongitudeFormatter()\n",
    "        gl.yformatter = LatitudeFormatter()\n",
    "        axs[axs_start].coastlines()\n",
    "        # plt.colorbar(im)\n",
    "        # axs[idx].set_aspect('auto', adjustable=None)\n",
    "        axs[axs_start].set_aspect('equal')  # this makes the plots better\n",
    "        axs[axs_start].set_title(f'{name} Lead {lead}',fontsize=15)\n",
    "\n",
    "        if name in ['UNET','Baseline']:\n",
    "            # Calculate the Pearson correlation coefficient\n",
    "            obs_corr = return_array_anomaly_lead(file=obs, date=date).flatten()\n",
    "            data_corr = data.flatten()\n",
    "\n",
    "            data_corr = data_corr[~np.isnan(obs_corr)]\n",
    "            obs_corr = obs_corr[~np.isnan(obs_corr)]\n",
    "            \n",
    "            correlation_matrix = np.corrcoef(obs_corr, data_corr)\n",
    "            # The correlation coefficient is in the top right corner of the correlation matrix\n",
    "            correlation_coefficient = correlation_matrix[0, 1]\n",
    "            correlation_coefficient = round(correlation_coefficient,4)\n",
    "            #find the correlation coefficient across the dataset\n",
    "            axs[axs_start].text(text_x, text_y, f'Corr: {correlation_coefficient}', ha='right', va='bottom', fontsize=font_size_corr, color='blue', weight = 'bold')\n",
    "        \n",
    "            \n",
    "        axs_start+=1\n",
    "\n",
    "    for experiment_name in experiment_list: \n",
    "        # break\n",
    "        data = np.nanmean(load_unet_prediction_by_lead(experiment_name, lead),axis=1)\n",
    "        #mask data\n",
    "        unet_select = obs.copy(deep = True)\n",
    "        unet_select.RZSM[:,:,:] = data\n",
    "        unet_select = xr.where(~np.isnan(obs),unet_select,np.nan)\n",
    "        unet_select = unet_select.sel(S=init_date)\n",
    "        unet_select.RZSM.shape\n",
    "        min_,max_ = get_min_max_of_files_anomaly_lead(obs.sel(S=init_date),unet_select)\n",
    "        v = np.linspace(min_, max_, 20, endpoint=True)\n",
    "        \n",
    "        #Make sure it diverges at 0\n",
    "        neg = [i for i in v if i <0]\n",
    "        pos = [i for i in v if i >0]\n",
    "        v = np.array(neg +[0] + pos)\n",
    "        \n",
    "        \n",
    "        map = Basemap(projection='cyl', llcrnrlat=25, urcrnrlat=50,\n",
    "                      llcrnrlon=-128, urcrnrlon=-60, resolution='l')\n",
    "        x, y = map(*np.meshgrid(lon, lat))\n",
    "        # Adjust the text coordinates based on the actual data coordinates\n",
    "        \n",
    "        norm = TwoSlopeNorm(vmin=min_, vcenter=0, vmax=max_)\n",
    "        \n",
    "        im = axs[axs_start].contourf(x, y, unet_select.RZSM.values, levels=v, extend='both',\n",
    "                              transform=ccrs.PlateCarree(), cmap=cmap,norm=norm)\n",
    "        \n",
    "        \n",
    "        # axs[idx].title.set_text(f'SubX Lead {lead*7}')\n",
    "        gl = axs[axs_start].gridlines(crs=ccrs.PlateCarree(), draw_labels=True,\n",
    "                                   linewidth=0.7, color='gray', alpha=0.5, linestyle='--')\n",
    "        gl.xlabels_top = False\n",
    "        gl.ylabels_right = False\n",
    "        if lead != 1:\n",
    "            gl.ylabels_left = False\n",
    "        gl.xformatter = LongitudeFormatter()\n",
    "        gl.yformatter = LatitudeFormatter()\n",
    "        axs[axs_start].coastlines()\n",
    "        # plt.colorbar(im)\n",
    "        # axs[idx].set_aspect('auto', adjustable=None)\n",
    "        axs[axs_start].set_aspect('equal')  # this makes the plots better\n",
    "        axs[axs_start].set_title(f'{experiment_name} Lead {lead}',fontsize=15)\n",
    "        \n",
    "        if name in ['UNET','Baseline']:\n",
    "            # Calculate the Pearson correlation coefficient\n",
    "            obs_corr = return_array_anomaly_lead(file=obs, date=date).flatten()\n",
    "            data_corr = unet_select.RZSM.values.flatten()\n",
    "        \n",
    "            data_corr = data_corr[~np.isnan(obs_corr)]\n",
    "            obs_corr = obs_corr[~np.isnan(obs_corr)]\n",
    "            \n",
    "            correlation_matrix = np.corrcoef(obs_corr, data_corr)\n",
    "            # The correlation coefficient is in the top right corner of the correlation matrix\n",
    "            correlation_coefficient = correlation_matrix[0, 1]\n",
    "            correlation_coefficient = round(correlation_coefficient,4)\n",
    "            #find the correlation coefficient across the dataset\n",
    "            axs[axs_start].text(text_x, text_y, f'Corr: {correlation_coefficient}', ha='right', va='bottom', fontsize=font_size_corr, color='blue', weight = 'bold')\n",
    "    \n",
    "                \n",
    "            axs_start+=1\n",
    "\n",
    "\n",
    "                \n",
    "    # unet_anomaly.shape\n",
    "    # unet_anomaly = np.nanmean(unet_anomaly,axis=1)\n",
    "    # unet_anom = xr.where(mask_anom ==1, unet_select,np.nan)\n",
    "    # unet_anom = xr.where(~np.isnan(obs_anom), unet_select,np.nan)\n",
    "\n",
    "    \n",
    "    cbar_ax = fig.add_axes([0.05, -0.05, .9, .04])\n",
    "    \n",
    "    # Draw the colorbar\n",
    "    cbar = fig.colorbar(im, cax=cbar_ax, orientation='horizontal')\n",
    "    fig.suptitle(f'Init date: {date}\\n{file_name_out}', fontsize=30)\n",
    "    fig.tight_layout()\n",
    "\n",
    "    plt.savefig(f'{save_dir}/init_{init_date}_{file_name_out}.png',bbox_inches='tight')\n",
    "    \n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f459b93-ce93-411d-b75f-415b10b5369b",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "# Plot UNET experiments for each weekly lead 3 -5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "af698a10-9271-4b30-8656-0b8703b8823a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We have run several different experiments\n",
    "def load_unet_prediction_by_lead(experiment_name, lead):\n",
    "    max_RZSM_reforecast, min_RZSM_reforecast = f.load_reforecast_min_max_RZSM()\n",
    "    unet_anomaly_file_list = np.load(f'predictions/Wk_{lead}_testing/Wk{lead}_testing_{experiment_name}.npy')\n",
    "    #Convert back to anomalies\n",
    "    test = f.reverse_min_max_scaling(unet_anomaly_file_list[2,:,:,:,0],max_RZSM_reforecast, min_RZSM_reforecast)\n",
    "    test = np.reshape(test,(test.shape[0]//11,11,test.shape[1],test.shape[2]))\n",
    "    return(test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6995adea-e8eb-4eea-9753-43467bfb2faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "Wk3 = [f'EX{i}_RZSM' for i in range(26)]\n",
    "Wk4a = [f'EX{i}_RZSM' for i in range(12)]\n",
    "Wk4b = [f'EX{i}_RZSM' for i in range(13,27)]\n",
    "\n",
    "Wk4 = Wk4a+Wk4b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5b18b66-8535-4fa6-9418-82160a1c3861",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_ = '2019-07-25'\n",
    "end_ =  '2019-09-14'\n",
    "\n",
    "# obs_anom = obs_anomaly_mf.sel(S=slice(start_,end_)).mean(dim='M').astype(np.float32)\n",
    "# baseline_anom = baseline_anomaly.sel(S=slice(start_,end_)).mean(dim='M').astype(np.float32)\n",
    "\n",
    "\n",
    "# break\n",
    "#First get the testing dates for obs\n",
    "start_test = '2018-01-01'\n",
    "end_test = '2019-12-31'\n",
    "\n",
    "obs_anom = obs_anomaly_mf.sel(S=slice(start_test,end_test)).mean(dim='M').astype(np.float32)\n",
    "baseline_anom = baseline_anomaly.sel(S=slice(start_test,end_test)).mean(dim='M').astype(np.float32)\n",
    "\n",
    "\n",
    "obs_select = obs_anom.sel(L=(lead*7)-1)\n",
    "baseline_select = baseline_anom.sel(L=(lead*7)-1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "obs_anom = xr.where(mask_anom ==1, obs_select,np.nan)\n",
    "\n",
    "baseline_anom = xr.where(mask_anom ==1, baseline_select,np.nan)\n",
    "\n",
    "baseline_anom = xr.where(~np.isnan(obs_anom), baseline_select,np.nan)\n",
    "\n",
    "\n",
    "obs_anom_dates = obs_anom.sel(S=slice(start_,end_))\n",
    "\n",
    "for (experiment_list,lead) in zip([Wk3,Wk4], [3,4]):\n",
    "    for init_date in obs_anom_dates.S.values:\n",
    "        plot_unet_experiments(obs=obs_anom, baseline=baseline_anom, init_date=init_date, \n",
    "                                year=2019, file_name_out = f'ALL_unets_Lead_{lead}', experiment_list = experiment_list, lead=lead)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b83a870f-5bc3-4e80-ac2f-64d45f13098f",
   "metadata": {},
   "source": [
    "# 2017 Flash Drought"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "80b072e7-a415-463c-bd1d-5466665c0d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dates\n",
    "start_ = '2017-04-01'\n",
    "end_ = '2017-08-30'\n",
    "\n",
    "\n",
    "obs_anom = obs_anomaly_mf.sel(S=slice(start_,end_)).mean(dim='M')\n",
    "unet_anom = unet_anomaly.sel(S=slice(start_,end_)).mean(dim='M')\n",
    "baseline_anom = baseline_anomaly.sel(S=slice(start_,end_)).mean(dim='M')\n",
    "\n",
    "#Masking on ocean areas\n",
    "obs_anom = xr.where(mask_anom ==1, obs_anom,np.nan).sel(L=[20,27,34])\n",
    "unet_anom = xr.where(mask_anom ==1, unet_anom,np.nan).sel(L=[20,27,34])\n",
    "baseline_anom = xr.where(mask_anom ==1, baseline_anom,np.nan).sel(L=[20,27,34])\n",
    "\n",
    "#Further masking of grid cells within CONUS that aren't in GlEAM\n",
    "unet_anom = xr.where(~np.isnan(obs_anom), unet_anom,np.nan)\n",
    "baseline_anom = xr.where(~np.isnan(obs_anom), baseline_anom,np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb992289-6373-4380-bcf3-36e08e04617f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for init_date in obs_anom.S.values:\n",
    "    plot_case_study_anomaly(obs=obs_anom, unet=unet_anom, baseline=baseline_anom, init_date=init_date, year = 2017)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "580fa655-3278-4f2f-8a18-1605d8340d6d",
   "metadata": {},
   "source": [
    "# 2012 Flash Drought"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "33590834-493c-4f76-94ec-10964a9d95d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dates\n",
    "start_ = '2012-04-01'\n",
    "end_ = '2012-06-30'\n",
    "\n",
    "\n",
    "obs_anom = obs_anomaly_mf.sel(S=slice(start_,end_)).mean(dim='M')\n",
    "unet_anom = unet_anomaly.sel(S=slice(start_,end_)).mean(dim='M')\n",
    "baseline_anom = baseline_anomaly.sel(S=slice(start_,end_)).mean(dim='M')\n",
    "\n",
    "#Masking on ocean areas\n",
    "obs_anom = xr.where(mask_anom ==1, obs_anom,np.nan).sel(L=[20,27,34])\n",
    "unet_anom = xr.where(mask_anom ==1, unet_anom,np.nan).sel(L=[20,27,34])\n",
    "baseline_anom = xr.where(mask_anom ==1, baseline_anom,np.nan).sel(L=[20,27,34])\n",
    "\n",
    "#Further masking of grid cells within CONUS that aren't in GlEAM\n",
    "unet_anom = xr.where(~np.isnan(obs_anom), unet_anom,np.nan)\n",
    "baseline_anom = xr.where(~np.isnan(obs_anom), baseline_anom,np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9108473-3e1a-496c-ae84-77719dd84d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "for init_date in obs_anom.S.values:\n",
    "    plot_case_study_anomaly(obs=obs_anom, unet=unet_anom, baseline=baseline_anom, init_date=init_date, year = 2012)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e47d545-38f5-4af7-81ba-fc612080c939",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tf212gpu]",
   "language": "python",
   "name": "conda-env-tf212gpu-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "toc-autonumbering": true,
  "toc-showcode": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
