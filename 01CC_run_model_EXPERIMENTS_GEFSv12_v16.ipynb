{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b51fd071-9238-4e03-982e-68dafa29e04f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-14 15:23:06.098873: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-08-14 15:23:46.088428: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/glade/work/klesinger/conda-envs/tf212gpu_new/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Mixed precision compatibility check (mixed_float16): WARNING\n",
      "Your GPU may run slowly with dtype policy mixed_float16 because it does not have compute capability of at least 7.0. Your GPU:\n",
      "  Quadro GP100, compute capability 6.0\n",
      "See https://developer.nvidia.com/cuda-gpus for a list of GPUs and their compute capabilities.\n",
      "If you will use compatible GPU(s) not attached to this host, e.g. by running a multi-worker model, you can ignore this warning. This message will only be logged once\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload \n",
    "%autoreload 2\n",
    "%reload_ext autoreload\n",
    "\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "import datetime as dt\n",
    "from PIL import Image\n",
    "import sys\n",
    "import functions as f\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from keras.models import Model\n",
    "from keras import backend as K\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from IPython.display import Image \n",
    "from tensorflow.python.data.ops import dataset_ops\n",
    "import dask\n",
    "from keras.models import load_model\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from io import StringIO\n",
    "import shap\n",
    "from keras.layers import Input\n",
    "import keras as k\n",
    "from contextlib import redirect_stdout\n",
    "from PIL import Image\n",
    "import matplotlib.gridspec as gridspec\n",
    "import cv2\n",
    "import channelExperiment as CE\n",
    "import loadDataWeek0 as loadData\n",
    "import bottleneck as bn\n",
    "from tensorflow.keras import mixed_precision\n",
    "import csv\n",
    "import addPredictors as pred\n",
    "import loadValues as lv\n",
    "import masks\n",
    "import denseValue\n",
    "import verifications\n",
    "import preprocessUtils as putils\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "global lead_week_predictions \n",
    "lead_week_predictions = [1,2,3,4,5] #for running the model for different lead weeks. Can choose any numbers in a LIST from [1,2,3,4,5]\n",
    "\n",
    "\n",
    "global region_name,testing_scenario,save_loss_name\n",
    "region_name = 'CONUS' #['australia','CONUS', 'china']\n",
    "\n",
    "\n",
    "    \n",
    "'''Make sure to fill in this information depending on what test we are doing'''\n",
    "make_single_prediction_from_model_for_testing=False\n",
    "make_additional_predictions_from_model_for_testing = False\n",
    "permutation_test_graphs_create=True\n",
    "bias_correction_predict = False\n",
    "\n",
    "#Tensorflow RT things\n",
    "policy = mixed_precision.Policy('mixed_float16')\n",
    "mixed_precision.set_global_policy(policy)\n",
    "tf.config.optimizer.set_jit(True) # Enable XLA.\n",
    "\n",
    "\n",
    "global RZSM_or_Tmax_or_both, num_predictions_testing, num_train_val_predictions\n",
    "RZSM_or_Tmax_or_both = 'RZSM' # for getting the predictor from either RZSM and Tmax ('both') or only RZSM ('RZSM')\n",
    "\n",
    "num_predictions_testing = 25\n",
    "num_train_val_predictions=10\n",
    "\n",
    "#for permutation plot\n",
    "max_RZSM_value,max_tmax_value = 0.05,5\n",
    "\n",
    "#set for the larger memeory ones\n",
    "# os.environ['TF_GPU_ALLOCATOR'] = 'cuda_malloc_async'\n",
    "\n",
    "\n",
    "global ref_source,final_testing_year, test_year\n",
    "ref_source = 'GEFSv12'\n",
    "final_testing_year = 2019\n",
    "test_year = final_testing_year"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4638590c-749d-4c6c-85c4-3af63200d242",
   "metadata": {},
   "source": [
    "# Choose different loss and architecture configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c30eb77c-8143-4556-b370-ff75098f35f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-14 15:26:22.458212: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 15448 MB memory:  -> device: 0, name: Quadro GP100, pci bus id: 0000:18:00.0, compute capability: 6.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#First just re-save the new density value into a new file (it's convoluted but it works)\n",
    "# denseValue.return_dense_value_file(region_name, 0.5) #can chooose 0.5 or 0.8 as the alpha coefficient\n",
    "\n",
    "\n",
    "import losses\n",
    "\n",
    "testing_scenario = 'regular' #['dense', 'regular', 'transformer', 'super_pixel', 'attention', 'denseLarge', 'basic', 'regularResidual','regularDepth']\n",
    "\n",
    "global save_loss_name, loss_fn\n",
    "\n",
    "if testing_scenario == 'dense':\n",
    "    import modelRzsmDenseRelu as UNETRzsm\n",
    "    \n",
    "    save_loss_name = 'denseLoss'\n",
    "    loss_fn = losses.crps2d_tf_dense_test2\n",
    "    \n",
    "elif testing_scenario == 'regular':\n",
    "    import modelRzsmReluExtraConv as UNETRzsm\n",
    "\n",
    "    save_loss_name = 'regular'\n",
    "    loss_fn = losses.crps2d_tf\n",
    "\n",
    "elif testing_scenario == 'regularDepth':\n",
    "    import modelRzsmReluExtraConvDepthwise as UNETRzsm\n",
    "\n",
    "    save_loss_name = 'regularDepth'\n",
    "    loss_fn = losses.crps2d_tf\n",
    "\n",
    "elif testing_scenario == 'transformer':\n",
    "    import modelRzsmReluTransformer as UNETRzsm\n",
    "    \n",
    "    save_loss_name = 'transformer'\n",
    "    loss_fn = losses.crps2d_tf_dense_test2\n",
    "\n",
    "elif testing_scenario == 'super_pixel':\n",
    "    import modelRzsmReluPixelSuper as UNETRzsm\n",
    "    \n",
    "    save_loss_name = 'supPixel'\n",
    "    loss_fn = losses.crps2d_tf_dense_test2\n",
    "\n",
    "elif testing_scenario == 'attention':\n",
    "    import modelRzsmReluAttention as UNETRzsm\n",
    "    \n",
    "    save_loss_name = 'attention'\n",
    "    loss_fn = losses.crps2d_tf_dense_test2\n",
    "    \n",
    "elif testing_scenario == 'None':\n",
    "    import modelRzsm2DdropoutRelu as UNETRzsm\n",
    "    \n",
    "    save_loss_name = ''\n",
    "    loss_fn = losses.crps2d_tf\n",
    "\n",
    "elif testing_scenario == 'denseLarge':\n",
    "    import modelRzsmReluExtraConv as UNETRzsm\n",
    "\n",
    "    save_loss_name = 'denseLarge'\n",
    "    loss_fn = losses.crps2d_tf_dense_test2\n",
    "    \n",
    "elif testing_scenario == 'basic':\n",
    "    import basicUNET as UNETRzsm\n",
    "\n",
    "    save_loss_name = testing_scenario\n",
    "    loss_fn = losses.crps2d_tf\n",
    "\n",
    "elif testing_scenario == 'regularResidual':\n",
    "    #For predicting residuals\n",
    "    import modelRzsmReluExtraConvResidual as UNETRzsm\n",
    "\n",
    "    save_loss_name = 'regularResidual'\n",
    "    loss_fn = losses.crps2d_tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afaa26b2-3d09-43c4-90c2-b3adf94d4126",
   "metadata": {
    "tags": []
   },
   "source": [
    "# This script will load data based on specific lead times that we want to experiment with and what Experiments we choose to run"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fe39e5b-a435-4b47-8272-b0fc8c20c1c8",
   "metadata": {},
   "source": [
    "# Week 1 (lead index 6 of the forecast)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cf62daf-7f99-475f-bc39-5eefe7c31436",
   "metadata": {
    "tags": []
   },
   "source": [
    "| Ex. Number/Name | Obs. RZSM Inputs | Obs. Other Inputs                    | UNET predicted Inputs (N>=2)     |Reforecast Inputs| Prediction Lead Week/Variables | Activation function | Loss function | Batch size |\n",
    "| ----------------| -----------------| ------------------------------------ | -------------------      |--------          | -------------------| ---------------------| ------------------------| ------------|\n",
    "| 0 - EX0         | None             | None                                 | None                     | RZSM, Wk 1-N| Wk N     -  RZSM |              Relu             | CRPS experimental| 66\n",
    "| 1 - EX1         | Wk. lags 1-3    | pwat,spfh,tmax,z200,diff_temp lags 1-3 | RZSM Wk 1-N |        None |  Wk N     -  RZSM |             Relu             | CRPS experimental | 66\n",
    "| 2 - EX2         | Wk. lags 1-6   | pwat,spfh,tmax,z200,diff_temp lags 1-3  | RZSM Wk 1-N          |  None |  Wk N     -  RZSM |       Relu             | CRPS experimental| 66\n",
    "| 3 - EX3         | Wk. lags 1-9    | pwat,spfh,tmax,z200,diff_temp lags 1-3 | RZSM Wk 1-N         |  None |  Wk N     -  RZSM |       Relu             | CRPS experimental| 66\n",
    "| 4 - EX4         | Wk. lags 1-12    | pwat,spfh,tmax,z200,diff_temp lags 1-3| RZSM Wk 1-N         |  None |  Wk N     -  RZSM |      Relu             | CRPS experimental| 66\n",
    "| 5 - EX5         | Wk. lags 1-3   | None                                   | None                   | RZSM, week N | Wk N     -  RZSM  |         Relu             | CRPS experimental| 66\n",
    "| 6 - EX6         | Wk. lags 1-6   | None                                     | None                   |RZSM, week N  | Wk N     -  RZSM  |        Relu             | CRPS experimental| 66\n",
    "| 7 - EX7         | Wk. lags 1-9    | None                                | None                   |RZSM, week N  | Wk N     -  RZSM  |         Relu             | CRPS experimental |66\n",
    "| 8 - EX8         | Wk. lags 1-12    | None                                  | None                   |RZSM, week N  | Wk N     -  RZSM |         Relu             | CRPS experimental | 66\n",
    "| 9 - EX9         | Wk. lags 1-3    |pwat,spfh,tmax,z200,diff_temp lags 1-3  | RZSM Wk 1-N                  |RZSM  week N  | Wk N     -  RZSM  |         Relu             | CRPS experimental| 66\n",
    "| 10 - EX10       | Wk. lags 1-6    |pwat,spfh,tmax,z200,diff_temp  lags 1-3 | RZSM Wk 1-N                  |RZSM  week N  |Wk N     -  RZSM   |         Relu             | CRPS experimental| 66\n",
    "| 11 - EX11       | Wk. lags 1-9    |pwat,spfh,tmax,z200,diff_temp  lags 1-3 | RZSM Wk 1-N                  |RZSM  week N  | Wk N     -  RZSM  |         Relu             | CRPS experimental| 66\n",
    "| 12 - EX12       | Wk. lags 1-12   |pwat,spfh,tmax,z200,diff_temp lags 1-3  | RZSM Wk 1-N                  |RZSM  week N  | Wk N     -  RZSM  |         Relu             | CRPS experimental| 66\n",
    "| 13 - EX13       | None             | None                                 | None                     | RZSM week N| Wk N     -  RZSM |              Relu             | CRPS experimental| 66\n",
    "| 14 - EX14         | Wk. lags 1-3    | pwat,spfh,tmax,z200,diff_temp lags 1-3 | None |        None |  Wk N     -  RZSM |             Relu             | CRPS experimental | 66\n",
    "| 15 - EX15         | Wk. lags 1-6   | pwat,spfh,tmax,z200,diff_temp lags 1-3  | None             |  None |  Wk N     -  RZSM |       Relu             | CRPS experimental| 66\n",
    "| 16 - EX16         | Wk. lags 1-9    | pwat,spfh,tmax,z200,diff_temp lags 1-3 | None            |  None|  Wk N     -  RZSM |       Relu             | CRPS experimental| 66\n",
    "| 17 - EX17        | Wk. lags 1-12    | pwat,spfh,tmax,z200,diff_temp lags 1-3| None            |  None|  Wk N     -  RZSM |      Relu             | CRPS experimental| 66\n",
    "| 18 - EX18         | Wk. lags 1-3   | None                                   | RZSM Wk 1-N                 | RZSM, week N | Wk N     -  RZSM  |         Relu             | CRPS experimental| 66\n",
    "| 19 - EX19         | Wk. lags 1-6   | None                                     | RZSM Wk 1-N                  |RZSM, week N  | Wk N     -  RZSM  |        Relu             | CRPS experimental| 66\n",
    "| 20 - EX20         | Wk. lags 1-9    | None                                | RZSM Wk 1-N                  |RZSM, week N  | Wk N     -  RZSM  |         Relu             | CRPS experimental |66\n",
    "| 21 - EX21         | Wk. lags 1-12    | None                                  | RZSM Wk 1-N                   |RZSM, week N  | Wk N     -  RZSM |         Relu             | CRPS experimental | 66\n",
    "| 22 - EX22         | Wk. lags 1-3   | None                                   | None                   | None | Wk N     -  RZSM  |         Relu             | CRPS experimental| 66\n",
    "| 23 - EX23         | Wk. lags 1-6   | None                                     | None                   |None  | Wk N     -  RZSM  |        Relu             | CRPS experimental| 66\n",
    "| 24 - EX24         | Wk. lags 1-9    | None                                | None                   |None  | Wk N     -  RZSM  |         Relu             | CRPS experimental |66\n",
    "| 25 - EX25         | Wk. lags 1-12    | None                                  | None                   |None  | Wk N     -  RZSM |         Relu             | CRPS experimental | 66\n",
    "| 26 - EX26         | None    | None                                  | None                   |Wk 1-N (choose best models)  | Wk N     -  RZSM |         Relu             | CRPS experimental | 66\n",
    "| 27 - EX27         | Wk. lags 1-3    |pwat,spfh,tmax,z200,diff_temp lags 1-3  |  None                   |Wk1 RZSM,tmax, diff_temp, z200, pwat, spfh  | Wk N     -  RZSM  |         Relu             | CRPS experimental| 66 (like EX9)\n",
    "| 28 - EX28         | Wk. lags 1-6    |pwat,spfh,tmax,z200,diff_temp lags 1-3  |  None                   |Wk1 RZSM,tmax, diff_temp, z200, pwat, spfh  | Wk N     -  RZSM  |         Relu             | CRPS experimental| 66 (like EX10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f3bc1a4-0171-4e83-9601-76c524bbf735",
   "metadata": {
    "tags": []
   },
   "source": [
    "# EX 1-4 - Testing if the prediction of previous week adds value (but don't include the current week that is trying to be predicted). Observation driven but with a prediction.\n",
    "# EX 14-17 - Testing if the prediction of previous week adds value (but don't include the current week that is trying to be predicted). Purely observation driven.\n",
    "# EX 5-8 - Testing if adding other observations (pwat, spfh, etc) has an increase or decrease in skill.\n",
    "# EX 18-21 - Seeing if adding the previous week gains additional skill\n",
    "# EX 22-25 - Purely observation driven. Only soil moisture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1674ec3d-e9f4-415d-84b7-cfcd0a50e0dc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "input_directory = f'Data/model_npy_inputs/{region_name}/Model_input_data' #For inputs into the model\n",
    "verification_directory = f'Data/model_npy_inputs/{region_name}/Verification_data' #For observation verification\n",
    "start_of_forecast_init = '2000-01-05'\n",
    "end_of_forecast_init = '2019-12-25'\n",
    "\n",
    "global training_size_shape\n",
    "training_size_shape = np.array((9185,48,96))\n",
    "\n",
    "global validation_testing_size_shape\n",
    "validation_testing_size_shape = np.array((1144,48,96))\n",
    "\n",
    "'''This decides how many lag weeks we have for data such as pwat, z200, tmax, etc'''\n",
    "global observation_lag_list_not_RZSM\n",
    "#This is for observations pwat, z200, spfh, tmax, diff_temp variables used as predictors\n",
    "#These are the day lags which were already computed as the 7-day rolling mean\n",
    "\n",
    "observation_lag_list_not_RZSM = [-1,-7,-14] \n",
    "\n",
    "global train_start, train_end, val_start, val_end, test_start, test_end\n",
    "train_start = '2000-01-01'\n",
    "train_end = '2015-12-31'\n",
    "\n",
    "val_start = '2016-01-01'\n",
    "val_end = '2017-12-31'\n",
    "\n",
    "test_start = '2018-01-01'\n",
    "test_end = '2019-12-31'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5e3530f0-bd36-49f6-95c7-809be77583f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_all_data_EX0(lead, num_lags_obs_RZSM, include_lags_obs_pwat_spfh_tmax, include_reforecast_or_not, observation_lag_list_not_RZSM, lag_integer_list, input_directory,training_size_shape,validation_testing_size_shape,RZSM_or_Tmax_or_both,addtl_experiment,experiment_test):\n",
    "\n",
    "    soil_var = 'soilw_bgrnd' #This is the observation verification variable name\n",
    "    \n",
    "    channel_list = []\n",
    "\n",
    "    if addtl_experiment == False:\n",
    "        assert lead >=1, 'Lead must be >=1, do not look at Week 0'\n",
    "        \n",
    "        lead_list = np.arange(1,lead+1)\n",
    "\n",
    "        print(f'Only adding Reforecast data as input for leads {list(lead_list)}.')\n",
    "\n",
    "        training_input = np.empty(shape = (training_size_shape[0],training_size_shape[1],training_size_shape[2],lead)) #We are adding both RZSM and/or Tmax (so use * 2)\n",
    "        validation_input = np.empty(shape = (validation_testing_size_shape[0],validation_testing_size_shape[1],validation_testing_size_shape[2],lead))\n",
    "        testing_input = np.empty(shape = (validation_testing_size_shape[0],validation_testing_size_shape[1],validation_testing_size_shape[2],lead))\n",
    "\n",
    "        #Add reforecast data\n",
    "        for idx,lead in enumerate(lead_list):\n",
    "            channel_list.append(f'RZSM_ref_lead{lead}')\n",
    "\n",
    "            training_input, validation_input, testing_input = pred.add_reforecast_by_lag(training_input, validation_input, testing_input, lead, input_directory,soil_var, idx,ref_source,final_testing_year)\n",
    "\n",
    "        print(f'Index idx value is {idx}. Done adding RZSM obs.')    \n",
    "\n",
    "    \n",
    "    elif addtl_experiment == True:\n",
    "        print(f'Only adding Reforecast data as input for lead {lead}.')\n",
    "\n",
    "        lead_add = 1 #We are only adding the current week of reforecast\n",
    "        lead_list = [lead]\n",
    "\n",
    "        training_input = np.empty(shape = (training_size_shape[0],training_size_shape[1],training_size_shape[2],lead_add)) #We are adding both RZSM and Tmax (so use * 2)\n",
    "        validation_input = np.empty(shape = (validation_testing_size_shape[0],validation_testing_size_shape[1],validation_testing_size_shape[2],lead_add))\n",
    "        testing_input = np.empty(shape = (validation_testing_size_shape[0],validation_testing_size_shape[1],validation_testing_size_shape[2],lead_add))\n",
    "\n",
    "        channel_list.append(f'RZSM_ref_lead{lead}')\n",
    "\n",
    "        idx = 0\n",
    "        training_input, validation_input, testing_input = pred.add_reforecast_by_lag(training_input, validation_input, testing_input, lead, input_directory,soil_var, idx,ref_source,final_testing_year)\n",
    "\n",
    "    return(training_input, validation_input, testing_input, channel_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "734ec27f-2cfe-4c54-8735-c54b34588e05",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_all_data_EX1_EX2_EX3_EX4_after_week_0(lead, num_lags_obs_RZSM, include_lags_obs_pwat_spfh_tmax, include_reforecast_or_not, \n",
    "                                           observation_lag_list_not_RZSM, lag_integer_list, input_directory,training_size_shape,\n",
    "                                           validation_testing_size_shape,experiment_name,RZSM_or_Tmax_or_both,addtl_experiment,experiment_test, \n",
    "                                               experiment_name_out,ref_source,final_testing_year):\n",
    "    channel_list = []\n",
    "    \n",
    "    #Reforecast predictors\n",
    "    var_list = ['pwat_eatm', 'spfh_2m', 'tmax_2m', 'diff_temp_2m', 'hgt_pres']\n",
    "\n",
    "    assert lead >=1, 'Lead must be >=1, we are not testing week 0 anymore'\n",
    "\n",
    "    if addtl_experiment == False:\n",
    "        #Get the number of extra channels to add from previous weeks predictions\n",
    "        if RZSM_or_Tmax_or_both == 'both':\n",
    "            add_channels = lead * 2\n",
    "        else:\n",
    "            #Also add the number of channels according to the lead. If lead == 1, then only add lead 1 current week. If lead == 2, add one channel for week 2 and one channel for the prediction from Week 1\n",
    "            if lead > 1:\n",
    "                add_channels = lead - 1\n",
    "            else:\n",
    "                add_channels = 0\n",
    "\n",
    "\n",
    "\n",
    "        training_input = np.empty(shape = (training_size_shape[0],training_size_shape[1],training_size_shape[2],len(lag_integer_list)+len(var_list)*3+add_channels))\n",
    "        validation_input = np.empty(shape = (validation_testing_size_shape[0],validation_testing_size_shape[1],validation_testing_size_shape[2],len(lag_integer_list)+len(var_list)*3+add_channels))\n",
    "        testing_input = np.empty(shape = (validation_testing_size_shape[0],validation_testing_size_shape[1],validation_testing_size_shape[2],len(lag_integer_list)+len(var_list)*3+add_channels))\n",
    "\n",
    "        print(f'Training shape input is {training_input.shape}')\n",
    "\n",
    "        #Add RZSM observations first\n",
    "        for idx,lag in enumerate(lag_integer_list):\n",
    "            channel_list.append(f'RZSM_obs_lag{lag}')\n",
    "            training_input, validation_input, testing_input = pred.add_obs_RZSM_by_lag(training_input, validation_input, testing_input, lag, input_directory, idx, final_testing_year)\n",
    "\n",
    "        print(f'Index idx value is {idx}. Done adding RZSM obs.')\n",
    "        \n",
    "        RZSM_train_obs, RZSM_validation_obs = pred.return_masking_objects_for_RZSM(input_directory,final_testing_year)\n",
    "\n",
    "        \n",
    "        for variable in var_list:\n",
    "            channel_name_output = pred.return_channel_name(variable)\n",
    "            for lag in observation_lag_list_not_RZSM:\n",
    "                channel_list.append(f'{channel_name_output}_obs_lag{lag}')\n",
    "                idx+=1\n",
    "                #Observations adding\n",
    "                training_input, validation_input, testing_input = pred.add_obs_other_observations_by_lag(training_input, validation_input, testing_input, lag, input_directory, variable, idx, final_testing_year)\n",
    "     \n",
    "        \n",
    "            print(f'Index idx value is {idx}. Done adding {variable} obs.')\n",
    "    \n",
    "        if lead in [0,1]:\n",
    "            pass\n",
    "        else:\n",
    "            #Now we need to load our data from the previous weeks\n",
    "            for lead_previous in range(1,lead):\n",
    "                print(f'Working on previous lead: Week {lead_previous}')\n",
    "                # break\n",
    "    \n",
    "                pred_dir = f'predictions/{region_name}/Wk{lead_previous}_training_validation'\n",
    "                testing_dir = f'predictions/{region_name}/Wk{lead_previous}_testing'\n",
    "    \n",
    "                os.system(f'mkdir -p {pred_dir}')\n",
    "    \n",
    "                training_prediction_name= f'{pred_dir}/Wk{lead_previous}_training_{experiment_name_out}.npy'\n",
    "                validation_prediction_name = f'{pred_dir}/Wk{lead_previous}_validation_{experiment_name_out}.npy'\n",
    "                testing_prediction_name = f'{testing_dir}/Wk{lead_previous}_testing_{experiment_name_out}.npy'\n",
    "    \n",
    "                testing_prediction = np.load(testing_prediction_name)\n",
    "                \n",
    "                '''Load the training and validation predictions if they exist'''\n",
    "                if os.path.exists(training_prediction_name):\n",
    "                    print(f'Loading data from previous week lead {lead_previous}')\n",
    "                    training_prediction = np.load(training_prediction_name)\n",
    "                    validation_prediction =np.load(validation_prediction_name)\n",
    "    \n",
    "                else:\n",
    "                    print(f'Creating prediction data from previous week lead {lead_previous}')\n",
    "                    '''If they don't exist..... load model for previous week'''\n",
    "                    model = load_model(f'checkpoints/Wk{lead_previous}/Wk{lead_previous}_{experiment_name_out}',compile=False) #don't need the custom loss function for predictions\n",
    "    \n",
    "                    training_input_previous = np.load(f'Data/model_npy_inputs/{region_name}/Wk{lead_previous}_EX_input_data/{experiment_name_out}_training_input.npy')\n",
    "                    validation_input_previous = np.load(f'Data/model_npy_inputs/{region_name}/Wk{lead_previous}_EX_input_data/{experiment_name_out}_validation_input.npy')\n",
    "                    testing_input_previous = np.load(f'Data/model_npy_inputs/{region_name}/Wk{lead_previous}_EX_input_data/{experiment_name_out}_testing_input.npy')\n",
    "    \n",
    "                    '''Make predictions and save data to load for previous use'''\n",
    "                    training_prediction = model.predict(training_input_previous) #Just for unit checking\n",
    "                    np.save(training_prediction_name,training_prediction)\n",
    "    \n",
    "                    validation_prediction = model.predict(validation_input_previous)\n",
    "                    np.save(validation_prediction_name,validation_prediction)\n",
    "    \n",
    "                ############# ADD BACK TO CREATED ARRAY ###############################\n",
    "                '''Now get the best UNET index prediction for RZSM and Tmax. Because the UNET plus plus produces 4 different outputs'''\n",
    "                min_RZSM_index,min_tmax_index = f.load_loss_csv_bias_correction(lead_previous,experiment_name_out,RZSM_or_Tmax_or_both,region_name)\n",
    "    \n",
    "                if np.array(training_prediction).shape[0] == 8 and RZSM_or_Tmax_or_both == 'both':\n",
    "                    min_tmax_index = min_tmax_index+4 #Because index values 0-3 are RZSM and 4-7 are Tmax\n",
    "                elif np.array(training_prediction).shape[0] == 6 and RZSM_or_Tmax_or_both == 'both':\n",
    "                    min_tmax_index = min_tmax_index + 3 #Because index values are 0-2 for RZSM and 3-5 for Tmax\n",
    "                '''Now split the training and validation data back into RZSM and/or Tmax'''\n",
    "    \n",
    "    \n",
    "                train_RZSM = np.array(training_prediction)[min_RZSM_index,:,:,:,:]\n",
    "                val_RZSM = np.array(validation_prediction)[min_RZSM_index,:,:,:,:]\n",
    "                test_RZSM = np.array(testing_prediction)[min_RZSM_index,:,:,:,:]\n",
    "\n",
    "    \n",
    "                '''Make sure we mask RZSM values which aren't on land'''\n",
    "                train_RZSM = np.where(RZSM_train_obs==0,0,train_RZSM)\n",
    "                val_RZSM = np.where(RZSM_validation_obs==0,0,val_RZSM)\n",
    "                test_RZSM = np.where(RZSM_validation_obs==0,0,test_RZSM)\n",
    "    \n",
    "                #Now add back to the data\n",
    "                '''Now add back to the newly created dataset'''\n",
    "                idx+=1\n",
    "                channel_list.append(f'RZSM_prediction_lead{lead_previous}')\n",
    "                print(f'Adding RZSM training, validation, testing into index {idx}')\n",
    "                training_input[:,:,:,idx] = train_RZSM[:,:,:,0]\n",
    "                validation_input[:,:,:,idx] = val_RZSM[:,:,:,0]\n",
    "                testing_input[:,:,:,idx] = test_RZSM[:,:,:,0]\n",
    "    \n",
    "            if RZSM_or_Tmax_or_both == 'both':\n",
    "                channel_list.append(f'tmax_prediction_lead{lead_previous}')\n",
    "                idx+=1\n",
    "                print(f'Adding Tmax training, validation, testing into index {idx}')\n",
    "                training_input[:,:,:,idx] = train_tmax[:,:,:,0]\n",
    "                validation_input[:,:,:,idx] = val_tmax[:,:,:,0]\n",
    "                testing_input[:,:,:,idx] = test_tmax[:,:,:,0]\n",
    "    \n",
    "\n",
    "            print('Final channel of input is the following (just make sure it has zeros for RZSM)')\n",
    "            print(training_input[0,:,:,-1])\n",
    "\n",
    "    elif addtl_experiment == True:\n",
    "        #Get the number of extra channels to add from previous weeks predictions\n",
    "        add_channels = 0\n",
    "\n",
    "\n",
    "        training_input = np.empty(shape = (training_size_shape[0],training_size_shape[1],training_size_shape[2],len(lag_integer_list)+len(observation_lag_list_not_RZSM)*5+add_channels))\n",
    "        validation_input = np.empty(shape = (validation_testing_size_shape[0],validation_testing_size_shape[1],validation_testing_size_shape[2],len(lag_integer_list)+len(observation_lag_list_not_RZSM)*5+add_channels))\n",
    "        testing_input = np.empty(shape = (validation_testing_size_shape[0],validation_testing_size_shape[1],validation_testing_size_shape[2],len(lag_integer_list)+len(observation_lag_list_not_RZSM)*5+add_channels))\n",
    "\n",
    "\n",
    "        #Add RZSM observations first\n",
    "        for idx,lag in enumerate(lag_integer_list):\n",
    "            channel_list.append(f'RZSM_obs_lag{lag}')\n",
    "            training_input, validation_input, testing_input = pred.add_obs_RZSM_by_lag(training_input, validation_input, testing_input, lag, input_directory, idx, final_testing_year)\n",
    "\n",
    "        print(f'Index idx value is {idx}. Done adding RZSM obs.')    \n",
    "        \n",
    "        RZSM_train_obs, RZSM_validation_obs = pred.return_masking_objects_for_RZSM(input_directory, final_testing_year)\n",
    "\n",
    "\n",
    "        for variable in var_list:\n",
    "            channel_name_output = pred.return_channel_name(variable)\n",
    "            for lag in observation_lag_list_not_RZSM:\n",
    "                channel_list.append(f'{channel_name_output}_obs_lag{lag}')\n",
    "                idx+=1\n",
    "                #Observations adding\n",
    "                training_input, validation_input, testing_input = pred.add_obs_other_observations_by_lag(training_input, validation_input, testing_input, lag, input_directory, variable, idx,final_testing_year)\n",
    "     \n",
    "        \n",
    "            print(f'Index idx value is {idx}. Done adding {variable} obs.')\n",
    "\n",
    "        print('Final channel of input is the following (just make sure it has zeros for RZSM)')\n",
    "        print(training_input[0,:,:,-1])\n",
    "\n",
    "    return(training_input, validation_input, testing_input,channel_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b76505fe-47ac-4edc-aab5-108a48d4f8e2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_all_data_EX5_EX6_EX7_EX8_experiments(lead, num_lags_obs_RZSM, include_lags_obs_pwat_spfh_tmax, \n",
    "                                              include_reforecast_or_not, observation_lag_list_not_RZSM, lag_integer_list,\n",
    "                                              input_directory,training_size_shape,validation_testing_size_shape,RZSM_or_Tmax_or_both,experiment_test,experiment_name,experiment_name_out):\n",
    "    print('\\nUsing observations as predictions and forecast lead week 1\\n')\n",
    "    #Observations RZSM\n",
    "    '''We need to combine all the RZSM files into 1 single dictionary for later processing'''\n",
    "    \n",
    "    channel_list = []\n",
    "\n",
    "    assert lead >=1, 'We are only looking at weekly leads 1-5, cannot do 0 lead'\n",
    "    \n",
    "    #Reforecast predictors\n",
    "    var_list = ['pwat_eatm', 'spfh_2m', 'tmax_2m', 'diff_temp_2m', 'hgt_pres']\n",
    "    \n",
    "    print(f'Experiment name is {experiment_name_out}')\n",
    "    \n",
    "    if experiment_name in ['EX22','EX23','EX24','EX25']:\n",
    "        #This is only a bias correction using observations (no reforecast input at all)\n",
    "        lead_add = 0\n",
    "    elif experiment_name in ['EX5','EX6','EX7','EX8']:\n",
    "        #This is only a bias correction using observations and the current week of reforecast as inputs\n",
    "        lead_add = 1\n",
    "    elif experiment_name in ['EX18','EX19','EX20','EX21']:\n",
    "        if lead ==1:\n",
    "            lead_add = 1 #Only adding the current week of forecast\n",
    "        else:\n",
    "            lead_add = lead #Adding previous weeks forecast and the current week\n",
    "\n",
    "    print(f'Adding {lead_add} to channel list from reforecast.')\n",
    "\n",
    "        \n",
    "    training_input = np.empty(shape = (training_size_shape[0],training_size_shape[1],training_size_shape[2],len(lag_integer_list)+ lead_add))\n",
    "    validation_input = np.empty(shape = (validation_testing_size_shape[0],validation_testing_size_shape[1],validation_testing_size_shape[2],len(lag_integer_list) + lead_add))\n",
    "    testing_input = np.empty(shape = (validation_testing_size_shape[0],validation_testing_size_shape[1],validation_testing_size_shape[2],len(lag_integer_list)+ lead_add))\n",
    "    \n",
    "    print(f'Training shape: {training_input.shape}')\n",
    "    \n",
    "    #Add RZSM observations first\n",
    "    for idx,lag in enumerate(lag_integer_list):\n",
    "        channel_list.append(f'RZSM_obs_lag{lag}')\n",
    "        training_input, validation_input, testing_input = pred.add_obs_RZSM_by_lag(training_input, validation_input, testing_input, lag, input_directory, idx,final_testing_year)\n",
    "\n",
    "    print(f'Index idx value is {idx}. Done adding RZSM obs.')\n",
    "    \n",
    "    #For masking\n",
    "    RZSM_train_obs, RZSM_validation_obs = pred.return_masking_objects_for_RZSM(input_directory,final_testing_year)\n",
    "\n",
    "    if experiment_name in ['EX5','EX6','EX7','EX8']:\n",
    "        #We only need to add the current reforecast week\n",
    "        #Add final predictor for the current week of RZSM within reforecast\n",
    "        idx+=1\n",
    "        soil_var = 'soilw_bgrnd'\n",
    "        channel_name_output = pred.return_channel_name(soil_var)\n",
    "        channel_list.append(f'{channel_name_output}_ref_lead{lead}')\n",
    "    \n",
    "        print(f'And finally adding RZSM week {lead} from reforecast as a predictor')\n",
    "        \n",
    "        training_input, validation_input, testing_input = pred.add_reforecast_by_lag(training_input, validation_input, testing_input, lead, input_directory,soil_var, idx, ref_source, final_testing_year)\n",
    "        \n",
    "        return(training_input, validation_input, testing_input, channel_list)\n",
    "\n",
    "    elif experiment_name in ['EX22','EX23','EX24','EX25']:\n",
    "         #We are not adding any additional predictors\n",
    "         return(training_input, validation_input, testing_input, channel_list)\n",
    "        \n",
    "    \n",
    "    else:\n",
    "        assert lead >= 2, 'If trying to run EX18-EX21, DO NOT RUN with week 1 data. Start with Week 2'\n",
    "\n",
    "        #Now we need to load our data from the previous weeks\n",
    "        for lead_previous in range(1,lead):\n",
    "\n",
    "            #To not have to re-run a bunch more models, we can re-use the training from a previous week\n",
    "\n",
    "            if lead_previous == 1:\n",
    "                if experiment_name == 'EX18':\n",
    "                    prev_experiment = f'EX5_regular_RZSM'\n",
    "                        \n",
    "                elif experiment_name == 'EX19':\n",
    "                    prev_experiment = f'EX6_regular_RZSM'    \n",
    "                    \n",
    "                elif experiment_name == 'EX20':\n",
    "                    prev_experiment = f'EX7_regular_RZSM'  \n",
    "                    \n",
    "                elif experiment_name == 'EX21':\n",
    "                    prev_experiment = f'EX8_regular_RZSM'\n",
    "            else:\n",
    "                prev_experiment = experiment_name_out\n",
    "\n",
    "\n",
    "            print(f'Working on previous lead: Week {lead_previous}')\n",
    "            # break\n",
    "\n",
    "            pred_dir = f'predictions/{region_name}/Wk{lead_previous}_training_validation'\n",
    "            testing_dir = f'predictions/{region_name}/Wk{lead_previous}_testing'\n",
    "\n",
    "            os.system(f'mkdir -p {pred_dir}')\n",
    "\n",
    "            training_prediction_name= f'{pred_dir}/Wk{lead_previous}_training_{prev_experiment}.npy'\n",
    "            validation_prediction_name = f'{pred_dir}/Wk{lead_previous}_validation_{prev_experiment}.npy'\n",
    "            testing_prediction_name = f'{testing_dir}/Wk{lead_previous}_testing_{prev_experiment}.npy'\n",
    "\n",
    "    \n",
    "            testing_prediction = np.load(testing_prediction_name)\n",
    "            '''Load the training and validation predictions if they exist'''\n",
    "            \n",
    "            if os.path.exists(training_prediction_name):\n",
    "                print(f'Loading data from previous week lead {lead_previous}')\n",
    "                training_prediction = np.load(training_prediction_name)\n",
    "                validation_prediction =np.load(validation_prediction_name)\n",
    "\n",
    "            else:\n",
    "                print(f'Creating prediction data from previous week lead {lead_previous} from {prev_experiment}.')\n",
    "                '''If they don't exist..... load model for previous week'''\n",
    "                model = load_model(f'checkpoints/{region_name}/Wk{lead_previous}/Wk{lead_previous}_{prev_experiment}',compile=False) #don't need the custom loss function for predictions\n",
    "\n",
    "                training_input_previous = np.load(f'Data/model_npy_inputs/{region_name}/Wk{lead_previous}_EX_input_data/{prev_experiment}_training_input.npy')\n",
    "                validation_input_previous = np.load(f'Data/model_npy_inputs/{region_name}/Wk{lead_previous}_EX_input_data/{prev_experiment}_validation_input.npy')\n",
    "                testing_input_previous = np.load(f'Data/model_npy_inputs/{region_name}/Wk{lead_previous}_EX_input_data/{prev_experiment}_testing_input.npy')\n",
    "\n",
    "                '''Make predictions and save data to load for previous use'''\n",
    "                training_prediction = model.predict(training_input_previous) #Just for unit checking\n",
    "                np.save(training_prediction_name,training_prediction)\n",
    "\n",
    "                validation_prediction = model.predict(validation_input_previous)\n",
    "                np.save(validation_prediction_name,validation_prediction)\n",
    "\n",
    "            ############# ADD BACK TO CREATED ARRAY ###############################\n",
    "\n",
    "            train_RZSM = np.array(training_prediction)[-1,:,:,:,:]\n",
    "            val_RZSM = np.array(validation_prediction)[-1,:,:,:,:]\n",
    "            test_RZSM = np.array(testing_prediction)[-1,:,:,:,:]\n",
    "\n",
    "\n",
    "            '''Make sure we mask RZSM values which aren't on land'''\n",
    "            train_RZSM = np.where(RZSM_train_obs==0,0,train_RZSM)\n",
    "            val_RZSM = np.where(RZSM_validation_obs==0,0,val_RZSM)\n",
    "            test_RZSM = np.where(RZSM_validation_obs==0,0,test_RZSM)\n",
    "\n",
    "            #Now add back to the data\n",
    "            '''Now add back to the newly created dataset'''\n",
    "            idx+=1\n",
    "            channel_list.append(f'RZSM_prediction_lead{lead_previous}')\n",
    "            print(f'Adding RZSM training, validation, testing into index {idx}')\n",
    "            training_input[:,:,:,idx] = train_RZSM[:,:,:,0]\n",
    "            validation_input[:,:,:,idx] = val_RZSM[:,:,:,0]\n",
    "            testing_input[:,:,:,idx] = test_RZSM[:,:,:,0]\n",
    "\n",
    "\n",
    "        #Add final predictor for the current week of RZSM within reforecast\n",
    "        idx+=1\n",
    "        soil_var = 'soilw_bgrnd'\n",
    "        channel_name_output = pred.return_channel_name(soil_var)\n",
    "        channel_list.append(f'{channel_name_output}_ref_lead{lead}')\n",
    "    \n",
    "        print(f'And finally adding RZSM week {lead} from reforecast as a predictor')\n",
    "        \n",
    "        training_input, validation_input, testing_input = pred.add_reforecast_by_lag(training_input, validation_input, testing_input, lead, input_directory,soil_var, idx, ref_source, final_testing_year)\n",
    "    \n",
    "        print(f'Index idx value is {idx}. Done adding {soil_var} reforecast.')\n",
    "\n",
    "        print('Final channel of input is the following (just make sure it has zeros for RZSM)')\n",
    "        print(training_input[0,:,:,-1])\n",
    "\n",
    "\n",
    "        return(training_input, validation_input, testing_input, channel_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c30f7d9a-2690-4223-904a-83158fa830ce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_all_data_EX9_EX10_EX11_EX12_after_week_0(lead, num_lags_obs_RZSM, include_lags_obs_pwat_spfh_tmax, include_reforecast_or_not, \n",
    "                                           observation_lag_list_not_RZSM, lag_integer_list, input_directory,training_size_shape,\n",
    "                                           validation_testing_size_shape,experiment_name,RZSM_or_Tmax_or_both, experiment_test,region_name,experiment_name_out):\n",
    "    '''We need to combine all the RZSM files and all the observation data (pwat, spfh, tmax, diff_temp, z200) into one file. Also adding the RZSM reforecast data from RZSM and Tmax '''\n",
    "\n",
    "    channel_list = []\n",
    "    \n",
    "    #Reforecast predictors\n",
    "    var_list = ['pwat_eatm', 'spfh_2m', 'tmax_2m', 'diff_temp_2m', 'hgt_pres']\n",
    "\n",
    "    if experiment_test == 0:\n",
    "        add_channels = lead  \n",
    "        reforecast_predictors = False\n",
    "    elif (experiment_test >= 1) and (lead in [1,2]):\n",
    "        #This is adding 5 additional predictors (tmax, diff_temp, z200, pwat, spfh)\n",
    "        #Also add the number of channels according to the lead. If lead == 1, then only add lead 1 current week. If lead == 2, add one channel for week 2 and one channel for the prediction from Week 1\n",
    "        add_channels = lead  + len(var_list)\n",
    "        reforecast_predictors = True\n",
    "    elif (experiment_test >= 1) and (lead > 2):\n",
    "        add_channels = lead \n",
    "        reforecast_predictors = False\n",
    "            \n",
    "   \n",
    "    training_input = np.empty(shape = (training_size_shape[0],training_size_shape[1],training_size_shape[2],len(lag_integer_list)+len(var_list)*3+add_channels))\n",
    "    validation_input = np.empty(shape = (validation_testing_size_shape[0],validation_testing_size_shape[1],validation_testing_size_shape[2],len(lag_integer_list)+len(var_list)*3+add_channels))\n",
    "    testing_input = np.empty(shape = (validation_testing_size_shape[0],validation_testing_size_shape[1],validation_testing_size_shape[2],len(lag_integer_list)+len(var_list)*3+add_channels))\n",
    "    \n",
    "    print(f'Training input shape = {training_input.shape}')\n",
    "    \n",
    "    #Add RZSM observations first\n",
    "    for idx,lag in enumerate(lag_integer_list):\n",
    "        channel_list.append(f'RZSM_obs_lag{lag}')\n",
    "        training_input, validation_input, testing_input = pred.add_obs_RZSM_by_lag(training_input, validation_input, testing_input, lag, input_directory, idx, final_testing_year)\n",
    "        \n",
    "    print(f'Index idx value is {idx}. Done adding RZSM obs.')    \n",
    "    \n",
    "    RZSM_train_obs, RZSM_validation_obs = pred.return_masking_objects_for_RZSM(input_directory, final_testing_year)\n",
    "\n",
    "    for variable in var_list:\n",
    "        channel_name_output = pred.return_channel_name(variable)\n",
    "        for lag in observation_lag_list_not_RZSM:\n",
    "            channel_list.append(f'{channel_name_output}_obs_lag{lag}')\n",
    "            idx+=1\n",
    "            #Observations adding\n",
    "            training_input, validation_input, testing_input = pred.add_obs_other_observations_by_lag(training_input, validation_input, testing_input, lag, input_directory, variable, idx,final_testing_year)\n",
    " \n",
    "    \n",
    "        print(f'Index idx value is {idx}. Done adding {variable} obs.')\n",
    "    \n",
    "    ############################### NOW ADD THE PREDICTION DATA FROM PREVIOUS WEEK ################################################\n",
    "    #Now we need to load our data from the previous weeks \n",
    "    \n",
    "    if lead in [0, 1]:\n",
    "        #DO NOT INCLUDE LEAD 0 AS A PREDICTOR (FROM PREVIOUS WEEK)\n",
    "        pass\n",
    "    else:\n",
    "\n",
    "        for lead_previous in range(1,lead):\n",
    "            print(f'Adding previous RZSM prediction from week {lead_previous} as an input channel')\n",
    "            # break\n",
    "            \n",
    "            pred_dir = f'predictions/{region_name}/Wk{lead_previous}_training_validation'\n",
    "            testing_dir = f'predictions/{region_name}/Wk{lead_previous}_testing'\n",
    "            \n",
    "            os.system(f'mkdir -p {pred_dir}')\n",
    "            \n",
    "            training_prediction_name= f'{pred_dir}/Wk{lead_previous}_training_{experiment_name_out}.npy'\n",
    "            validation_prediction_name = f'{pred_dir}/Wk{lead_previous}_validation_{experiment_name_out}.npy'\n",
    "            testing_prediction_name = f'{testing_dir}/Wk{lead_previous}_testing_{experiment_name_out}.npy'\n",
    "            \n",
    "            testing_prediction = np.load(testing_prediction_name)\n",
    "            \n",
    "            '''Load the training and validation predictions if they exist'''\n",
    "            if os.path.exists(training_prediction_name):\n",
    "                print(f'Loading data from previous week lead {lead_previous}')\n",
    "                training_prediction = np.load(training_prediction_name)\n",
    "                validation_prediction =np.load(validation_prediction_name)\n",
    "                \n",
    "            else:\n",
    "                print(f'Creating prediction data from previous week lead {lead_previous}')\n",
    "                '''If they don't exist..... load model for previous week'''\n",
    "                model = load_model(f'checkpoints/Wk_{lead_previous}/Wk{lead_previous}_{experiment_name_out}',compile=False) #don't need the custom loss function for predictions\n",
    "                \n",
    "                training_input_previous = np.load(f'Data/model_npy_inputs/{region_name}/Wk{lead_previous}_EX_input_data/{experiment_name_out}_training_input.npy')\n",
    "                validation_input_previous = np.load(f'Data/model_npy_inputs/{region_name}/Wk{lead_previous}_EX_input_data/{experiment_name_out}_validation_input.npy')\n",
    "                testing_input_previous = np.load(f'Data/model_npy_inputs/{region_name}/Wk{lead_previous}_EX_input_data/{experiment_name_out}_testing_input.npy')\n",
    "                \n",
    "                '''Make predictions and save data to load for previous use'''\n",
    "                training_prediction = model.predict(training_input_previous) #Just for unit checking\n",
    "                np.save(training_prediction_name,training_prediction)\n",
    "                \n",
    "                validation_prediction = model.predict(validation_input_previous)\n",
    "                np.save(validation_prediction_name,validation_prediction)\n",
    "            \n",
    "            \n",
    "            ############# ADD BACK TO CREATED ARRAY ###############################\n",
    "            '''Now get the best UNET index prediction for RZSM and Tmax. Because the UNET plus plus produces 4 different outputs'''\n",
    "            min_RZSM_index,min_tmax_index = f.load_loss_csv_bias_correction(lead_previous,experiment_name_out,RZSM_or_Tmax_or_both,region_name)\n",
    "    \n",
    "            if np.array(training_prediction).shape[0] == 8 and RZSM_or_Tmax_or_both == 'both':\n",
    "                min_tmax_index = min_tmax_index+4 #Because index values 0-3 are RZSM and 4-7 are Tmax\n",
    "            elif np.array(training_prediction).shape[0] == 6 and RZSM_or_Tmax_or_both == 'both':\n",
    "                min_tmax_index = min_tmax_index + 3 #Because index values are 0-2 for RZSM and 3-5 for Tmax\n",
    "            '''Now split the training and validation data back into RZSM and/or Tmax'''\n",
    "            \n",
    "            \n",
    "            train_RZSM = np.array(training_prediction)[min_RZSM_index,:,:,:,:]\n",
    "            val_RZSM = np.array(validation_prediction)[min_RZSM_index,:,:,:,:]\n",
    "            test_RZSM = np.array(testing_prediction)[min_RZSM_index,:,:,:,:]\n",
    "\n",
    "    \n",
    "            '''Make sure we mask RZSM values which aren't on land'''\n",
    "            train_RZSM = np.where(RZSM_train_obs==0,0,train_RZSM)\n",
    "            val_RZSM = np.where(RZSM_validation_obs==0,0,val_RZSM)\n",
    "            test_RZSM = np.where(RZSM_validation_obs==0,0,test_RZSM)\n",
    "    \n",
    "            #Now add back to the data\n",
    "            '''Now add back to the newly created dataset'''\n",
    "            idx+=1\n",
    "            channel_list.append(f'RZSM_prediction_lead{lead_previous}')\n",
    "            print(f'Adding RZSM training, validation, testing into index {idx}')\n",
    "            training_input[:,:,:,idx] = train_RZSM[:,:,:,0]\n",
    "            validation_input[:,:,:,idx] = val_RZSM[:,:,:,0]\n",
    "            testing_input[:,:,:,idx] = test_RZSM[:,:,:,0]\n",
    "\n",
    "    \n",
    "    ############################### NOW ADD THE REFORECAST DATA FROM THE WEEK TO BE PREDICTED ################################################\n",
    "    \n",
    "    #Add predictors from the reforecast model\n",
    "    if (lead in [1,2]) and (experiment_test == 1):\n",
    "        print(f'Adding current reforecast data from week {lead} for vars {(var_list)}')  \n",
    "        #Only add these for week 1 and 2. \n",
    "        for variable in var_list:\n",
    "            idx+=1\n",
    "            channel_name_output = pred.return_channel_name(variable)\n",
    "            \n",
    "            channel_list.append(f'{channel_name_output}_ref_lead{lead}')\n",
    "            \n",
    "            training_input, validation_input, testing_input = pred.add_reforecast_by_lag(training_input, validation_input, testing_input, lead, input_directory, variable, idx, ref_source, final_testing_year)\n",
    "    \n",
    "            print(f'Index idx value is {idx}. Done adding {variable} reforecast.')\n",
    "\n",
    "    #Add final predictor for the current week of RZSM within reforecast\n",
    "    idx+=1\n",
    "    soil_var = 'soilw_bgrnd'\n",
    "    channel_name_output = pred.return_channel_name(soil_var)\n",
    "    channel_list.append(f'{channel_name_output}_ref_lead{lead}')\n",
    "\n",
    "    print(f'And finally adding RZSM week {lead} from reforecast as a predictor')\n",
    "    \n",
    "    training_input, validation_input, testing_input = pred.add_reforecast_by_lag(training_input, validation_input, testing_input, lead, input_directory,soil_var, idx, ref_source, final_testing_year)\n",
    "\n",
    "    print(f'Index idx value is {idx}. Done adding {soil_var} reforecast.')\n",
    "\n",
    "    print('Final channel of input is the following (just make sure it has zeros for RZSM)')\n",
    "    print(training_input[0,:,:,-1])\n",
    "\n",
    "    return(training_input, validation_input, testing_input,channel_list)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9e58697c-2d96-475e-ab05-17adc7a0f00f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_all_data_EX29_after_week_0(lead, num_lags_obs_RZSM, include_lags_obs_pwat_spfh_tmax, include_reforecast_or_not, \n",
    "                                           observation_lag_list_not_RZSM, lag_integer_list, input_directory,training_size_shape,\n",
    "                                           validation_testing_size_shape,experiment_name,RZSM_or_Tmax_or_both, experiment_test,region_name,experiment_name_out):\n",
    "    '''We need to combine all the RZSM files and all the observation data (pwat, spfh, tmax, diff_temp, z200) into one file. Also adding the RZSM reforecast data from RZSM and Tmax '''\n",
    "\n",
    "    channel_list = []\n",
    "    \n",
    "    #Reforecast predictors\n",
    "    var_list = ['pwat_eatm', 'spfh_2m', 'tmax_2m', 'diff_temp_2m', 'hgt_pres']\n",
    "\n",
    "    if (experiment_test == 2) and (lead ==1):\n",
    "        #This is adding 5 additional predictors (tmax, diff_temp, z200, pwat, spfh)\n",
    "        #Also add the number of channels according to the lead. If lead == 1, then only add lead 1 current week. If lead == 2, add one channel for week 2 and one channel for the prediction from Week 1\n",
    "        add_channels = len(lag_integer_list)+len(var_list)*2  #Only add a single prediction week from these\n",
    "        reforecast_predictors = True\n",
    "    elif (experiment_test == 2) and (lead ==2):\n",
    "        add_channels = len(lag_integer_list) + len(var_list)*2 + (lead -1) \n",
    "        reforecast_predictors = True   \n",
    "    elif (experiment_test == 2) and (lead > 2):\n",
    "        add_channels = len(lag_integer_list) + (lead -1) \n",
    "        reforecast_predictors = False  \n",
    "        \n",
    "    training_input = np.empty(shape = (training_size_shape[0],training_size_shape[1],training_size_shape[2],add_channels))\n",
    "    validation_input = np.empty(shape = (validation_testing_size_shape[0],validation_testing_size_shape[1],validation_testing_size_shape[2],add_channels))\n",
    "    testing_input = np.empty(shape = (validation_testing_size_shape[0],validation_testing_size_shape[1],validation_testing_size_shape[2],add_channels))\n",
    "    \n",
    "    print(f'Training input shape = {training_input.shape}')\n",
    "    \n",
    "    #Add RZSM observations first\n",
    "    for idx,lag in enumerate(lag_integer_list):\n",
    "        channel_list.append(f'RZSM_obs_lag{lag}')\n",
    "        training_input, validation_input, testing_input = pred.add_obs_RZSM_by_lag(training_input, validation_input, testing_input, lag, input_directory, idx, final_testing_year)\n",
    "        \n",
    "    print(f'Index idx value is {idx}. Done adding RZSM obs.')    \n",
    "    \n",
    "    RZSM_train_obs, RZSM_validation_obs = pred.return_masking_objects_for_RZSM(input_directory, final_testing_year)\n",
    "\n",
    "    if lead <=2:\n",
    "        for variable in var_list:\n",
    "            channel_name_output = pred.return_channel_name(variable)\n",
    "            for lag in [-1]:\n",
    "                '''Only include the first lag'''\n",
    "                channel_list.append(f'{channel_name_output}_obs_lag{lag}')\n",
    "                idx+=1\n",
    "                #Observations adding\n",
    "                training_input, validation_input, testing_input = pred.add_obs_other_observations_by_lag(training_input, validation_input, testing_input, lag, input_directory, variable, idx,final_testing_year)\n",
    "     \n",
    "        \n",
    "            print(f'Index idx value is {idx}. Done adding {variable} obs.')\n",
    "        \n",
    "    ############################### NOW ADD THE PREDICTION DATA FROM PREVIOUS WEEK ################################################\n",
    "    #Now we need to load our data from the previous weeks \n",
    "    \n",
    "    if lead in [0, 1]:\n",
    "        #DO NOT INCLUDE LEAD 0 AS A PREDICTOR (FROM PREVIOUS WEEK)\n",
    "        pass\n",
    "    else:\n",
    "\n",
    "        for lead_previous in range(1,lead):\n",
    "            print(f'Adding previous RZSM prediction from week {lead_previous} as an input channel')\n",
    "            # break\n",
    "            \n",
    "            pred_dir = f'predictions/{region_name}/Wk{lead_previous}_training_validation'\n",
    "            testing_dir = f'predictions/{region_name}/Wk{lead_previous}_testing'\n",
    "            \n",
    "            os.system(f'mkdir -p {pred_dir}')\n",
    "            \n",
    "            training_prediction_name= f'{pred_dir}/Wk{lead_previous}_training_{experiment_name_out}.npy'\n",
    "            validation_prediction_name = f'{pred_dir}/Wk{lead_previous}_validation_{experiment_name_out}.npy'\n",
    "            testing_prediction_name = f'{testing_dir}/Wk{lead_previous}_testing_{experiment_name_out}.npy'\n",
    "            \n",
    "            testing_prediction = np.load(testing_prediction_name)\n",
    "            \n",
    "            '''Load the training and validation predictions if they exist'''\n",
    "            if os.path.exists(training_prediction_name):\n",
    "                print(f'Loading data from previous week lead {lead_previous}')\n",
    "                training_prediction = np.load(training_prediction_name)\n",
    "                validation_prediction =np.load(validation_prediction_name)\n",
    "                \n",
    "            else:\n",
    "                print(f'Creating prediction data from previous week lead {lead_previous}')\n",
    "                '''If they don't exist..... load model for previous week'''\n",
    "                model = load_model(f'checkpoints/Wk_{lead_previous}/Wk{lead_previous}_{experiment_name_out}',compile=False) #don't need the custom loss function for predictions\n",
    "                \n",
    "                training_input_previous = np.load(f'Data/model_npy_inputs/{region_name}/Wk{lead_previous}_EX_input_data/{experiment_name_out}_training_input.npy')\n",
    "                validation_input_previous = np.load(f'Data/model_npy_inputs/{region_name}/Wk{lead_previous}_EX_input_data/{experiment_name_out}_validation_input.npy')\n",
    "                testing_input_previous = np.load(f'Data/model_npy_inputs/{region_name}/Wk{lead_previous}_EX_input_data/{experiment_name_out}_testing_input.npy')\n",
    "                \n",
    "                '''Make predictions and save data to load for previous use'''\n",
    "                training_prediction = model.predict(training_input_previous) #Just for unit checking\n",
    "                np.save(training_prediction_name,training_prediction)\n",
    "                \n",
    "                validation_prediction = model.predict(validation_input_previous)\n",
    "                np.save(validation_prediction_name,validation_prediction)\n",
    "            \n",
    "            \n",
    "            ############# ADD BACK TO CREATED ARRAY ###############################\n",
    "            '''Now get the best UNET index prediction for RZSM and Tmax. Because the UNET plus plus produces 4 different outputs'''\n",
    "            min_RZSM_index,min_tmax_index = f.load_loss_csv_bias_correction(lead_previous,experiment_name_out,RZSM_or_Tmax_or_both,region_name)\n",
    "    \n",
    "            if np.array(training_prediction).shape[0] == 8 and RZSM_or_Tmax_or_both == 'both':\n",
    "                min_tmax_index = min_tmax_index+4 #Because index values 0-3 are RZSM and 4-7 are Tmax\n",
    "            elif np.array(training_prediction).shape[0] == 6 and RZSM_or_Tmax_or_both == 'both':\n",
    "                min_tmax_index = min_tmax_index + 3 #Because index values are 0-2 for RZSM and 3-5 for Tmax\n",
    "            '''Now split the training and validation data back into RZSM and/or Tmax'''\n",
    "            \n",
    "            \n",
    "            train_RZSM = np.array(training_prediction)[min_RZSM_index,:,:,:,:]\n",
    "            val_RZSM = np.array(validation_prediction)[min_RZSM_index,:,:,:,:]\n",
    "            test_RZSM = np.array(testing_prediction)[min_RZSM_index,:,:,:,:]\n",
    "\n",
    "    \n",
    "            '''Make sure we mask RZSM values which aren't on land'''\n",
    "            train_RZSM = np.where(RZSM_train_obs==0,0,train_RZSM)\n",
    "            val_RZSM = np.where(RZSM_validation_obs==0,0,val_RZSM)\n",
    "            test_RZSM = np.where(RZSM_validation_obs==0,0,test_RZSM)\n",
    "    \n",
    "            #Now add back to the data\n",
    "            '''Now add back to the newly created dataset'''\n",
    "            idx+=1\n",
    "            channel_list.append(f'RZSM_prediction_lead{lead_previous}')\n",
    "            print(f'Adding RZSM training, validation, testing into index {idx}')\n",
    "            training_input[:,:,:,idx] = train_RZSM[:,:,:,0]\n",
    "            validation_input[:,:,:,idx] = val_RZSM[:,:,:,0]\n",
    "            testing_input[:,:,:,idx] = test_RZSM[:,:,:,0]\n",
    "\n",
    "    \n",
    "    ############################### NOW ADD THE REFORECAST DATA FROM THE WEEK TO BE PREDICTED ################################################\n",
    "    \n",
    "    #Add predictors from the reforecast model\n",
    "    if (lead in [1,2]):\n",
    "        print(f'Adding current reforecast data from week {lead} for vars {(var_list)}')  \n",
    "        #Only add these for week 1 and 2. \n",
    "        for variable in var_list:\n",
    "            idx+=1\n",
    "            channel_name_output = pred.return_channel_name(variable)\n",
    "            \n",
    "            channel_list.append(f'{channel_name_output}_ref_lead{lead}')\n",
    "            \n",
    "            training_input, validation_input, testing_input = pred.add_reforecast_by_lag(training_input, validation_input, testing_input, lead, input_directory, variable, idx, ref_source, final_testing_year)\n",
    "    \n",
    "            print(f'Index idx value is {idx}. Done adding {variable} reforecast.')\n",
    "\n",
    "    print(training_input[0,:,:,-1])\n",
    "\n",
    "    return(training_input, validation_input, testing_input,channel_list)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c8f158ec-5304-457d-b60f-485f78f4a95b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_only_predictions_EX26(lead, input_directory,training_size_shape,validation_testing_size_shape,RZSM_or_Tmax_or_both,experiment_name,region_name,\n",
    "                               experiment_name_out):\n",
    "    '''We need to combine all the RZSM files and all the observation data (pwat, spfh, tmax, diff_temp, z200) into one file. Also adding the RZSM reforecast data from RZSM and Tmax '''\n",
    "\n",
    "    channel_list = []\n",
    "\n",
    "    assert lead >=2, 'We cannot make a prediction if lead week is 1 because we dont have an input. So make lead week >= 2.'\n",
    "\n",
    "    #Get the number of extra channels to add from previous weeks predictions\n",
    "    add_channels = lead # We are only adding the previous weeks lag and the current week. \n",
    "\n",
    "    training_input = np.empty(shape = (training_size_shape[0],training_size_shape[1],training_size_shape[2],add_channels))\n",
    "    validation_input = np.empty(shape = (validation_testing_size_shape[0],validation_testing_size_shape[1],validation_testing_size_shape[2],add_channels))\n",
    "    testing_input = np.empty(shape = (validation_testing_size_shape[0],validation_testing_size_shape[1],validation_testing_size_shape[2],add_channels))\n",
    "    \n",
    "    print(f'Training input shape = {training_input.shape}')\n",
    "    \n",
    "    #For masking\n",
    "    RZSM_train_obs, RZSM_validation_obs = pred.return_masking_objects_for_RZSM(input_directory)\n",
    "\n",
    "    ############################### NOW ADD THE PREDICTION DATA FROM PREVIOUS WEEK ################################################\n",
    "        #Now we need to load our data from the previous weeks\n",
    "    for idx,lead_previous in enumerate(range(1,lead)):\n",
    "        # break\n",
    "        \n",
    "        pred_dir = f'predictions/{region_name}/Wk{lead_previous}_training_validation'\n",
    "        testing_dir = f'predictions/{region_name}/Wk{lead_previous}_testing'\n",
    "        \n",
    "        os.system(f'mkdir -p {pred_dir}')\n",
    "        \n",
    "        previous_model = return_fully_autoregressive_EX26(lead)\n",
    "            \n",
    "        \n",
    "        training_prediction_name= f'{pred_dir}/Wk{lead_previous}_training_{previous_model[idx]}.npy'\n",
    "        validation_prediction_name = f'{pred_dir}/Wk{lead_previous}_validation_{previous_model[idx]}.npy'\n",
    "        testing_prediction_name = f'{testing_dir}/Wk{lead_previous}_testing_{previous_model[idx]}.npy'\n",
    "        \n",
    "        testing_prediction = np.load(testing_prediction_name)\n",
    "        '''Load the training and validation predictions if they exist'''\n",
    "        \n",
    "        if os.path.exists(training_prediction_name):\n",
    "            print(f'Loading data from previous week lead {lead_previous}')\n",
    "            training_prediction = np.load(training_prediction_name)\n",
    "            validation_prediction =np.load(validation_prediction_name)\n",
    "            \n",
    "        else:\n",
    "            print(f'Creating prediction data from previous week lead {lead_previous}')\n",
    "            '''If they don't exist..... load model for previous week'''\n",
    "            model = load_model(f'checkpoints/Wk_{lead_previous}/Wk{lead_previous}_{experiment_name}',compile=False) #don't need the custom loss function for predictions\n",
    "            \n",
    "            training_input_previous = np.load(f'Data/model_npy_inputs/{region_name}/Wk{lead_previous}_EX_input_data/{experiment_name_out}_training_input.npy')\n",
    "            validation_input_previous = np.load(f'Data/model_npy_inputs/{region_name}/Wk{lead_previous}_EX_input_data/{experiment_name_out}_validation_input.npy')\n",
    "            testing_input_previous = np.load(f'Data/model_npy_inputs{region_name}//Wk{lead_previous}_EX_input_data/{experiment_name_out}_testing_input.npy')\n",
    "            \n",
    "            '''Make predictions and save data to load for previous use'''\n",
    "            training_prediction = model.predict(training_input_previous) #Just for unit checking\n",
    "            np.save(training_prediction_name,training_prediction)\n",
    "            \n",
    "            validation_prediction = model.predict(validation_input_previous)\n",
    "            np.save(validation_prediction_name,validation_prediction)\n",
    "        \n",
    "        \n",
    "        ############# ADD BACK TO CREATED ARRAY ###############################\n",
    "        '''Now get the best UNET index prediction for RZSM and Tmax. Because the UNET plus plus produces 4 different outputs'''\n",
    "        min_RZSM_index,min_tmax_index = f.load_loss_csv_bias_correction(lead_previous,previous_model[idx],RZSM_or_Tmax_or_both, region_name)\n",
    "\n",
    "        if np.array(training_prediction).shape[0] == 8 and RZSM_or_Tmax_or_both == 'both':\n",
    "            min_tmax_index = min_tmax_index+4 #Because index values 0-3 are RZSM and 4-7 are Tmax\n",
    "        elif np.array(training_prediction).shape[0] == 6 and RZSM_or_Tmax_or_both == 'both':\n",
    "            min_tmax_index = min_tmax_index + 3 #Because index values are 0-2 for RZSM and 3-5 for Tmax\n",
    "        '''Now split the training and validation data back into RZSM and/or Tmax'''\n",
    "        \n",
    "        \n",
    "        train_RZSM = np.array(training_prediction)[min_RZSM_index,:,:,:,:]\n",
    "        val_RZSM = np.array(validation_prediction)[min_RZSM_index,:,:,:,:]\n",
    "        test_RZSM = np.array(testing_prediction)[min_RZSM_index,:,:,:,:]\n",
    "\n",
    "\n",
    "        '''Make sure we mask RZSM values which aren't on land'''\n",
    "        train_RZSM = np.where(RZSM_train_obs==0,0,train_RZSM)\n",
    "        val_RZSM = np.where(RZSM_validation_obs==0,0,val_RZSM)\n",
    "        test_RZSM = np.where(RZSM_validation_obs==0,0,test_RZSM)\n",
    "\n",
    "        #Now add back to the data\n",
    "        '''Now add back to the newly created dataset'''\n",
    "        channel_list.append(f'RZSM_prediction_lead{lead_previous}')\n",
    "        print(f'Adding RZSM training, validation, testing into index {idx}')\n",
    "        training_input[:,:,:,idx] = train_RZSM[:,:,:,0]\n",
    "        validation_input[:,:,:,idx] = val_RZSM[:,:,:,0]\n",
    "        testing_input[:,:,:,idx] = test_RZSM[:,:,:,0]\n",
    "\n",
    "        idx+=1\n",
    "\n",
    "    \n",
    "    ############################### NOW ADD THE REFORECAST DATA FROM THE WEEK TO BE PREDICTED ################################################\n",
    "    \n",
    "    #Add RZSM reforecast week N\n",
    "    soil_var = 'soilw_bgrnd'\n",
    "    channel_name_output = pred.return_channel_name(soil_var)\n",
    "    channel_list.append(f'{channel_name_output}_ref_lead{lead}')\n",
    "\n",
    "    print(f'And finally adding RZSM week {lead} from reforecast as a predictor')\n",
    "    \n",
    "    training_input, validation_input, testing_input = pred.add_reforecast_by_lag(training_input, validation_input, testing_input, lead, input_directory,soil_var, idx)\n",
    "\n",
    "    print(f'Index idx value is {idx}. Done adding {soil_var} reforecast.')\n",
    "\n",
    "    print('Final channel of input is the following (just make sure it has zeros for RZSM)')\n",
    "    print(training_input[0,:,:,-1])\n",
    "\n",
    "    return(training_input, validation_input, testing_input,channel_list)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "705e8a43-188b-46c5-a45f-02a2637c28c8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def make_UNET_stacked_inputs(lead, num_lags_obs_RZSM, include_lags_obs_pwat_spfh_tmax, include_reforecast_or_not, \n",
    "                             observation_lag_list_not_RZSM, lag_integer_list, input_directory,training_size_shape,\n",
    "                             validation_testing_size_shape,experiment_name,RZSM_or_Tmax_or_both,addtl_experiment,experiment_test,region_name,experiment_name_out):\n",
    "    \n",
    "    \n",
    "    #Set restrictions. For EX0, we only want to bias correct the forecasts with week lead 1 RZSM and tmax\n",
    "    if experiment_name == 'EX0' or experiment_name == 'EX13':\n",
    "        \n",
    "        #Step 1 load data \n",
    "        print(f'\\nWorking on setting up data for Experiment {experiment_name} for lead {lead}\\n')\n",
    "        \n",
    "        final_input_train, final_input_validation, final_input_testing,channel_list =  loadData.load_all_data_EX0(lead, num_lags_obs_RZSM, include_lags_obs_pwat_spfh_tmax, include_reforecast_or_not, \n",
    "                                                                                                     observation_lag_list_not_RZSM, lag_integer_list, input_directory,training_size_shape,\n",
    "                                                                                                     validation_testing_size_shape,RZSM_or_Tmax_or_both,addtl_experiment,experiment_test,ref_source,final_testing_year)\n",
    "\n",
    "        print(f'\\nInput channels will be only week 1 Tmax and RZSM through the current lead {lead} which are also going to be predicted. There are no observations in this experiment\\n')\n",
    "        \n",
    "        print('Done')\n",
    "        \n",
    "        \n",
    "    \n",
    "    ############################################### EXPERIMENTS 1-4 ####################################################################################\n",
    "    elif experiment_name in ['EX1','EX2','EX3','EX4','EX14','EX15','EX16','EX17']:\n",
    "\n",
    "        print(f'\\nWorking on setting up data for Experiment {experiment_name} for lead {lead}\\n')\n",
    "        \n",
    "        if lead == 0:\n",
    "            #Step 1 load data \n",
    "            final_input_train, final_input_validation, final_input_testing,channel_list = loadData.load_all_data_EX1_EX2_EX3_EX4(lead, num_lags_obs_RZSM, include_lags_obs_pwat_spfh_tmax, \n",
    "                                                                                                                    include_reforecast_or_not, observation_lag_list_not_RZSM, lag_integer_list, input_directory,\n",
    "                                                                                                                   training_size_shape,validation_testing_size_shape,RZSM_or_Tmax_or_both,\n",
    "                                                                                                                                   region_name=region_name,ref_source=ref_source,final_testing_year=final_testing_year)\n",
    "        else:\n",
    "            final_input_train, final_input_validation, final_input_testing,channel_list = load_all_data_EX1_EX2_EX3_EX4_after_week_0(lead, num_lags_obs_RZSM, include_lags_obs_pwat_spfh_tmax, include_reforecast_or_not, \n",
    "                                                                                                                                       observation_lag_list_not_RZSM, lag_integer_list, input_directory,training_size_shape,\n",
    "                                                                                                                                       validation_testing_size_shape,experiment_name,RZSM_or_Tmax_or_both,addtl_experiment,experiment_test,\n",
    "                                                                                                                                    experiment_name_out=experiment_name_out,ref_source=ref_source,final_testing_year=final_testing_year)\n",
    "\n",
    "        \n",
    "                \n",
    "        print('Done')\n",
    "        \n",
    "        \n",
    "    \n",
    "    ############################################### EXPERIMENTS 5-8 ####################################################################################\n",
    "    elif experiment_name in ['EX5','EX6','EX7','EX8','EX18','EX19','EX20','EX21','EX22','EX23','EX24','EX25']:\n",
    "\n",
    "        print(f'\\nWorking on setting up data for Experiment {experiment_name} for lead {lead}\\n')\n",
    "        \n",
    "        # #Step 1 load data \n",
    "        # if addtl_experiment == False:\n",
    "        #     final_input_train, final_input_validation, final_input_testing,channel_list = loadData.load_all_data_EX5_EX6_EX7_EX8(lead, num_lags_obs_RZSM, include_lags_obs_pwat_spfh_tmax, \n",
    "        #                                                                                                    include_reforecast_or_not, observation_lag_list_not_RZSM, lag_integer_list,\n",
    "        #                                                                                                    input_directory,training_size_shape,validation_testing_size_shape,RZSM_or_Tmax_or_both,\n",
    "                                                                                                                                   # region_name=region_name)\n",
    "        # else:\n",
    "        final_input_train, final_input_validation, final_input_testing,channel_list = load_all_data_EX5_EX6_EX7_EX8_experiments(lead, num_lags_obs_RZSM, include_lags_obs_pwat_spfh_tmax, include_reforecast_or_not, \n",
    "                                                                                      observation_lag_list_not_RZSM, lag_integer_list, input_directory,training_size_shape,\n",
    "                                                                                      validation_testing_size_shape,RZSM_or_Tmax_or_both,experiment_test,experiment_name,experiment_name_out=experiment_name_out)\n",
    "\n",
    "        print('Done')\n",
    "        \n",
    "        \n",
    "    \n",
    "    ############################################### EXPERIMENTS 9-12 ####################################################################################\n",
    "    elif (experiment_name == 'EX9') or (experiment_name == 'EX10') or (experiment_name == 'EX11') or (experiment_name == 'EX12') or (experiment_name == 'EX27') or (experiment_name == 'EX28'):\n",
    "        \n",
    "        print(f'\\nWorking on setting up data for Experiment {experiment_name} for lead {lead}\\n')\n",
    "\n",
    "        if lead == 0:\n",
    "            final_input_train, final_input_validation, final_input_testing,channel_list = loadData.load_all_data_EX9_EX10_EX11_EX12(lead, num_lags_obs_RZSM, include_lags_obs_pwat_spfh_tmax, \n",
    "                                                                                                              include_reforecast_or_not, observation_lag_list_not_RZSM, lag_integer_list, \n",
    "                                                                                                              input_directory,training_size_shape,validation_testing_size_shape,RZSM_or_Tmax_or_both, \n",
    "                                                                                                                                    experiment_test = experiment_test,\n",
    "                                                                                                                                   region_name=region_name)\n",
    "        else:\n",
    "            final_input_train, final_input_validation, final_input_testing,channel_list = load_all_data_EX9_EX10_EX11_EX12_after_week_0(lead, num_lags_obs_RZSM, include_lags_obs_pwat_spfh_tmax, include_reforecast_or_not, \n",
    "                                                                                                       observation_lag_list_not_RZSM, lag_integer_list, input_directory,training_size_shape,\n",
    "                                                                                                   validation_testing_size_shape,experiment_name,RZSM_or_Tmax_or_both,\n",
    "                                                                                                                                       experiment_test = experiment_test,\n",
    "                                                                                                                                       region_name = region_name,experiment_name_out=experiment_name_out)\n",
    "    elif (experiment_name == 'EX26'):\n",
    "\n",
    "        print(f'\\nWorking on setting up data for Experiment {experiment_name} for lead {lead}\\n')\n",
    "\n",
    "        final_input_train, final_input_validation, final_input_testing,\n",
    "        channel_list = load_only_predictions_EX26(lead, input_directory,training_size_shape,validation_testing_size_shape,RZSM_or_Tmax_or_both,experiment_name,region_name,\n",
    "                               experiment_name_out)\n",
    "        print('Done')\n",
    "        \n",
    "    ############################################### EXPERIMENTS 29 ####################################################################################\n",
    "    elif (experiment_name == 'EX29'):\n",
    "        \n",
    "        print(f'\\nWorking on setting up data for Experiment {experiment_name} for lead {lead}\\n')\n",
    "\n",
    "        final_input_train, final_input_validation, final_input_testing,channel_list = load_all_data_EX29_after_week_0(lead, num_lags_obs_RZSM, include_lags_obs_pwat_spfh_tmax, include_reforecast_or_not, \n",
    "                                                                                                   observation_lag_list_not_RZSM, lag_integer_list, input_directory,training_size_shape,\n",
    "                                                                                               validation_testing_size_shape,experiment_name,RZSM_or_Tmax_or_both,experiment_test = experiment_test,\n",
    "                                                                                                                                       region_name = region_name,experiment_name_out=experiment_name_out)\n",
    "                                                                                                        \n",
    "\n",
    "    return (final_input_train,final_input_validation,final_input_testing,channel_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "84042a9e-5635-447c-a16a-679fcbd7624a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#To try and save on memory, only load certain files at a time\n",
    "def return_only_train_validation(lead, num_lags_obs_RZSM, include_lags_obs_pwat_spfh_tmax, include_reforecast_or_not, \n",
    "                                 observation_lag_list_not_RZSM, lag_integer_list, input_directory,training_size_shape,\n",
    "                                 validation_testing_size_shape,experiment_name):\n",
    "    \n",
    "    reforecast_train_input, reforecast_validation_input, reforecast_testing_input,channel_list \\\n",
    "    = make_UNET_stacked_inputs(lead, num_lags_obs_RZSM, include_lags_obs_pwat_spfh_tmax, \n",
    "                               include_reforecast_or_not, observation_lag_list_not_RZSM, \n",
    "                               lag_integer_list, input_directory,training_size_shape,validation_testing_size_shape,experiment_name,region_name)\n",
    "\n",
    "    return(reforecast_train_input, reforecast_validation_input,reforecast_testing_input,channel_list)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def return_testing_data_model_training(lead, num_lags_obs_RZSM, include_lags_obs_pwat_spfh_tmax, \n",
    "                               include_reforecast_or_not, observation_lag_list_not_RZSM, \n",
    "                               lag_integer_list, input_directory,training_size_shape,validation_testing_size_shape,experiment_name):\n",
    "\n",
    "    reforecast_train_input, reforecast_validation_input, reforecast_testing_input,channel_list = make_UNET_stacked_inputs(lead, num_lags_obs_RZSM, include_lags_obs_pwat_spfh_tmax, \n",
    "                               include_reforecast_or_not, observation_lag_list_not_RZSM, \n",
    "                               lag_integer_list, input_directory,training_size_shape,validation_testing_size_shape,experiment_name,region_name)\n",
    "    return(reforecast_testing_input,channel_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f023cfa8-d5b4-4bc2-8031-d4d71d939e39",
   "metadata": {},
   "source": [
    "# Load Data files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b606d2ec-7c9c-46a8-96df-1810e8c991b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Testing\n",
    "# region_name=region_name\n",
    "# lead = lead_week\n",
    "# num_lags_obs_RZSM=3\n",
    "# include_lags_obs_pwat_spfh_tmax=True\n",
    "# include_reforecast_or_not=True\n",
    "# addtl_experiment = False\n",
    "# experiment_test = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "08e37a45-e7c7-4e62-b3cf-31ef129dbb24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_experiment_name_and_lags_and_channel_dir(include_reforecast_or_not, num_lags_obs_RZSM, include_lags_obs_pwat_spfh_tmax, addtl_experiment, experiment_test, region_name):\n",
    "    \n",
    "    experiment_name = CE.return_experiment_name(include_reforecast_or_not,num_lags_obs_RZSM,include_lags_obs_pwat_spfh_tmax,addtl_experiment,experiment_test)\n",
    "\n",
    "    save_experiment_name = f'{experiment_name}_RZSM'\n",
    "    if testing_scenario == 'None':\n",
    "        experiment_name_out = f'{experiment_name}_RZSM'\n",
    "    else:\n",
    "        experiment_name_out = f'{experiment_name}_{save_loss_name}_RZSM' #Need to manually change this if using different loss functions to keep track of things\n",
    "    \n",
    "    global lag_integer_list\n",
    "    lag_integer_list =  CE.return_num_day_lags_from_weekly_lags(num_lags_obs_RZSM) #For number of RZSM observation lags\n",
    "\n",
    "    #Where to save channel information\n",
    "    save_experiment_dir = f'Data/model_npy_inputs/{region_name}/Wk{lead}_EX_input_data'\n",
    "    \n",
    "    channel_save_dir = f'channel_list_information/Wk{lead}'\n",
    "    \n",
    "    checkpoint_filepath = f'checkpoints/{region_name}/Wk{lead}/Wk{lead}_{experiment_name_out}'\n",
    "    \n",
    "    losses_dir = f'Losses_with_OBS/{region_name}/Wk{lead}'\n",
    "    \n",
    "    save_checkpoint_dir =f'checkpoints/{region_name}/Wk{lead}'\n",
    "    \n",
    "    os.system(f'mkdir -p {checkpoint_filepath} {channel_save_dir} {save_experiment_dir} {losses_dir} {save_checkpoint_dir}')\n",
    "\n",
    "    \n",
    "    #Set up files for either saving or loading\n",
    "    training_input_file = f'{save_experiment_dir}/{save_experiment_name}_training_input.npy'\n",
    "    validation_input_file = f'{save_experiment_dir}/{save_experiment_name}_validation_input.npy'\n",
    "    testing_input_file = f'{save_experiment_dir}/{save_experiment_name}_testing_input.npy'\n",
    "\n",
    "    \n",
    "    return(save_experiment_name,experiment_name_out,experiment_name,lag_integer_list,channel_save_dir,\n",
    "           training_input_file,validation_input_file,testing_input_file,checkpoint_filepath,\n",
    "          losses_dir,save_checkpoint_dir,save_experiment_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "93274b84-b5c7-4103-9412-2dd052ae1c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_model_inputs(region_name,lead,include_reforecast_or_not,num_lags_obs_RZSM,include_lags_obs_pwat_spfh_tmax,addtl_experiment,experiment_test):\n",
    "\n",
    "    save_experiment_name, experiment_name_out, experiment_name,lag_integer_list, \\\n",
    "    channel_save_dir, training_input_file, validation_input_file, \\\n",
    "    testing_input_file,checkpoint_filepath, losses_dir,save_checkpoint_dir, \\\n",
    "    save_experiment_dir = return_experiment_name_and_lags_and_channel_dir(include_reforecast_or_not, num_lags_obs_RZSM, include_lags_obs_pwat_spfh_tmax, addtl_experiment, experiment_test, region_name)\n",
    "\n",
    "    if os.path.exists('redoooooo.nc'):\n",
    "    # if os.path.exists(training_input_file) and os.path.exists(validation_input_file) and os.path.exists(testing_input_file):\n",
    "        pass\n",
    "    else:\n",
    "        reforecast_train_input, reforecast_validation_input, reforecast_testing_input, channel_list \\\n",
    "        = make_UNET_stacked_inputs(lead, num_lags_obs_RZSM, include_lags_obs_pwat_spfh_tmax, include_reforecast_or_not, \n",
    "                             observation_lag_list_not_RZSM, lag_integer_list, input_directory,training_size_shape,\n",
    "                             validation_testing_size_shape,experiment_name,RZSM_or_Tmax_or_both,addtl_experiment,experiment_test,region_name,experiment_name_out)\n",
    "    \n",
    "        #Save data to file\n",
    "        np.save(training_input_file,tf.convert_to_tensor(reforecast_train_input,dtype=tf.float32))\n",
    "        np.save(validation_input_file,tf.convert_to_tensor(reforecast_validation_input,dtype=tf.float32))\n",
    "        np.save(testing_input_file,tf.convert_to_tensor(reforecast_testing_input,dtype=tf.float32))\n",
    "        \n",
    "        image_size = reforecast_train_input.shape[1:]           \n",
    "        #Save channel list information to txt file\n",
    "    \n",
    "        with open(f'{channel_save_dir}/{save_experiment_name}_channel_list.txt', 'w') as file:\n",
    "            for idx,element in enumerate(channel_list):\n",
    "                if '-' in element:\n",
    "                    source_='OBSERVATIONS'\n",
    "                else:\n",
    "                    source_='REFORECAST'\n",
    "    \n",
    "                file.write(f'Channel_{idx} is from {source_} with lead or lag {str(element)}' + '\\n')\n",
    "\n",
    "    return(f'Completed writing lead {lead} model input data to {save_experiment_dir}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b1cc6fa0-f9ae-4c0a-89db-5bbb73ddff50",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train(epochs, batch_size, lead, initial_learning_rate, beta_1,shuffle,patience, kernel_norm,deep_supervision,\n",
    "         num_lags_obs_RZSM,include_lags_obs_pwat_spfh_tmax,include_reforecast_or_not,\n",
    "          number_of_UNET_backbone_max_pool,permutation_test,make_additional_predictions_from_model_for_testing,\n",
    "         input_directory,training_size_shape,validation_testing_size_shape,addtl_experiment,experiment_test,region_name):\n",
    "    \n",
    "#For testing\n",
    "# lead=1\n",
    "# num_lags_obs_RZSM = 3\n",
    "# include_lags_obs_pwat_spfh_tmax = True\n",
    "# include_reforecast_or_not=True\n",
    "# deep_supervision = True\n",
    "# initial_learning_rate = 0.0001\n",
    "# beta_1 = 0.9\n",
    "# batch_size=66\n",
    "# epochs=1\n",
    "# shuffle=False\n",
    "# kernel_norm =  None\n",
    "# patience=10\n",
    "# permutation_test = False\n",
    "    \n",
    "    # print(addtl_experiment)\n",
    "    #Training data\n",
    "    #Needed for calculating the loss for individual UNET predictions (each has 4 predictions for each variable)\n",
    "    def return_training_verification_data(RZSM_or_tmax):\n",
    "        #We had multiple verification inputs in the past, but now we just reduced to RZSM\n",
    "        if RZSM_or_tmax == 'RZSM':\n",
    "            return(np.array(tf.expand_dims(obs_final_train,-1)))\n",
    "\n",
    "    \n",
    "    #Validation data\n",
    "    def return_validation_verification_data(RZSM_or_tmax):\n",
    "        #We had multiple verification inputs in the past, but now we just reduced to RZSM\n",
    "        if RZSM_or_tmax == 'RZSM':\n",
    "            return(np.array(tf.expand_dims(obs_final_validation,-1)))\n",
    "\n",
    "    \n",
    "    \n",
    "    def print_shape(file,name):\n",
    "        print(f'Shape of {name} is {file.shape}')\n",
    "        \n",
    "    save_experiment_name, experiment_name_out, experiment_name,lag_integer_list, \\\n",
    "    channel_save_dir, training_input_file, validation_input_file, \\\n",
    "    testing_input_file,checkpoint_filepath, losses_dir,save_checkpoint_dir, \\\n",
    "    save_experiment_dir = return_experiment_name_and_lags_and_channel_dir(include_reforecast_or_not, num_lags_obs_RZSM, include_lags_obs_pwat_spfh_tmax, addtl_experiment, experiment_test, region_name)\n",
    "\n",
    "    obs_final_train,obs_final_validation,obs_final_testing = f.load_verification_observations_updated(lead,verification_directory)\n",
    "    \n",
    "\n",
    "    print('Loading previously created data')\n",
    "    #Have to do this way because of memory issues\n",
    "    \n",
    "    if number_of_UNET_backbone_max_pool == 4:\n",
    "        if RZSM_or_Tmax_or_both == 'both':\n",
    "            reforecast_train_input_tensor = tf.data.Dataset.from_tensor_slices(({'input_image':np.load(training_input_file)},\n",
    "                                                                                {'RZSM_output_1': return_training_verification_data('RZSM'), 'RZSM_output_2': return_training_verification_data('RZSM'), 'RZSM_output_3': return_training_verification_data('RZSM'),\n",
    "                                                                                 'tmax_output_1': return_training_verification_data('tmax'), 'tmax_output_2': return_training_verification_data('tmax'), 'tmax_output_3': return_training_verification_data('tmax')}))\n",
    "            reforecast_validation_input_tensor = tf.data.Dataset.from_tensor_slices(({'input_image':np.load(validation_input_file)},\n",
    "                                                                                {'RZSM_output_1': return_validation_verification_data('RZSM'), 'RZSM_output_2': return_validation_verification_data('RZSM'), 'RZSM_output_3': return_validation_verification_data('RZSM'),\n",
    "                                                                                 'tmax_output_1': return_validation_verification_data('tmax'), 'tmax_output_2': return_validation_verification_data('tmax'), 'tmax_output_3': return_validation_verification_data('tmax')}))\n",
    "            # reforecast_testing_input_tensor = tf.data.Dataset.from_tensor_slices((np.load(testing_input_file),obs_final_testing))\n",
    "            # reforecast_testing_input = np.load(testing_input_file)\n",
    "        elif RZSM_or_Tmax_or_both == 'RZSM':\n",
    "            reforecast_train_input_tensor = tf.data.Dataset.from_tensor_slices(({'input_image':np.load(training_input_file)},\n",
    "                                                                                {'RZSM_output_1': return_training_verification_data('RZSM'), 'RZSM_output_2': return_training_verification_data('RZSM'), 'RZSM_output_3': return_training_verification_data('RZSM')}))\n",
    "            reforecast_validation_input_tensor = tf.data.Dataset.from_tensor_slices(({'input_image':np.load(validation_input_file)},\n",
    "                                                                                {'RZSM_output_1': return_validation_verification_data('RZSM'), 'RZSM_output_2': return_validation_verification_data('RZSM'), 'RZSM_output_3': return_validation_verification_data('RZSM')}))\n",
    "\n",
    "        image_size = np.array(list(reforecast_train_input_tensor.element_spec)[0]['input_image'].shape)\n",
    "        \n",
    "    elif number_of_UNET_backbone_max_pool == 5:\n",
    "        if RZSM_or_Tmax_or_both == 'both':\n",
    "            reforecast_train_input_tensor = tf.data.Dataset.from_tensor_slices(({'input_image':np.load(training_input_file)},\n",
    "                                                                                    {'RZSM_output_1': return_training_verification_data('RZSM'), 'RZSM_output_2': return_training_verification_data('RZSM'), 'RZSM_output_3': return_training_verification_data('RZSM'),'RZSM_output_4': return_training_verification_data('RZSM'),\n",
    "                                                                                     'tmax_output_1': return_training_verification_data('tmax'), 'tmax_output_2': return_training_verification_data('tmax'), 'tmax_output_3': return_training_verification_data('tmax'),'tmax_output_4': return_training_verification_data('tmax')}))\n",
    "            reforecast_validation_input_tensor = tf.data.Dataset.from_tensor_slices(({'input_image':np.load(validation_input_file)},\n",
    "                                                                                    {'RZSM_output_1': return_validation_verification_data('RZSM'), 'RZSM_output_2': return_validation_verification_data('RZSM'), 'RZSM_output_3': return_validation_verification_data('RZSM'),'RZSM_output_4': return_validation_verification_data('RZSM'),\n",
    "                                                                                     'tmax_output_1': return_validation_verification_data('tmax'), 'tmax_output_2': return_validation_verification_data('tmax'), 'tmax_output_3': return_validation_verification_data('tmax'), 'tmax_output_4': return_validation_verification_data('tmax')}))\n",
    "        elif RZSM_or_Tmax_or_both == 'RZSM':\n",
    "            reforecast_train_input_tensor = tf.data.Dataset.from_tensor_slices(({'input_image':np.load(training_input_file)},\n",
    "                                                                                    {'RZSM_output_1': return_training_verification_data('RZSM'), 'RZSM_output_2': return_training_verification_data('RZSM'), 'RZSM_output_3': return_training_verification_data('RZSM'),'RZSM_output_4': return_training_verification_data('RZSM')}))\n",
    "            reforecast_validation_input_tensor = tf.data.Dataset.from_tensor_slices(({'input_image':np.load(validation_input_file)},\n",
    "                                                                                    {'RZSM_output_1': return_validation_verification_data('RZSM'), 'RZSM_output_2': return_validation_verification_data('RZSM'), 'RZSM_output_3': return_validation_verification_data('RZSM'),'RZSM_output_4': return_validation_verification_data('RZSM')}))\n",
    "            # reforecast_testing_input_tensor = tf.data.Dataset.from_tensor_slices((np.load(testing_input_file),obs_final_testing))\n",
    "            # reforecast_testing_input = np.load(testing_input_file)\n",
    "\n",
    "        image_size = np.array(list(reforecast_train_input_tensor.element_spec)[0]['input_image'].shape)\n",
    "\n",
    "        # reforecast_train_input = np.load(training_input_file)\n",
    "        # reforecast_validation_input  = np.load(validation_input_file)\n",
    "        # reforecast_testing_input  = np.load(testing_input_file)\n",
    "        # image_size = np.array(reforecast_train_input).shape\n",
    "  \n",
    "    \n",
    "    with open(f'{channel_save_dir}/{save_experiment_name}_channel_list.txt', 'r') as file:\n",
    "        # Read all lines from the file into a list\n",
    "        channel_list = file.readlines()\n",
    "\n",
    "    # print_shape(reforecast_train_input,'Training input')\n",
    "    # print_shape(reforecast_validation_input,'Validation input')\n",
    "    # print_shape(reforecast_testing_input,'Testing input')\n",
    "    # print_shape(obs_final_train,'Observation verification training')\n",
    "    # print_shape(obs_final_validation,'Observation verification validation')\n",
    "    # print_shape(obs_final_testing,'Observation verification testing')\n",
    "    \n",
    "\n",
    "    print('Actual channel order list')\n",
    "    print(channel_list)\n",
    "\n",
    "    inputs = Input(shape=image_size, name='input_image')\n",
    "    \n",
    "    print('\\nCompiling model\\n')\n",
    "    if RZSM_or_Tmax_or_both =='both':\n",
    "        build_model = UNETRzsmTmax.model_build_func(inputs=inputs, output_channels=1, \n",
    "                               using_deep_supervision=deep_supervision, \n",
    "                               kernel_norm = kernel_norm , var_name='RZSM_Tmax',\n",
    "                              number_of_UNET_backbone_max_pool = number_of_UNET_backbone_max_pool)\n",
    "        model = Model(inputs=inputs,\n",
    "                 outputs = build_model,\n",
    "                 name=\"UNET_tmax_RZSM\")\n",
    "        \n",
    "    elif RZSM_or_Tmax_or_both =='RZSM':\n",
    "        build_model = UNETRzsm.model_build_func(inputs=inputs, output_channels=1, \n",
    "                               using_deep_supervision=deep_supervision, \n",
    "                               kernel_norm = kernel_norm , var_name='RZSM',\n",
    "                              number_of_UNET_backbone_max_pool = number_of_UNET_backbone_max_pool)\n",
    "        model = Model(inputs=inputs,\n",
    "                 outputs = build_model,\n",
    "                 name=\"UNET_RZSM\")\n",
    "\n",
    "\n",
    "    \n",
    "    # print(model.summary())\n",
    "\n",
    "    if number_of_UNET_backbone_max_pool == 4:\n",
    "        if RZSM_or_Tmax_or_both =='both':\n",
    "            model.compile(loss= {'tmax_output_1':loss_fn, 'tmax_output_2':loss_fn, 'tmax_output_3':loss_fn, \n",
    "                                 'RZSM_output_1':loss_fn, 'RZSM_output_2':loss_fn, 'RZSM_output_3':loss_fn},\n",
    "                          metrics = 'mae', optimizer = k.optimizers.Adam(learning_rate=initial_learning_rate, beta_1=beta_1),run_eagerly=True)\n",
    "        elif RZSM_or_Tmax_or_both =='RZSM':\n",
    "            model.compile(loss= {'RZSM_output_1':loss_fn, 'RZSM_output_2':loss_fn, 'RZSM_output_3':loss_fn},\n",
    "                      metrics = 'mae', optimizer = k.optimizers.Adam(learning_rate=initial_learning_rate, beta_1=beta_1),run_eagerly=True)\n",
    "            \n",
    "    elif number_of_UNET_backbone_max_pool == 5:\n",
    "        if RZSM_or_Tmax_or_both =='both':\n",
    "        # With all return channels\n",
    "            model.compile(loss= {'tmax_output_1':loss_fn, 'tmax_output_2':loss_fn, 'tmax_output_3':loss_fn, 'tmax_output_4':loss_fn,\n",
    "                                 'RZSM_output_1':loss_fn, 'RZSM_output_2':loss_fn, 'RZSM_output_3':loss_fn, 'RZSM_output_4':loss_fn},\n",
    "                metrics = 'mae', optimizer = k.optimizers.Adam(learning_rate=initial_learning_rate, beta_1=beta_1),run_eagerly=True)\n",
    "        elif RZSM_or_Tmax_or_both =='RZSM':\n",
    "            model.compile(loss= {'RZSM_output_1':loss_fn, 'RZSM_output_2':loss_fn, 'RZSM_output_3':loss_fn, 'RZSM_output_4':loss_fn},\n",
    "                metrics = 'mae', optimizer = k.optimizers.Adam(learning_rate=initial_learning_rate, beta_1=beta_1),run_eagerly=True)\n",
    "\n",
    "\n",
    "    '''For some reason I can't save anymore to my home space, so let's just move it to scratch'''\n",
    "\n",
    "    checkpoint_filepath_out = f'/glade/derecho/scratch/klesinger/{checkpoint_filepath}'\n",
    "    save_checkpoint_dir_out = f'/glade/derecho/scratch/klesinger/{save_checkpoint_dir}'\n",
    "\n",
    "    os.system(f'rm {checkpoint_filepath} -r') #must do this so that we can make a soft link\n",
    "    os.system(f'mkdir -p {save_checkpoint_dir_out} {save_checkpoint_dir}')\n",
    "    \n",
    "    model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath_out,\n",
    "    save_weights_only=True,\n",
    "    mode='min',\n",
    "    save_best_only=True)\n",
    "    \n",
    "    rlrop = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=5)\n",
    "    \n",
    "    my_callbacks = [tf.keras.callbacks.EarlyStopping(patience=patience),model_checkpoint_callback, rlrop] \n",
    "    \n",
    "    unet_history=model.fit(\n",
    "        x=reforecast_train_input_tensor.batch(batch_size), \n",
    "        batch_size=batch_size, epochs=epochs, initial_epoch=0, shuffle=shuffle, callbacks=my_callbacks, \\\n",
    "        validation_data=reforecast_validation_input_tensor.batch(batch_size))\n",
    "\n",
    "    loss_out_df = pd.DataFrame(unet_history.history)\n",
    "    loss_out_df.to_csv(f'{losses_dir}/Wk{lead}_{experiment_name_out}')\n",
    "\n",
    "\n",
    "    ########### MODEL CHECKPOINTS ############################\n",
    "\n",
    "    model.save(f'/glade/work/klesinger/FD_RZSM_deep_learning/{save_checkpoint_dir}/Wk{lead}_{experiment_name_out}')\n",
    "\n",
    "    #If saving to a scratch location\n",
    "    # model.save(f'{save_checkpoint_dir_out}/Wk{lead}_{experiment_name_out}')\n",
    "    # os.system(f'ln -s {save_checkpoint_dir_out}/Wk{lead}_{experiment_name_out} /glade/work/klesinger/FD_RZSM_deep_learning/{save_checkpoint_dir}/Wk{lead}_{experiment_name_out}')\n",
    "              \n",
    "    return(0)\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "26c37ba1-26be-47ea-b851-417c89a79bc2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # #Testing for model runs\n",
    "# permutation_test=False\n",
    "# lead=1\n",
    "# num_lags_obs_RZSM =3\n",
    "# include_lags_obs_pwat_spfh_tmax = True\n",
    "# include_reforecast_or_not=True\n",
    "# deep_supervision = True\n",
    "# initial_learning_rate = 0.0001\n",
    "# beta_1 = 0.9\n",
    "# batch_size=66\n",
    "# epochs=1\n",
    "# shuffle=False\n",
    "# kernel_norm =  None\n",
    "# patience=10\n",
    "# number_of_UNET_backbone_max_pool=4\n",
    "# make_additional_predictions_from_model_for_testing=False\n",
    "# addtl_experiment = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2076b03f-80ee-49ad-b256-3450efcd55df",
   "metadata": {},
   "source": [
    "# Run the model for each experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ddec9e60-e784-4dd7-88e9-d3c2aa086c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''For experiments, you need to run the script once to make the data. Then restart the kernel to load the data. \n",
    "Otherwise the memory leaks are too high'''\n",
    "def run_EXPERIMENT(lead, num_lags_obs_RZSM,include_lags_obs_pwat_spfh_tmax ,include_reforecast_or_not,addtl_experiment,experiment_test,region_name):\n",
    "    if lead_week == 5:\n",
    "        patience=15\n",
    "    else:\n",
    "        patience = 10\n",
    "\n",
    "    #Options for num_lags_obs_RZSM weekly lags [ 3,6,9,12 ] ** this inc\n",
    "    #Options for num_lags_obs_pwat_spfh_tmax weekly lags [0 weeks or 2 weeks ]\n",
    "\n",
    "    train(epochs = 300, \n",
    "          batch_size = 66, \n",
    "          lead=lead_week, \n",
    "          initial_learning_rate=0.0001,\n",
    "          beta_1 = 0.9,\n",
    "          shuffle=False,\n",
    "          patience=patience,\n",
    "          kernel_norm = None,\n",
    "          deep_supervision = True,\n",
    "          num_lags_obs_RZSM=num_lags_obs_RZSM, \n",
    "          include_lags_obs_pwat_spfh_tmax=include_lags_obs_pwat_spfh_tmax,\n",
    "          include_reforecast_or_not=include_reforecast_or_not,\n",
    "          number_of_UNET_backbone_max_pool=4,\n",
    "          permutation_test = False,\n",
    "          make_additional_predictions_from_model_for_testing = False,\n",
    "          input_directory=input_directory,\n",
    "          training_size_shape=training_size_shape,\n",
    "          validation_testing_size_shape=validation_testing_size_shape,\n",
    "          addtl_experiment = addtl_experiment,\n",
    "          experiment_test =experiment_test,\n",
    "          region_name = region_name)\n",
    "    return(0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a0cb1309-91f7-4ce8-bc2b-f4a3432913b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_single_predictions_testing(lead, include_reforecast_or_not, num_lags_obs_RZSM, include_lags_obs_pwat_spfh_tmax,addtl_experiment,experiment_test, region_name):\n",
    "    \n",
    "    save_experiment_name, experiment_name_out, experiment_name,lag_integer_list, \\\n",
    "    channel_save_dir, training_input_file, validation_input_file, \\\n",
    "    testing_input_file,checkpoint_filepath, losses_dir,save_checkpoint_dir, \\\n",
    "    save_experiment_dir = return_experiment_name_and_lags_and_channel_dir(include_reforecast_or_not, num_lags_obs_RZSM, include_lags_obs_pwat_spfh_tmax, addtl_experiment, experiment_test, region_name)\n",
    "\n",
    "    print(f'Testing input file is: {testing_input_file}')\n",
    "    ########### MAKE PREDICTIONS ON TRAINING, TESTING, VALIDATION SET ############################\n",
    "    # model = load_model(f'checkpoints/Wk_{lead}/Wk{lead}_{experiment_name_out}',compile=False)\n",
    "\n",
    "    print(f'Starting single prediction for Experiment {experiment_name_out}')\n",
    "    try:\n",
    "        model = load_model(checkpoint_filepath,compile=False) #don't need the custom loss function for predictions\n",
    "        \n",
    "        #Load data\n",
    "        reforecast_testing_input = np.load(testing_input_file)\n",
    "        \n",
    "        ########### SAVE PREDICTIONS (SINGLE PREDICTIONS) ############################\n",
    "        test_dir = f'predictions/{region_name}/Wk{lead}_testing'\n",
    "    \n",
    "        os.system(f'mkdir -p {test_dir}')\n",
    "    \n",
    "        mask = masks.load_mask(region_name)\n",
    "    \n",
    "        print('\\nCurrently only predicting the test dataset\\n')\n",
    "        predictions = model.predict(reforecast_testing_input)\n",
    "        # predictions.shape\n",
    "        np.save(f'{test_dir}/Wk{lead}_testing_{experiment_name_out}.npy',predictions)\n",
    "    except NameError:\n",
    "        print('Error loading model')\n",
    "        pass\n",
    "    except OSError:\n",
    "        print('Error loading model')\n",
    "        pass\n",
    "    \n",
    "    return(f'Completed Experiment {experiment_name_out}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b43bdde2-35f0-411e-8565-887afdb79625",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_single_predictions_training_validation(lead, include_reforecast_or_not, num_lags_obs_RZSM, include_lags_obs_pwat_spfh_tmax,addtl_experiment,experiment_test, region_name):\n",
    "    \n",
    "    save_experiment_name, experiment_name_out, experiment_name,lag_integer_list, \\\n",
    "    channel_save_dir, training_input_file, validation_input_file, \\\n",
    "    testing_input_file,checkpoint_filepath, losses_dir,save_checkpoint_dir, \\\n",
    "    save_experiment_dir = return_experiment_name_and_lags_and_channel_dir(include_reforecast_or_not, num_lags_obs_RZSM, include_lags_obs_pwat_spfh_tmax, addtl_experiment, experiment_test, region_name)\n",
    "\n",
    "    ########### MAKE PREDICTIONS ON TRAINING, TESTING, VALIDATION SET ############################\n",
    "    # model = load_model(f'checkpoints/Wk_{lead}/Wk{lead}_{experiment_name_out}',compile=False)\n",
    "\n",
    "    print(f'Starting single prediction for Experiment {experiment_name_out}')\n",
    "       \n",
    "    model = load_model(checkpoint_filepath,compile=False) #don't need the custom loss function for predictions\n",
    "    \n",
    "    #Load data\n",
    "    reforecast_training_input = np.load(training_input_file)\n",
    "    reforecast_validation_input = np.load(validation_input_file)\n",
    "\n",
    "    \n",
    "    ########### SAVE PREDICTIONS (SINGLE PREDICTIONS) ############################\n",
    "    train_val_dir = f'predictions/{region_name}/Wk{lead}_training_validation'\n",
    "\n",
    "    os.system(f'mkdir -p {train_val_dir}')\n",
    "\n",
    "    mask = masks.load_mask(region_name)\n",
    "\n",
    "    print('\\nPredicting training and validation input')\n",
    "    predictions = model.predict(reforecast_training_input)\n",
    "    # predictions.shape\n",
    "    np.save(f'{train_val_dir}/Wk{lead}_training_{experiment_name_out}.npy',predictions)\n",
    "    \n",
    "    predictions = model.predict(reforecast_validation_input)\n",
    "    # predictions.shape\n",
    "    np.save(f'{train_val_dir}/Wk{lead}_validation_{experiment_name_out}.npy',predictions)\n",
    "    \n",
    "    return(f'Completed Experiment {experiment_name_out}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "03e1d8a6-4f31-445e-8ce8-3393ce515359",
   "metadata": {},
   "outputs": [],
   "source": [
    "#These are models which only include the reforecast predictions. We are not including any observations into them.\n",
    "\n",
    "EX0 ={'region_name':region_name, 'num_lags_obs_RZSM': 0, 'include_lags_obs_pwat_spfh_tmax': False, 'include_reforecast_or_not': True, 'addtl_experiment': False, 'experiment_test':0 }\n",
    "EX13={'region_name':region_name, 'num_lags_obs_RZSM': 0, 'include_lags_obs_pwat_spfh_tmax': False, 'include_reforecast_or_not': True, 'addtl_experiment': True, 'experiment_test':1 }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4c1a1677-e926-450e-b8f7-6d3f4c93f63b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Include all predictors for obs but DO NOT include the current reforecast RZSM \n",
    "\n",
    "EX1 ={'region_name':region_name, 'num_lags_obs_RZSM': 3, 'include_lags_obs_pwat_spfh_tmax': True, 'include_reforecast_or_not': False, 'addtl_experiment': False, 'experiment_test':0 }\n",
    "EX2 ={'region_name':region_name, 'num_lags_obs_RZSM': 6, 'include_lags_obs_pwat_spfh_tmax': True, 'include_reforecast_or_not': False, 'addtl_experiment': False, 'experiment_test':0 }\n",
    "EX3 ={'region_name':region_name, 'num_lags_obs_RZSM': 9, 'include_lags_obs_pwat_spfh_tmax': True, 'include_reforecast_or_not': False, 'addtl_experiment': False, 'experiment_test':0 }\n",
    "EX4 ={'region_name':region_name, 'num_lags_obs_RZSM': 12, 'include_lags_obs_pwat_spfh_tmax': True, 'include_reforecast_or_not': False, 'addtl_experiment': False, 'experiment_test':0 }\n",
    "\n",
    "\n",
    "#Include all predictors for obs but DO include the current reforecast RZSM \n",
    "EX14 ={'region_name':region_name, 'num_lags_obs_RZSM': 3, 'include_lags_obs_pwat_spfh_tmax': True, 'include_reforecast_or_not': False, 'addtl_experiment': True, 'experiment_test':1 }\n",
    "EX15 ={'region_name':region_name, 'num_lags_obs_RZSM': 6, 'include_lags_obs_pwat_spfh_tmax': True, 'include_reforecast_or_not': False, 'addtl_experiment': True, 'experiment_test':2 }\n",
    "EX16 ={'region_name':region_name, 'num_lags_obs_RZSM': 9, 'include_lags_obs_pwat_spfh_tmax': True, 'include_reforecast_or_not': False, 'addtl_experiment': True, 'experiment_test':3 }\n",
    "EX17 ={'region_name':region_name, 'num_lags_obs_RZSM': 12, 'include_lags_obs_pwat_spfh_tmax': True, 'include_reforecast_or_not': False, 'addtl_experiment': True, 'experiment_test':4 }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "40665067-ac31-4ba4-afff-47017b4b33de",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Include only OBS RZSM predictors and the current reforecast RZSM week \n",
    "\n",
    "EX5 ={'region_name':region_name, 'num_lags_obs_RZSM': 3, 'include_lags_obs_pwat_spfh_tmax': False, 'include_reforecast_or_not': True, 'addtl_experiment': False, 'experiment_test':0 }\n",
    "EX6 ={'region_name':region_name, 'num_lags_obs_RZSM': 6, 'include_lags_obs_pwat_spfh_tmax': False, 'include_reforecast_or_not': True, 'addtl_experiment': False, 'experiment_test':0 }\n",
    "EX7 ={'region_name':region_name, 'num_lags_obs_RZSM': 9, 'include_lags_obs_pwat_spfh_tmax': False, 'include_reforecast_or_not': True, 'addtl_experiment': False, 'experiment_test':0 }\n",
    "EX8 ={'region_name':region_name, 'num_lags_obs_RZSM': 12, 'include_lags_obs_pwat_spfh_tmax': False, 'include_reforecast_or_not': True, 'addtl_experiment': False, 'experiment_test':0 }\n",
    "\n",
    "#Include only OBS RZSM predictors, previous weeks prediction, and current reforecast RZSM week \n",
    "EX18 ={'region_name':region_name, 'num_lags_obs_RZSM': 3, 'include_lags_obs_pwat_spfh_tmax': False, 'include_reforecast_or_not': True, 'addtl_experiment': True, 'experiment_test':1 }\n",
    "EX19 ={'region_name':region_name, 'num_lags_obs_RZSM': 6, 'include_lags_obs_pwat_spfh_tmax': False, 'include_reforecast_or_not': True, 'addtl_experiment': True, 'experiment_test':2 }\n",
    "EX20 ={'region_name':region_name, 'num_lags_obs_RZSM': 9, 'include_lags_obs_pwat_spfh_tmax': False, 'include_reforecast_or_not': True, 'addtl_experiment': True, 'experiment_test':3 }\n",
    "EX21 ={'region_name':region_name, 'num_lags_obs_RZSM': 12, 'include_lags_obs_pwat_spfh_tmax': False, 'include_reforecast_or_not': True, 'addtl_experiment': True, 'experiment_test':4 }\n",
    "\n",
    "#Include only OBS RZSM predictors DO NOT INCLUDE ANY REFORECAST OR PREDICTION\n",
    "EX22 ={'region_name':region_name, 'num_lags_obs_RZSM': 3, 'include_lags_obs_pwat_spfh_tmax': False, 'include_reforecast_or_not': True, 'addtl_experiment': True, 'experiment_test':5 }\n",
    "EX23 ={'region_name':region_name, 'num_lags_obs_RZSM': 6, 'include_lags_obs_pwat_spfh_tmax': False, 'include_reforecast_or_not': True, 'addtl_experiment': True, 'experiment_test':6 }\n",
    "EX24 ={'region_name':region_name, 'num_lags_obs_RZSM': 9, 'include_lags_obs_pwat_spfh_tmax': False, 'include_reforecast_or_not': True, 'addtl_experiment': True, 'experiment_test':7 }\n",
    "EX25 ={'region_name':region_name, 'num_lags_obs_RZSM': 12, 'include_lags_obs_pwat_spfh_tmax': False, 'include_reforecast_or_not': True, 'addtl_experiment': True, 'experiment_test':8 }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cc90eaef-f15d-49e6-8ae1-be3f15b7671b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Include only OBS RZSM predictors, OBS other variables, previous predictions of RZSM, and current reforecast lead\n",
    "\n",
    "EX9 ={'region_name':region_name, 'num_lags_obs_RZSM': 3, 'include_lags_obs_pwat_spfh_tmax': True, 'include_reforecast_or_not': True, 'addtl_experiment': False, 'experiment_test':0 }\n",
    "EX10 ={'region_name':region_name, 'num_lags_obs_RZSM': 6, 'include_lags_obs_pwat_spfh_tmax': True, 'include_reforecast_or_not': True, 'addtl_experiment': False, 'experiment_test':0 }\n",
    "EX11 ={'region_name':region_name, 'num_lags_obs_RZSM': 9, 'include_lags_obs_pwat_spfh_tmax': True, 'include_reforecast_or_not': True, 'addtl_experiment': False, 'experiment_test':0 }\n",
    "EX12 ={'region_name':region_name, 'num_lags_obs_RZSM': 12, 'include_lags_obs_pwat_spfh_tmax': True, 'include_reforecast_or_not': True, 'addtl_experiment': False, 'experiment_test':0 }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d7676e44-292d-4d97-b09b-420e6d82cf4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# EX26 ={'region_name':region_name, 'num_lags_obs_RZSM': 3, 'include_lags_obs_pwat_spfh_tmax': True, 'include_reforecast_or_not': True, 'addtl_experiment': False, 'experiment_test':0 }\n",
    "\n",
    "# run_EXPERIMENT(num_lags_obs_RZSM=0,include_lags_obs_pwat_spfh_tmax=False,include_reforecast_or_not=True, addtl_experiment = False, experiment_test = 26)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a82df4c6-6153-4b5e-a9bd-882db0499056",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This like EX9 and EX10 except now we are adding additional reforecast predictors from week 1 and 2\n",
    "\n",
    "EX27 ={'region_name':region_name, 'num_lags_obs_RZSM': 3, 'include_lags_obs_pwat_spfh_tmax': True, 'include_reforecast_or_not': True, 'addtl_experiment': False, 'experiment_test':1 }\n",
    "EX28 ={'region_name':region_name, 'num_lags_obs_RZSM': 6, 'include_lags_obs_pwat_spfh_tmax': True, 'include_reforecast_or_not': True, 'addtl_experiment': False, 'experiment_test':1 }\n",
    "\n",
    "EX29 ={'region_name':region_name, 'num_lags_obs_RZSM': 3, 'include_lags_obs_pwat_spfh_tmax': True, 'include_reforecast_or_not': True, 'addtl_experiment': False, 'experiment_test':2 }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "57418c32-98e7-41c1-adc4-78597ba6191d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_model_and_prediction(experiment):\n",
    "    global lead_week\n",
    "    for lead_week in [1]:\n",
    "        global lead\n",
    "        lead=lead_week\n",
    "    \n",
    "        generate_model_inputs(region_name=experiment['region_name'], lead = lead_week, num_lags_obs_RZSM=experiment['num_lags_obs_RZSM'],\n",
    "                              include_lags_obs_pwat_spfh_tmax=experiment['include_lags_obs_pwat_spfh_tmax'],include_reforecast_or_not=experiment['include_reforecast_or_not'], \n",
    "                              addtl_experiment = experiment['addtl_experiment'], experiment_test = experiment['experiment_test'])\n",
    "    \n",
    "        # run_EXPERIMENT(region_name=experiment['region_name'], lead = lead_week, num_lags_obs_RZSM=experiment['num_lags_obs_RZSM'],\n",
    "        #                       include_lags_obs_pwat_spfh_tmax=experiment['include_lags_obs_pwat_spfh_tmax'],include_reforecast_or_not=experiment['include_reforecast_or_not'], \n",
    "        #                       addtl_experiment = experiment['addtl_experiment'], experiment_test = experiment['experiment_test'])\n",
    "    \n",
    "        # make_single_predictions_training_validation(region_name=experiment['region_name'], lead = lead_week, num_lags_obs_RZSM=experiment['num_lags_obs_RZSM'],\n",
    "        #                       include_lags_obs_pwat_spfh_tmax=experiment['include_lags_obs_pwat_spfh_tmax'],include_reforecast_or_not=experiment['include_reforecast_or_not'], \n",
    "        #                       addtl_experiment = experiment['addtl_experiment'], experiment_test = experiment['experiment_test'])\n",
    "\n",
    "        make_single_predictions_testing(region_name=experiment['region_name'], lead = lead_week, num_lags_obs_RZSM=experiment['num_lags_obs_RZSM'],\n",
    "                              include_lags_obs_pwat_spfh_tmax=experiment['include_lags_obs_pwat_spfh_tmax'],include_reforecast_or_not=experiment['include_reforecast_or_not'], \n",
    "                              addtl_experiment = experiment['addtl_experiment'], experiment_test = experiment['experiment_test'])\n",
    "\n",
    "        #For permutation test\n",
    "        # obs_final_train,obs_final_validation,obs_final_testing = verifications.open_obs_for_verification(region_name, [6,13,20,27],train_start, train_end, val_start, val_end, test_start, test_end)\n",
    "        \n",
    "    print(f'Completed {experiment}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "18163d41-4c88-4b76-9249-339910d0aaa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on experiment {'region_name': 'CONUS', 'num_lags_obs_RZSM': 0, 'include_lags_obs_pwat_spfh_tmax': False, 'include_reforecast_or_not': True, 'addtl_experiment': False, 'experiment_test': 0}\n",
      "\n",
      "Working on setting up data for Experiment EX29 for lead 1\n",
      "\n",
      "Training input shape = (9185, 48, 96, 13)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory Data/model_npy_inputs: File exists\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'Data/model_npy_inputs/CONUS/Model_input_data/obs_soilw_bgrnd_GLEAM_training.pickle'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m experiment \u001b[38;5;129;01min\u001b[39;00m all_exps:\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mWorking on experiment \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexperiment\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 5\u001b[0m     \u001b[43mrun_model_and_prediction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexperiment\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mEX29\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m t\n",
      "Cell \u001b[0;32mIn[26], line 7\u001b[0m, in \u001b[0;36mrun_model_and_prediction\u001b[0;34m(experiment)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mglobal\u001b[39;00m lead\n\u001b[1;32m      5\u001b[0m lead\u001b[38;5;241m=\u001b[39mlead_week\n\u001b[0;32m----> 7\u001b[0m \u001b[43mgenerate_model_inputs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mregion_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexperiment\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mregion_name\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlead\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mlead_week\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_lags_obs_RZSM\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexperiment\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mnum_lags_obs_RZSM\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m                      \u001b[49m\u001b[43minclude_lags_obs_pwat_spfh_tmax\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexperiment\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43minclude_lags_obs_pwat_spfh_tmax\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43minclude_reforecast_or_not\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexperiment\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43minclude_reforecast_or_not\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m                      \u001b[49m\u001b[43maddtl_experiment\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mexperiment\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43maddtl_experiment\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexperiment_test\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mexperiment\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mexperiment_test\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# run_EXPERIMENT(region_name=experiment['region_name'], lead = lead_week, num_lags_obs_RZSM=experiment['num_lags_obs_RZSM'],\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m#                       include_lags_obs_pwat_spfh_tmax=experiment['include_lags_obs_pwat_spfh_tmax'],include_reforecast_or_not=experiment['include_reforecast_or_not'], \u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m#                       addtl_experiment = experiment['addtl_experiment'], experiment_test = experiment['experiment_test'])\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m#                       include_lags_obs_pwat_spfh_tmax=experiment['include_lags_obs_pwat_spfh_tmax'],include_reforecast_or_not=experiment['include_reforecast_or_not'], \u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m#                       addtl_experiment = experiment['addtl_experiment'], experiment_test = experiment['experiment_test'])\u001b[39;00m\n\u001b[1;32m     19\u001b[0m make_single_predictions_testing(region_name\u001b[38;5;241m=\u001b[39mexperiment[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mregion_name\u001b[39m\u001b[38;5;124m'\u001b[39m], lead \u001b[38;5;241m=\u001b[39m lead_week, num_lags_obs_RZSM\u001b[38;5;241m=\u001b[39mexperiment[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnum_lags_obs_RZSM\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m     20\u001b[0m                       include_lags_obs_pwat_spfh_tmax\u001b[38;5;241m=\u001b[39mexperiment[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minclude_lags_obs_pwat_spfh_tmax\u001b[39m\u001b[38;5;124m'\u001b[39m],include_reforecast_or_not\u001b[38;5;241m=\u001b[39mexperiment[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minclude_reforecast_or_not\u001b[39m\u001b[38;5;124m'\u001b[39m], \n\u001b[1;32m     21\u001b[0m                       addtl_experiment \u001b[38;5;241m=\u001b[39m experiment[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maddtl_experiment\u001b[39m\u001b[38;5;124m'\u001b[39m], experiment_test \u001b[38;5;241m=\u001b[39m experiment[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mexperiment_test\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "Cell \u001b[0;32mIn[14], line 13\u001b[0m, in \u001b[0;36mgenerate_model_inputs\u001b[0;34m(region_name, lead, include_reforecast_or_not, num_lags_obs_RZSM, include_lags_obs_pwat_spfh_tmax, addtl_experiment, experiment_test)\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     12\u001b[0m     reforecast_train_input, reforecast_validation_input, reforecast_testing_input, channel_list \\\n\u001b[0;32m---> 13\u001b[0m     \u001b[38;5;241m=\u001b[39m \u001b[43mmake_UNET_stacked_inputs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlead\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_lags_obs_RZSM\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minclude_lags_obs_pwat_spfh_tmax\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minclude_reforecast_or_not\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m                         \u001b[49m\u001b[43mobservation_lag_list_not_RZSM\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlag_integer_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_directory\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtraining_size_shape\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m                         \u001b[49m\u001b[43mvalidation_testing_size_shape\u001b[49m\u001b[43m,\u001b[49m\u001b[43mexperiment_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43mRZSM_or_Tmax_or_both\u001b[49m\u001b[43m,\u001b[49m\u001b[43maddtl_experiment\u001b[49m\u001b[43m,\u001b[49m\u001b[43mexperiment_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43mregion_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43mexperiment_name_out\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;66;03m#Save data to file\u001b[39;00m\n\u001b[1;32m     18\u001b[0m     np\u001b[38;5;241m.\u001b[39msave(training_input_file,tf\u001b[38;5;241m.\u001b[39mconvert_to_tensor(reforecast_train_input,dtype\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mfloat32))\n",
      "Cell \u001b[0;32mIn[10], line 96\u001b[0m, in \u001b[0;36mmake_UNET_stacked_inputs\u001b[0;34m(lead, num_lags_obs_RZSM, include_lags_obs_pwat_spfh_tmax, include_reforecast_or_not, observation_lag_list_not_RZSM, lag_integer_list, input_directory, training_size_shape, validation_testing_size_shape, experiment_name, RZSM_or_Tmax_or_both, addtl_experiment, experiment_test, region_name, experiment_name_out)\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m (experiment_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEX29\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m     94\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mWorking on setting up data for Experiment \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexperiment_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for lead \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlead\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 96\u001b[0m     final_input_train, final_input_validation, final_input_testing,channel_list \u001b[38;5;241m=\u001b[39m \u001b[43mload_all_data_EX29_after_week_0\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlead\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_lags_obs_RZSM\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minclude_lags_obs_pwat_spfh_tmax\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minclude_reforecast_or_not\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     97\u001b[0m \u001b[43m                                                                                               \u001b[49m\u001b[43mobservation_lag_list_not_RZSM\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlag_integer_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_directory\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtraining_size_shape\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     98\u001b[0m \u001b[43m                                                                                           \u001b[49m\u001b[43mvalidation_testing_size_shape\u001b[49m\u001b[43m,\u001b[49m\u001b[43mexperiment_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43mRZSM_or_Tmax_or_both\u001b[49m\u001b[43m,\u001b[49m\u001b[43mexperiment_test\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mexperiment_test\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     99\u001b[0m \u001b[43m                                                                                                                                   \u001b[49m\u001b[43mregion_name\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mregion_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43mexperiment_name_out\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexperiment_name_out\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    102\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m (final_input_train,final_input_validation,final_input_testing,channel_list)\n",
      "Cell \u001b[0;32mIn[8], line 32\u001b[0m, in \u001b[0;36mload_all_data_EX29_after_week_0\u001b[0;34m(lead, num_lags_obs_RZSM, include_lags_obs_pwat_spfh_tmax, include_reforecast_or_not, observation_lag_list_not_RZSM, lag_integer_list, input_directory, training_size_shape, validation_testing_size_shape, experiment_name, RZSM_or_Tmax_or_both, experiment_test, region_name, experiment_name_out)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx,lag \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(lag_integer_list):\n\u001b[1;32m     31\u001b[0m     channel_list\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRZSM_obs_lag\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlag\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 32\u001b[0m     training_input, validation_input, testing_input \u001b[38;5;241m=\u001b[39m \u001b[43mpred\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_obs_RZSM_by_lag\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtraining_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtesting_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlag\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_directory\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfinal_testing_year\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mIndex idx value is \u001b[39m\u001b[38;5;132;01m{\u001b[39;00midx\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. Done adding RZSM obs.\u001b[39m\u001b[38;5;124m'\u001b[39m)    \n\u001b[1;32m     36\u001b[0m RZSM_train_obs, RZSM_validation_obs \u001b[38;5;241m=\u001b[39m pred\u001b[38;5;241m.\u001b[39mreturn_masking_objects_for_RZSM(input_directory, final_testing_year)\n",
      "File \u001b[0;32m/glade/work/klesinger/FD_RZSM_deep_learning/addPredictors.py:14\u001b[0m, in \u001b[0;36madd_obs_RZSM_by_lag\u001b[0;34m(training_input, validation_input, testing_input, lag, input_directory, idx, final_testing_year)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     12\u001b[0m     add_year \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfinal_testing_year\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m---> 14\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43minput_directory\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/obs_soilw_bgrnd_GLEAM_training\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43madd_year\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m.pickle\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m handle:\n\u001b[1;32m     15\u001b[0m     training_input[:,:,:,idx] \u001b[38;5;241m=\u001b[39m pickle\u001b[38;5;241m.\u001b[39mload(handle)[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLag\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlag\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00minput_directory\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/obs_soilw_bgrnd_GLEAM_validation\u001b[39m\u001b[38;5;132;01m{\u001b[39;00madd_year\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.pickle\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m handle:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Data/model_npy_inputs/CONUS/Model_input_data/obs_soilw_bgrnd_GLEAM_training.pickle'"
     ]
    }
   ],
   "source": [
    "all_exps= [EX0,EX1,EX2,EX3,EX4,EX5,EX6,EX7,EX8,EX9,EX10,EX11,EX13,EX14,EX15,EX16,EX17,EX18,EX19,EX20,EX21,EX22,EX23,EX24,EX25,EX27,EX28,EX29]\n",
    "\n",
    "for experiment in all_exps:\n",
    "    print(f'Working on experiment {experiment}')\n",
    "    run_model_and_prediction(experiment = experiment)\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3b049dc-6d03-4536-ac3e-7f268dad8983",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for ex in [EX1,EX2,EX3,EX4,EX14,EX15,]:\n",
    "    run_model_and_prediction(experiment = ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8962f62-2b4e-4d69-ac9b-b34357f243d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e919d116-d1de-4f28-a142-07f3c43a2f0a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1ccd3e21-a645-4ce3-862c-d15711d3ca5f",
   "metadata": {},
   "source": [
    "# Permutation test only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a00e185-77b0-4c1b-bee4-e907faf0d00b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_plot_permutation(lead,dictionary,metric):\n",
    "    test=pd.DataFrame(dictionary,index=[metric])\n",
    "    return(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c502857f-4068-4278-85e9-21184ae8a4f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_barplot_mae_rmse(save_for_plot_mae, save_for_plot_rmse, lead, model_name):\n",
    "    save_permutation_figures = f'Outputs/permutation_tests/barplots/{region_name}/Wk{lead}'\n",
    "    os.system(f'mkdir -p {save_permutation_figures}')\n",
    "    \n",
    "    mae = setup_plot_permutation(lead,save_for_plot_mae,'MAE')\n",
    "    rmse = setup_plot_permutation(lead,save_for_plot_rmse,'RMSE')\n",
    "       \n",
    "    # Plotting\n",
    "    fig, axs = plt.subplots(2)\n",
    "    \n",
    "    # Plot for DataFrame 1\n",
    "    mae.plot(kind='bar', ax=axs[0])\n",
    "    axs[0].set_title('MAE')\n",
    "    \n",
    "    # Plot for DataFrame 2\n",
    "    rmse.plot(kind='bar', ax=axs[1])\n",
    "    axs[1].set_title('RMSE')\n",
    "    \n",
    "    # Adjust layout\n",
    "    # plt.tight_layout()\n",
    "    plt.savefig(f'{save_permutation_figures}/{model_name}.png')\n",
    "    plt.show()\n",
    "\n",
    "    return(0)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9deedd83-197b-46c1-b633-3edc6553e429",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def create_plot_permutation(lead,max_RZSM_value,region_name):\n",
    "    save_permutation_figures = f'Outputs/permutation_tests/{region_name}/plots/Wk{lead}'\n",
    "    os.system(f'mkdir -p {save_permutation_figures}')\n",
    "\n",
    "    # del plot_['Lead']\n",
    "    plot_ = plot_.T #Must transpose to make it plot properly\n",
    "\n",
    "    fig = plt.figure(figsize=(8,6))\n",
    "\n",
    "    ax = fig.add_subplot(111) # Create matplotlib axes\n",
    "\n",
    "    plot_.RZSM.plot(kind='bar', color='red',width=0.3, ax=ax, position=1)\n",
    "\n",
    "    ax.set_ylabel('RZSM anomaly MAE')\n",
    "    ax.set_ylim(0, max_RZSM_value)\n",
    "\n",
    "    # plot_.plot(kind='bar')\n",
    "    # plt.ylabel(f'{error_}')\n",
    "    plt.suptitle(f'Permutation Test\\nObservation values are in legend\\nWk{lead} {experiment_name_out}',fontsize=10)\n",
    "    \n",
    "    legend1 = ax.legend(loc='upper right', bbox_to_anchor=(1.0, 1))\n",
    "\n",
    "    ax.set_xlabel('\\nPermutated Channels',weight='bold')\n",
    "    plt.tight_layout()\n",
    "\n",
    "    plt.savefig(f'{save_permutation_figures}/{experiment_name_out}.png')\n",
    "    #plt.savefig(f'{save_permutation_figures}/{experiment_name}.tiff', format='tiff', dpi=300)\n",
    "    #tiff.imsave(f'{save_permutation_figures}/{experiment_name}.tiff', data_array)\n",
    "    plt.show()\n",
    "\n",
    "    return(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fbc67dc-14fb-4ff9-bd67-299585c469ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_data_and_experiment_numbers(region_name, leads,train_start, train_end, val_start, val_end, test_start, test_end,day_num):\n",
    "        \n",
    "    obs_final_train,obs_final_validation,obs_final_testing = verifications.open_obs_for_verification(region_name, leads,train_start, train_end, val_start, val_end, test_start, test_end)\n",
    "\n",
    "    obs_final_testing = obs_final_testing.sel(L=day_num)\n",
    "    '''Now that we have the observations, we need to loop through each of the testing files and permutate them'''\n",
    "    \n",
    "    save_permutation_figures = f'Outputs/permutation_data/{region_name}'\n",
    "    os.system(f'mkdir -p {save_permutation_figures}')\n",
    "\n",
    "    #Get the files from the correct location (we need to loop through each of the models.\n",
    "    # exps = sorted(glob(f'checkpoints/{region_name}/Wk{lead}/*'))\n",
    "    exps = sorted(glob(f'Data/model_npy_inputs/{region_name}/Wk{lead}_EX_input_data/*testing*'))\n",
    "\n",
    "    exps = [i for i in exps if 'RZSM' in i]\n",
    "    exps = [i for i in exps if 'XGBOOST' not in i]\n",
    "\n",
    "    #Make a list of the experiment names. We only need to grab a single file since they all have the same data\n",
    "    '''We are going to seperate by hybrid and obs.driven. So remove EX0 and EX13'''\n",
    "    EX_list = [f'EX{i}' for i in range(26)]\n",
    "    EX_list = EX_list+['EX27']+['EX28']\n",
    "    EX_list = [i for i in EX_list if 'EX0' not in i ]\n",
    "    EX_list = [i for i in EX_list if 'EX13' not in i ]\n",
    "    # EX_list = [i for i in EX_list if 'EX10' not in i ]\n",
    "\n",
    "    return(obs_final_train,obs_final_validation,obs_final_testing,EX_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17f2063f-795a-42d6-a56b-578e1b0e6029",
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_the_experiment_input(exps,file,lead):\n",
    "    '''First find the experiment name within the file'''\n",
    "    ex_num = file.split(f'Wk{lead}_')[-1].split('_')[0]\n",
    "\n",
    "    '''Now loop through exps to grab the correct input'''\n",
    "    correct_file = [i for i in exps if ex_num in i]\n",
    "    correct_file = [i for i in correct_file if 'XGBOOST' not in i]\n",
    "\n",
    "    return(np.load(correct_file[0]),ex_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb6e33bc-03df-45a5-8c5f-27e7c9c0ea03",
   "metadata": {},
   "outputs": [],
   "source": [
    "def permutation_test_by_lead_save_MAE_RMSE(lead, test_year):\n",
    "    #test \n",
    "    # lead = 1\n",
    "    # test_year=2019\n",
    "\n",
    "    day_num = (lead*7) -1\n",
    "    \n",
    "    file_path = f'Outputs/permutation_tests/mae_rmse_results'\n",
    "    file_rmse_save = f'{file_path}/Wk{lead}_rmse_vals.pkl'\n",
    "    file_mae_save = f'{file_path}/Wk{lead}_mae_vals.pkl'\n",
    "    complete_rmse = f'{file_path}/Wk{lead}_rmse_complete.pkl'\n",
    "    complete_mae = f'{file_path}/Wk{lead}_mae_complete.pkl'\n",
    "    \n",
    "    os.system(f'mkdir -p {file_path}')\n",
    "\n",
    "    rmse_output, mae_output, rmse_complete, mae_complete = putils.return_rmse_and_mae_pickle_files(file_rmse_save, file_mae_save, complete_mae, complete_rmse)\n",
    "\n",
    "    ###########################################################################\n",
    "\n",
    "    leads = [6,13,20,27,34]\n",
    "\n",
    "    obs_final_train,obs_final_validation,obs_final_testing,EX_list = return_data_and_experiment_numbers(region_name, leads,train_start, train_end, val_start, val_end, test_start, test_end,day_num)\n",
    "\n",
    "    obs_final_testing_arr = obs_final_testing[putils.xarray_varname(obs_final_testing)].to_numpy()\n",
    "    '''These are the actual experiment names below'''\n",
    "    BC,OBS,HYB = verifications.return_experiment_colors_and_names()\n",
    "\n",
    "    '''Loop through each model checkpoint'''\n",
    "    checkpt_dir = f'checkpoints/{region_name}/Wk{lead}'\n",
    "    file_list = sorted(glob(f'{checkpt_dir}/*regular*'))\n",
    "    file_list = [i for i in file_list if '.' not in i] \n",
    "    file_list = [i for i in file_list if '/checkpoint' not in i]\n",
    "    file_list = [i for i in file_list if 'ECMWF' not in i] #don't do ECMWF. We haven't coded it with different varabiles yet\n",
    "    file_list = [i for i in file_list if '2012' not in i]\n",
    "\n",
    "    ##########################################################################\n",
    "    if test_year == 2019:\n",
    "        file_list = [i for i in file_list if '2012' not in i]\n",
    "    else:\n",
    "        file_list = [i for i in file_list if str(pd.to_datetime(test_end).year) in i]\n",
    "\n",
    "    '''Experiment saved inputs'''\n",
    "    exps = sorted(glob(f'Data/model_npy_inputs/{region_name}/Wk{lead}_EX_input_data/*testing*'))\n",
    "    exps = [i for i in exps if 'XGBOOST' not in i]\n",
    "    exps = [i for i in exps if 'mean' not in i]\n",
    "\n",
    "    print(f'Working on file list {file_list}')\n",
    "\n",
    "    #For masking\n",
    "    RZSM_train_obs, RZSM_validation_obs = pred.return_masking_objects_for_RZSM(input_directory,final_testing_year)\n",
    "    mask_zero = RZSM_validation_obs.squeeze()\n",
    "    \n",
    "    for file in file_list:\n",
    "        print(f'Working on file experiment {file}')\n",
    "        # break\n",
    "        try:\n",
    "            testing_input,ex_num = return_the_experiment_input(exps,file,lead)\n",
    "            channel_list = f.load_channel_list_permutation(ex_num, lead)\n",
    "            dont_continue=False\n",
    "        except IndexError:\n",
    "            dont_continue = True\n",
    "\n",
    "        try:\n",
    "            model = load_model(file,compile=False)\n",
    "            dont_continue = False\n",
    "        except OSError:\n",
    "            dont_continue = True # No model information found\n",
    "            \n",
    "        if dont_continue:\n",
    "            pass\n",
    "        else:\n",
    "            if (len(channel_list) == testing_input.shape[-1]):\n",
    "\n",
    "                model_name = file.split('/')[-1].split('_testing')[0]\n",
    "                \n",
    "                #These will contain the average MAE and RMSE across CONUS to plot\n",
    "                save_for_plot_mae = {}\n",
    "                save_for_plot_rmse = {}\n",
    "\n",
    "                continue_ = False\n",
    "                \n",
    "                for idx,channel in enumerate(channel_list):\n",
    "                    # break\n",
    "                    '''Check if we have already completed it'''\n",
    "                    unit_test = putils.check_if_already_completed_permuatation(rmse_complete, mae_complete, ex_num,  OBS, HYB, channel, model_name)\n",
    "\n",
    "                    '''Check if there is a .csv file already saved'''\n",
    "                    \n",
    "                    if unit_test == 'Not-Completed':\n",
    "                        # break\n",
    "                        print(f'\\nPermutating channel {channel}\\n')\n",
    "    \n",
    "                        new_input_with_noise,reforecast_nan,var_noise_min,var_noise_max,var_ = f.load_min_max_files_and_rescale_data(testing_input,channel,idx,file,region_name,day_num,test_year,lead)\n",
    "    \n",
    "                        try:\n",
    "                            prediction_ = np.array(model.predict(new_input_with_noise))\n",
    "                            prediction_.shape\n",
    "                            \n",
    "                            '''Just choose the very last prediction made'''\n",
    "                            prediction_ = prediction_[-1,:,:,:,0]\n",
    "        \n",
    "                            yhat = verifications.reverse_min_max_scaling_for_permutations(prediction_,region_name,day_num,'GEFSv12',test_year,'soilw_bgrnd')\n",
    "            \n",
    "                            yhat = np.where(np.isnan(reforecast_nan),np.nan,yhat)\n",
    "                            yhat = np.where(mask_zero == 0, np.nan, yhat)\n",
    "                            # yhat = np.where(np.isnan(reforecast_nan),np.nan,yhat.squeeze())\n",
    "                            yhat = np.reshape(yhat,(yhat.shape[0]//11,11,yhat.shape[1],yhat.shape[2]))\n",
    "                \n",
    "                            RZSM_mae =np.nanmean(np.abs(obs_final_testing_arr -  yhat),axis=(0,1))\n",
    "                \n",
    "                            RZSM_rmse = np.nanmean((obs_final_testing_arr -  yhat)**2,axis=(0,1))\n",
    "    \n",
    "                            save_for_plot_rmse[channel] = np.nanmean(RZSM_rmse)\n",
    "                            save_for_plot_mae[channel] = np.nanmean(RZSM_mae)\n",
    "                        \n",
    "                            '''Now add to the dictionary for RMSE'''\n",
    "                            if ex_num in OBS:\n",
    "                                try:\n",
    "                                    # if output['OBS'][channel]['Value']\n",
    "                                    rmse_output['OBS'][channel]['Value'] = rmse_output['OBS'][channel]['Value'] + RZSM_rmse\n",
    "                                    rmse_output['OBS'][channel]['Num_experiments'] = rmse_output['OBS'][channel]['Num_experiments'] + 1\n",
    "                                    rmse_complete['OBS'][model_name].append(channel)\n",
    "                                except KeyError:\n",
    "                                    rmse_output['OBS'][channel] = {'Num_experiments':1, 'Value':RZSM_rmse}\n",
    "                                    rmse_complete = putils.append_to_complete_list(rmse_complete, model_name, channel, 'OBS')\n",
    "                                    \n",
    "                            elif ex_num in HYB:\n",
    "                                try:\n",
    "                                    rmse_output['HYB'][channel]['Value'] = rmse_output['HYB'][channel]['Value'] + RZSM_rmse\n",
    "                                    rmse_output['HYB'][channel]['Num_experiments'] = rmse_output['HYB'][channel]['Num_experiments'] + 1\n",
    "                                    rmse_complete['HYB'][model_name].append(channel)\n",
    "                                except KeyError:\n",
    "                                    rmse_output['HYB'][channel] = {'Num_experiments':1, 'Value':RZSM_rmse}\n",
    "                                    rmse_complete = putils.append_to_complete_list(rmse_complete, model_name, channel, 'HYB')\n",
    "\n",
    "                                    \n",
    "                            '''Now add to the dictionary for MAE only'''\n",
    "                            if ex_num in OBS:\n",
    "                                try:\n",
    "                                    mae_output['OBS'][channel]['Value'] = mae_output['OBS'][channel]['Value'] + RZSM_mae\n",
    "                                    mae_output['OBS'][channel]['Num_experiments'] = mae_output['OBS'][channel]['Num_experiments'] + 1\n",
    "                                    mae_complete['OBS'][model_name].append(channel)\n",
    "                                except KeyError:\n",
    "                                    mae_output['OBS'][channel] = {'Num_experiments':1, 'Value':RZSM_mae}\n",
    "                                    mae_complete = putils.append_to_complete_list(mae_complete, model_name, channel, 'OBS')\n",
    "\n",
    "                            elif ex_num in HYB:\n",
    "                                try:\n",
    "                                    mae_output['HYB'][channel]['Value'] = mae_output['HYB'][channel]['Value'] + RZSM_mae\n",
    "                                    mae_output['HYB'][channel]['Num_experiments'] = mae_output['HYB'][channel]['Num_experiments'] + 1\n",
    "                                    mae_complete['HYB'][model_name].append(channel)\n",
    "                                except KeyError:\n",
    "                                    mae_output['HYB'][channel] = {'Num_experiments':1, 'Value':RZSM_mae}\n",
    "                                    mae_complete = putils.append_to_complete_list(mae_complete, model_name, channel, 'HYB')\n",
    "\n",
    "    \n",
    "                            continue_ = True\n",
    "                        \n",
    "                        except ValueError:\n",
    "                            continue_ = False\n",
    "                            pass\n",
    "                        \n",
    "                if continue_:\n",
    "                    plot_barplot_mae_rmse(save_for_plot_mae, save_for_plot_rmse, lead, model_name)\n",
    "                    \n",
    "            \n",
    "        '''Saves after each file is completed'''\n",
    "        with open(file_rmse_save, 'wb') as file:\n",
    "            pickle.dump(rmse_output, file)\n",
    "    \n",
    "        with open(file_mae_save, 'wb') as file:\n",
    "            pickle.dump(mae_output, file)\n",
    "        \n",
    "        with open(complete_rmse, 'wb') as file:\n",
    "            pickle.dump(rmse_complete, file)\n",
    "    \n",
    "        with open(complete_mae, 'wb') as file:\n",
    "            pickle.dump(mae_complete, file)\n",
    "\n",
    "    return(f'Completed week {lead}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02814ccf-334d-45cb-a20a-df38b168922d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# '''Permutation test'''\n",
    "# for lead in [1,2,3,4]:\n",
    "#     permutation_test_by_lead_save_MAE_RMSE(lead=lead, test_year=2019) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8ae0fa9-658a-4efb-b3be-219dbd79e77a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def permutation_test_save_csv(lead,experiment,train,val,test):\n",
    "    save_permutation_figures = f'Outputs/permutation_tests/Wk_{lead}'\n",
    "    os.system(f'mkdir -p {save_permutation_figures}')\n",
    "    \n",
    "    day_num = (lead*7)-1\n",
    "    \n",
    "    num_lags_obs_RZSM=experiment['num_lags_obs_RZSM']\n",
    "    include_lags_obs_pwat_spfh_tmax=experiment['include_lags_obs_pwat_spfh_tmax']\n",
    "    include_reforecast_or_not=experiment['include_reforecast_or_not']\n",
    "    addtl_experiment = experiment['addtl_experiment']\n",
    "    experiment_test = experiment['experiment_test']\n",
    "\n",
    "    experiment_name = CE.return_experiment_name(include_reforecast_or_not,num_lags_obs_RZSM,include_lags_obs_pwat_spfh_tmax,addtl_experiment,experiment_test)\n",
    "    experiment_name_out = f'{experiment_name}_RZSM'\n",
    "    \n",
    "    save_csv_path = f'{save_permutation_figures}/{experiment_name_out}.csv'    \n",
    "    obs_final_testing_arr = test.RZSM.values\n",
    "\n",
    "    obs_final_testing_arr = np.reshape(obs_final_testing_arr,(1144,48,96))\n",
    "    \n",
    "    ref_data = f'Data/model_npy_inputs/{region_name}/Wk{lead}_EX_input_data/{experiment_name_out}_testing_input.npy'\n",
    "    \n",
    "    if os.path.exists('redoooo.nc'):\n",
    "    # if os.path.exists(save_csv_path):\n",
    "        print(f'Already saved the csv file into path {save_csv_path}')\n",
    "    elif os.path.exists(ref_data):\n",
    "        reg_name = f'{experiment_name_out.split(\"_\")[0]}_regular_RZSM'\n",
    "\n",
    "        print(f'\\n\\n Starting permutation test with experiment {reg_name} \\n\\n')\n",
    "        \n",
    "        reforecast_testing_input = np.load(ref_data)\n",
    "        \n",
    "        #Load model \n",
    "        try:\n",
    "            model = load_model(f'checkpoints/{region_name}/Wk{lead}/Wk{lead}_{reg_name}',compile=False) #don't need the custom loss function for predictions\n",
    "            channel_list = f.load_channel_list_permutation(experiment_name_out, lead)\n",
    "        except OSError:\n",
    "            model_name = f'checkpoints/{region_name}/Wk{lead}/Wk{lead}_{experiment_name_out}'\n",
    "            model = load_model(model_name,compile=False) #don't need the custom loss function for predictions\n",
    "            channel_list = f.load_channel_list_permutation(experiment_name_out, lead)\n",
    "\n",
    "        \n",
    "        out_dict = {}\n",
    "        for idx,channel in enumerate(channel_list):\n",
    "            print(f'\\nPermutating channel {channel}\\n')\n",
    "            # break\n",
    "            '''Take the input, reverse back to anomaly, find mean and std, add gaussian noise according to the mean and std, get min max, then rescale to min max'''\n",
    "            new_input_with_noise,reforecast_nan,var_noise_min,var_noise_max,var_ = f.load_min_max_files_and_rescale_data(reforecast_testing_input,channel,idx,'GEFSv12',region_name,day_num,test_year,lead)\n",
    "            #The output is now min max scaled\n",
    "\n",
    "            pred_ = np.array(model.predict(new_input_with_noise))\n",
    "            '''Just choose the very last prediction made'''\n",
    "            pred_ = pred_[-1,:,:,:,0]\n",
    "\n",
    "            #Reverse the min max scaling from prediction back to anomaly\n",
    "            # pred_ = pred_ *(var_noise_max-var_noise_min)+var_noise_min \n",
    "            pred_ = verifications.reverse_min_max_scaling(pred_, region_name, day_num, 'GEFSv12',2019) #We only want the last channel\n",
    "            '''rescale back to anomaly with the min and max from the noisy dataset'''\n",
    "            #Now data is in the anomaly form\n",
    "\n",
    "            \n",
    "            pred_ = np.where(np.isnan(reforecast_nan),np.nan,pred_)\n",
    "            pred_ = np.where(np.isnan(obs_final_testing_arr), np.nan, pred_) #observation mask\n",
    "            # yhat = np.where(np.isnan(reforecast_nan),np.nan,yhat.squeeze())\n",
    "            # pred_ = np.reshape(pred_,(pred_.shape[0]//11,11,pred_.shape[1],pred_.shape[2]))\n",
    "\n",
    "            RZSM_mae =np.nanmean(np.abs(obs_final_testing_arr -  pred_))\n",
    "            # RZSM_rmse = np.nanmean((obs_final_testing_arr -  prediction_)**2)\n",
    "\n",
    "            out_dict[f'{channel}'] = np.nanmean(RZSM_mae)\n",
    "            print(f'RZSM MAE of channel {channel} is {np.nanmean(RZSM_mae)}')\n",
    "            contn = True\n",
    "            # except ValueError:\n",
    "            #     print('We could not complete this file, there is something wrong with the shape of the inputs''')\n",
    "            #     contn = False\n",
    "            #     break\n",
    "                \n",
    "        if contn:\n",
    "            csv_dict = {}\n",
    "            #Experiment_name\n",
    "            # Remove 'E', 'X', and '_RZSM' from the string\n",
    "            result_string = experiment_name_out.replace('E', '').replace('X', '').replace('_RZSM', '')\n",
    "        \n",
    "            csv_dict['Experiment'] = int(result_string)\n",
    "            for i in list(out_dict.keys()):\n",
    "                csv_dict[i] = out_dict[i]\n",
    "                \n",
    "            #Write to csv file for later processing\n",
    "            with open(save_csv_path, 'w') as csvfile:\n",
    "                writer = csv.DictWriter(csvfile, fieldnames=list(csv_dict.keys()))\n",
    "                writer.writeheader()\n",
    "                writer.writerows([csv_dict])\n",
    "    \n",
    "        # create_plot_permutation(setup_plot_permutation(lead,out_dict,RZSM_or_Tmax_or_both),lead,experiment_name_out,save_permutation_figures,max_RZSM_value,max_tmax_value,RZSM_or_Tmax_or_both)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "708f344b-eb1b-471b-ab59-d863000b9f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    #Testing the input layer for issues\n",
    "#         for experiment in range(0,13):\n",
    "#             print(f'Loading EX{experiment}')\n",
    "#             model = load_model(f'checkpoints/Wk_{lead}/Wk{lead}_EX{experiment}',compile=False) #don't need the custom loss function for predictions\n",
    "\n",
    "#             summary_str = None\n",
    "#             with StringIO() as buffer, redirect_stdout(buffer):\n",
    "#                 model.summary()\n",
    "#                 summary_str = buffer.getvalue()\n",
    "\n",
    "#             # Print the head of the summary\n",
    "#             head_lines = 5  # Adjust the number of lines you want to print\n",
    "#             print(\"\\n\".join(summary_str.splitlines()[:head_lines]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64e3f14a-29d4-4d4d-8ced-28b687a19b00",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load data, setup experiments to permutate\n",
    "\n",
    "all_exps = [EX0,EX1,EX2,EX3,EX4,EX5,EX6,EX7,EX8,EX9,EX10,EX11,EX12,EX13,EX14,EX15,EX16,EX17,EX18,EX19,EX20,EX21,EX22,EX23,EX24,EX25,EX27,EX28]\n",
    "obs_final_train,obs_final_validation,obs_final_testing = verifications.open_obs_for_verification(region_name, [6,13,20,27],train_start, train_end, val_start, val_end, test_start, test_end)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "850c593e-4b4c-458c-af78-96715b4ed65c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sub_exps = [EX13,EX14,EX15,EX16,EX17,EX18,EX19,EX20,EX22,EX23,EX24,EX25,EX27,EX28]\n",
    "\n",
    "redo_2thru_4 = [EX1,EX2,EX3,EX4,EX5,EX6,EX7,EX8,EX9,EX10,EX11,]\n",
    "sub_exps = [EX29]\n",
    "for lead in [1,2,3,4]:\n",
    "    day_num = (lead*7)-1\n",
    "    train = obs_final_train.sel(L=day_num)\n",
    "    val = obs_final_validation.sel(L=day_num)\n",
    "    test = obs_final_testing.sel(L=day_num)\n",
    "    # for experiment in all_exps:\n",
    "    for experiment in sub_exps:\n",
    "        permutation_test_save_csv(lead,experiment,train, val, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fea826c-e4a5-4ae5-b3d7-0494913df970",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def permutation_test_by_lead_by_experiment(lead, test_year, experiment_number):\n",
    "#     #test \n",
    "#     # lead = 1\n",
    "#     # test_year=2019\n",
    "    \n",
    "#     day_num = (lead*7) -1\n",
    "\n",
    "#     try:\n",
    "#         with open(file_rmse_save, \"rb\") as f:\n",
    "#             rmse_output = pickle.load(f)\n",
    "    \n",
    "#         with open(file_mae_save, \"rb\") as f:\n",
    "#             mae_output = pickle.load(f)    \n",
    "#     except FileNotFoundError:\n",
    "#         rmse_output = {}\n",
    "#         rmse_output['OBS'] = {}\n",
    "#         rmse_output['HYB'] = {}\n",
    "    \n",
    "#         mae_output = {}\n",
    "#         mae_output['OBS'] = {}\n",
    "#         mae_output['HYB'] = {}\n",
    "\n",
    "    \n",
    "#     leads = [6,13,20,27,34]\n",
    "\n",
    "#     obs_final_train,obs_final_validation,obs_final_testing,EX_list = return_data_and_experiment_numbers(region_name, leads,train_start, train_end, val_start, val_end, test_start, test_end,day_num)\n",
    "\n",
    "#     obs_final_testing_arr = obs_final_testing[putils.xarray_varname(obs_final_testing)].to_numpy()\n",
    "#     '''These are the actual experiment names below'''\n",
    "#     BC,OBS,HYB = verifications.return_experiment_colors_and_names()\n",
    "\n",
    "\n",
    "#     '''Loop through each model checkpoint'''\n",
    "#     checkpt_dir = f'checkpoints/{region_name}/Wk{lead}'\n",
    "#     file_list = sorted(glob(f'{checkpt_dir}/*{experiment_number}_regular*'))\n",
    "  \n",
    "    \n",
    "#     if test_year == 2019:\n",
    "#         file_list = [i for i in file_list if '2012' not in i]\n",
    "#     else:\n",
    "#         file_list = [i for i in file_list if str(pd.to_datetime(test_end).year) in i]\n",
    "\n",
    "#     '''Experiment saved inputs'''\n",
    "#     exps = sorted(glob(f'Data/model_npy_inputs/{region_name}/Wk{lead}_EX_input_data/*testing*'))\n",
    "#     exps = [i for i in exps if 'XGBOOST' not in i]\n",
    "#     exps = [i for i in exps if 'mean' not in i]\n",
    "\n",
    "#     print(f'Working on file list {file_list}')\n",
    "\n",
    "#     #For masking\n",
    "#     RZSM_train_obs, RZSM_validation_obs = pred.return_masking_objects_for_RZSM(input_directory,final_testing_year)\n",
    "#     mask_zero = RZSM_validation_obs.squeeze()\n",
    "    \n",
    "#     for file in file_list:\n",
    "#         print(f'Working on file experiment {file}')\n",
    "#         try:\n",
    "#             testing_input,ex_num = return_the_experiment_input(exps,file,lead)\n",
    "#             channel_list = f.load_channel_list_permutation(ex_num, lead)\n",
    "#             dont_continue=False\n",
    "            \n",
    "#         except IndexError:\n",
    "#             dont_continue = True\n",
    "\n",
    "#         if dont_continue:\n",
    "#             pass\n",
    "#         else:\n",
    "#             if len(channel_list) == testing_input.shape[-1]:\n",
    "#                 model = load_model(file,compile=False) \n",
    "#                 model_name = file.split('/')[-1].split('_testing')[0]\n",
    "                \n",
    "#                 #These will contain the average MAE and RMSE across CONUS to plot\n",
    "#                 save_for_plot_mae = {}\n",
    "#                 save_for_plot_rmse = {}\n",
    "                \n",
    "#                 for idx,channel in enumerate(channel_list):\n",
    "#                     '''Now add to the dictionary'''\n",
    "#                     if ex_num in OBS:\n",
    "#                         try:\n",
    "#                             rmse_output['OBS'][channel]['Value'] = rmse_output['OBS'][channel]['Value'] + RZSM_rmse\n",
    "#                             rmse_output['OBS'][channel]['Num_experiments'] = rmse_output['OBS'][channel]['Num_experiments'] + 1\n",
    "#                         except KeyError:\n",
    "#                             rmse_output['OBS'][channel] = {'Num_experiments':1, 'Value':RZSM_rmse}\n",
    "#                     elif ex_num in HYB:\n",
    "                        \n",
    "                \n",
    "#                     # idx,channel = 6, 'pwat_obs_lag-1'\n",
    "#                     # idx, channel = 0, 'RZSM_obs_lag-1'\n",
    "                    \n",
    "#                     new_input_with_noise,reforecast_nan,var_noise_min,var_noise_max,var_ = f.load_min_max_files_and_rescale_data(testing_input,channel,idx,file,region_name,day_num,test_year,lead)\n",
    "\n",
    "#                     try:\n",
    "#                         prediction_ = np.array(model.predict(new_input_with_noise))\n",
    "#                         prediction_.shape\n",
    "                        \n",
    "#                         '''Just choose the very last prediction made'''\n",
    "#                         prediction_ = prediction_[-1,:,:,:,0]\n",
    "        \n",
    "#                         yhat = verifications.reverse_min_max_scaling_for_permutations(prediction_,region_name,day_num,'GEFSv12',test_year,'soilw_bgrnd')\n",
    "        \n",
    "#                         yhat = np.where(np.isnan(reforecast_nan),np.nan,yhat)\n",
    "#                         yhat = np.where(mask_zero == 0, np.nan, yhat)\n",
    "#                         # yhat = np.where(np.isnan(reforecast_nan),np.nan,yhat.squeeze())\n",
    "#                         yhat = np.reshape(yhat,(yhat.shape[0]//11,11,yhat.shape[1],yhat.shape[2]))\n",
    "            \n",
    "#                         RZSM_mae =np.nanmean(np.abs(obs_final_testing_arr -  yhat),axis=(0,1))\n",
    "            \n",
    "#                         RZSM_rmse = np.nanmean((obs_final_testing_arr -  yhat)**2,axis=(0,1))\n",
    "    \n",
    "#                         save_for_plot_rmse[channel] = np.nanmean(RZSM_rmse)\n",
    "#                         save_for_plot_mae[channel] = np.nanmean(RZSM_mae)\n",
    "                        \n",
    "#                         '''Now add to the dictionary'''\n",
    "#                         if ex_num in OBS:\n",
    "#                             try:\n",
    "#                                 rmse_output['OBS'][channel]['Value'] = rmse_output['OBS'][channel]['Value'] + RZSM_rmse\n",
    "#                                 rmse_output['OBS'][channel]['Num_experiments'] = rmse_output['OBS'][channel]['Num_experiments'] + 1\n",
    "#                             except KeyError:\n",
    "#                                 rmse_output['OBS'][channel] = {'Num_experiments':1, 'Value':RZSM_rmse}\n",
    "#                         elif ex_num in HYB:\n",
    "#                             try:\n",
    "#                                 rmse_output['HYB'][channel]['Value'] = rmse_output['HYB'][channel]['Value'] + RZSM_rmse\n",
    "#                                 rmse_output['HYB'][channel]['Num_experiments'] = rmse_output['HYB'][channel]['Num_experiments'] + 1\n",
    "#                             except KeyError:\n",
    "#                                 rmse_output['HYB'][channel] = {'Num_experiments':1, 'Value':RZSM_rmse}\n",
    "    \n",
    "    \n",
    "#                         '''Now add to the dictionary'''\n",
    "#                         if ex_num in HYB:\n",
    "#                             try:\n",
    "#                                 mae_output['OBS'][channel]['Value'] = mae_output['OBS'][channel]['Value'] + RZSM_mae\n",
    "#                                 mae_output['OBS'][channel]['Num_experiments'] = mae_output['OBS'][channel]['Num_experiments'] + 1\n",
    "#                             except KeyError:\n",
    "#                                 mae_output['OBS'][channel] = {'Num_experiments':1, 'Value':RZSM_mae}\n",
    "#                         elif ex_num in HYB:\n",
    "#                             try:\n",
    "#                                 mae_output['HYB'][channel]['Value'] = mae_output['HYB'][channel]['Value'] + RZSM_mae\n",
    "#                                 mae_output['HYB'][channel]['Num_experiments'] = mae_output['HYB'][channel]['Num_experiments'] + 1\n",
    "#                             except KeyError:\n",
    "#                                 mae_output['HYB'][channel] = {'Num_experiments':1, 'Value':RZSM_mae}\n",
    "\n",
    "#                         continue_ = True\n",
    "                    \n",
    "            \n",
    "                    \n",
    "#                     except ValueError:\n",
    "#                         continue_ = False\n",
    "#                         pass\n",
    "                        \n",
    "#                 if continue_:\n",
    "#                     plot_barplot_mae_rmse(save_for_plot_mae, save_for_plot_rmse, lead, model_name)\n",
    "                    \n",
    "\n",
    "#     return(f'Completed week {lead}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b03ba3d-c7da-44b0-88b6-2640278ec02c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d2b7cab-012c-465f-b085-34ae01d66483",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85410672-95f4-4afd-99dc-4f2a76c6b22e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d57117ba-9586-4107-83a6-6b4264b6984f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_exps= [EX1,EX2,EX3,EX4,EX5,EX6,EX7,EX8,EX9,EX10,EX11,EX14,EX15,EX18,EX19,EX20,EX22,EX23,EX24,EX25,EX27]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ba81cff-5eba-4b50-9ddc-f40d840d8a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_exps= [EX3,EX4,EX11,EX16,EX17,EX18,EX19,EX20,EX21]\n",
    "all_exps = [EX11,EX16]\n",
    "for experiment in all_exps:\n",
    "    run_model_and_prediction(experiment)\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7407add8-5e04-4dff-984e-885a6f515760",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_exps= [EX0,EX1,EX2,EX3,EX4,EX5,EX6,EX7,EX8,EX9,EX10,EX11,EX13,EX14,EX15,EX16,EX17,EX18,EX19,EX20,EX21,EX22,EX23,EX24,EX25,EX27,EX28]\n",
    "all_exps= [EX3,EX4,EX11,EX16,EX17,EX18,EX19,EX20,EX21]\n",
    "\n",
    "# for lead in [1,2,3,4]:\n",
    "#     permutation_test_by_lead(lead=lead, test_year=2019) \n",
    "\n",
    "good= [EX0,EX1,EX2,EX5,EX6,EX7,EX8,EX9,EX10,EX13,EX14,EX15,EX22,EX23,EX24,EX25,EX27,EX28]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4edd1f6-e526-40d2-9780-354cd6571774",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48b7b5c5-57e9-4212-af76-14fe603dba4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_week4 = [EX11,EX16,EX17,EX21,EX28]\n",
    "\n",
    "for experiment in good:\n",
    "    run_model_and_prediction(experiment)\n",
    "\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "110a899c-af06-4aab-af94-3015304a2f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_exps= [EX1]\n",
    "\n",
    "for experiment in all_exps:\n",
    "    run_model_and_prediction(experiment)\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "490e59a0-196a-4d88-a0ce-5e011b656d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_exps= [EX0,EX1,EX2,EX3,EX4,EX5,EX6,EX7,EX8,EX9,EX10,EX11,EX13,EX14,EX15,EX16,EX17,EX18,EX19,EX20,EX21,EX22,EX23,EX24,EX25,EX27,EX28]\n",
    "\n",
    "'''We are not testing EX12 or EX26'''\n",
    "for idx,experiment in enumerate(all_exps):\n",
    "    run_model_and_prediction(experiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa6dcbd7-01be-4793-98cc-0800a1e7270b",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Run the single prediction tests'''\n",
    "        \n",
    "%load_ext autoreload \n",
    "%autoreload 2\n",
    "%reload_ext autoreload\n",
    "    \n",
    "testing_scenarios = ['dense', 'regular', 'transformer', 'super_pixel', 'attention', 'denseLarge', 'basic']\n",
    "\n",
    "for testing_scenario in testing_scenarios:\n",
    "    #removed EX12 and EX26\n",
    "    all_exps= [EX0,EX1,EX2,EX3,EX4,EX5,EX6,EX7,EX8,EX9,EX10,EX11,EX13,EX14,EX15,EX16,EX17,EX18,EX19,EX20,EX21,EX22,EX23,EX24,EX25,EX27,EX28]\n",
    "\n",
    "    \n",
    "    global save_loss_name, loss_fn\n",
    "    \n",
    "    if testing_scenario == 'dense':\n",
    "        import modelRzsmDenseRelu as UNETRzsm\n",
    "        \n",
    "        save_loss_name = 'denseLoss'\n",
    "        loss_fn = losses.crps2d_tf_dense_test2\n",
    "        \n",
    "    elif testing_scenario == 'regular':\n",
    "        import modelRzsmReluExtraConv as UNETRzsm\n",
    "    \n",
    "        save_loss_name = 'regular'\n",
    "        loss_fn = losses.crps2d_tf\n",
    "    \n",
    "    elif testing_scenario == 'transformer':\n",
    "        import modelRzsmReluTransformer as UNETRzsm\n",
    "        \n",
    "        save_loss_name = 'transformer'\n",
    "        loss_fn = losses.crps2d_tf_dense_test2\n",
    "    \n",
    "    elif testing_scenario == 'super_pixel':\n",
    "        import modelRzsmReluPixelSuper as UNETRzsm\n",
    "        \n",
    "        save_loss_name = 'supPixel'\n",
    "        loss_fn = losses.crps2d_tf_dense_test2\n",
    "    \n",
    "    elif testing_scenario == 'attention':\n",
    "        import modelRzsmReluAttention as UNETRzsm\n",
    "        \n",
    "        save_loss_name = 'attention'\n",
    "        loss_fn = losses.crps2d_tf_dense_test2\n",
    "        \n",
    "    elif testing_scenario == 'None':\n",
    "        import modelRzsm2DdropoutRelu as UNETRzsm\n",
    "        \n",
    "        save_loss_name = ''\n",
    "        loss_fn = losses.crps2d_tf\n",
    "    \n",
    "    elif testing_scenario == 'denseLarge':\n",
    "        import modelRzsmReluExtraConv as UNETRzsm\n",
    "    \n",
    "        save_loss_name = 'denseLarge'\n",
    "        loss_fn = losses.crps2d_tf_dense_test2\n",
    "        \n",
    "    elif testing_scenario == 'basic':\n",
    "        import basicUNET as UNETRzsm\n",
    "    \n",
    "        save_loss_name = testing_scenario\n",
    "        loss_fn = losses.crps2d_tf\n",
    "\n",
    "    for idx,experiment in enumerate(all_exps):\n",
    "        run_model_and_prediction(experiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2768ac13-e1ff-4ab5-95d6-08081f4bac2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_exps= [EX0,EX1,EX2,EX3,EX4,EX5,EX6,EX7,EX8,EX9,EX10,EX11,EX12,EX13,EX14,EX15,EX16,EX17,EX18,EX19,EX20,EX21,EX22,EX23,EX24,EX25,EX27,EX28]\n",
    "for idx,experiment in enumerate(all_exps):\n",
    "    run_model_and_prediction(experiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c83bd3e-d864-4824-931b-bd029194d083",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx,experiment in enumerate(all_exps):\n",
    "    run_model_and_prediction(experiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a51ebf6b-3ff0-4686-90f5-80dbd8fc0a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for experiment_ in [EX14,EX15,EX16,EX17,EX18,EX19,EX20,EX21,EX22,EX23,EX24,EX25,EX27,EX28]:\n",
    "#     global testing_scenario\n",
    "#     testing_scenario = 'None'\n",
    "#     run_model_and_prediction(experiment_)\n",
    "#     for test in ['dense', 'regular', 'transformer', 'super_pixel', 'attention', 'denseLarge', 'basic', None]:\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8bbea09-b7b1-422e-9ca2-708a8255c53c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run_model_and_prediction(EX27)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53d20619-f47f-4545-a680-f7e1b68cec51",
   "metadata": {},
   "source": [
    "# After all the experiments are completed, now do a permutation test\n",
    "## Save the results for each type (observation or hybrid driven) only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "694c9281-da90-4cc5-8f23-8f650ab0675e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for lead in [1,2]:\n",
    "    permutation_test_by_lead(lead=lead, test_year=2019)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65f08ca1-b5df-4fb5-9cfd-a27dac6da755",
   "metadata": {},
   "outputs": [],
   "source": [
    "for lead in [1]:\n",
    "    permutation_test_by_lead_by_experiment(lead=lead, test_year=2019, experiment_number = 'EX1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6801867-0c6f-4143-9c81-96c00f3b6a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment=EX29\n",
    "#for testing\n",
    "lead,lead_week = 3,3\n",
    "\n",
    "experiment['region_name']\n",
    "lead = lead_week\n",
    "num_lags_obs_RZSM=experiment['num_lags_obs_RZSM']\n",
    "include_lags_obs_pwat_spfh_tmax=experiment['include_lags_obs_pwat_spfh_tmax']\n",
    "include_reforecast_or_not=experiment['include_reforecast_or_not']\n",
    "addtl_experiment = experiment['addtl_experiment']\n",
    "experiment_test = experiment['experiment_test']\n",
    "\n",
    "epochs = 150\n",
    "batch_size = 66\n",
    "initial_learning_rate=0.0001\n",
    "beta_1 = 0.9\n",
    "shuffle=False\n",
    "patience=10\n",
    "kernel_norm = None\n",
    "deep_supervision = True\n",
    "number_of_UNET_backbone_max_pool=4\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91874317-21a3-4492-9398-ac8fa2616bfe",
   "metadata": {},
   "source": [
    "# def return_fully_autoregressive_EX26(lead):\n",
    "\n",
    "    #We can manually select the best models and create a week N estimate based on them (this implies that all the information from the observations is contained in the first \n",
    "    #Set of leads\n",
    "\n",
    "    best_models = []\n",
    "    \n",
    "    if lead == 2:\n",
    "        previous_model = ['EX10_RZSM','EX20_RZSM']\n",
    "    elif lead == 3:\n",
    "        previous_model = ['EX10_RZSM','EX20_RZSM','EX20_RZSM']\n",
    "    elif lead == 4:\n",
    "        previous_model = ['EX10_RZSM','EX20_RZSM','EX20_RZSM','EX20_RZSM']\n",
    "    elif lead == 5:\n",
    "        previous_model = ['EX10_RZSM','EX20_RZSM','EX20_RZSM','EX20_RZSM','EX20_RZSM']\n",
    "\n",
    "    return(previous_model)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tf212gpu_new]",
   "language": "python",
   "name": "conda-env-tf212gpu_new-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
