{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b51fd071-9238-4e03-982e-68dafa29e04f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-13 10:17:23.818520: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-13 10:17:28.256474: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-03-13 10:17:58.269396: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/glade/work/klesinger/conda-envs/tf212gpu/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload \n",
    "%autoreload 2\n",
    "%reload_ext autoreload\n",
    "\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "import datetime as dt\n",
    "from PIL import Image\n",
    "import sys\n",
    "import functions as f\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from keras.models import Model\n",
    "from keras import backend as K\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from IPython.display import Image \n",
    "from tensorflow.python.data.ops import dataset_ops\n",
    "import dask\n",
    "from keras.models import load_model\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from io import StringIO\n",
    "from keras.layers import Input\n",
    "import keras as k\n",
    "from contextlib import redirect_stdout\n",
    "from PIL import Image\n",
    "import matplotlib.gridspec as gridspec\n",
    "import channelExperiment as CE\n",
    "import loadDataWeek0 as loadData\n",
    "import bottleneck as bn\n",
    "from tensorflow.keras import mixed_precision\n",
    "import csv\n",
    "import addPredictors as pred\n",
    "import loadValues as lv\n",
    "import masks\n",
    "import denseValue\n",
    "import xgboost as xgb\n",
    "import json\n",
    "from hyperopt import hp, fmin, tpe, STATUS_OK, Trials\n",
    "from concurrent.futures import ProcessPoolExecutor, as_completed\n",
    "import bottleneck as bn\n",
    "import concurrent.futures\n",
    "\n",
    "global region_name\n",
    "region_name = 'CONUS' #['australia','CONUS']\n",
    "\n",
    "\n",
    "if region_name == 'CONUS':\n",
    "    source = 'Data'\n",
    "elif region_name == 'australia':\n",
    "    source = 'Data_australia'\n",
    "\n",
    "\n",
    "global RZSM_or_Tmax_or_both\n",
    "RZSM_or_Tmax_or_both = 'RZSM' # for getting the predictor from either RZSM and Tmax ('both') or only RZSM ('RZSM')\n",
    "\n",
    "\n",
    "global num_cores\n",
    "#Select the number of cpu cores selected at start\n",
    "num_cores = 10\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2da76f7b-0e9a-43f3-ae72-3c4e7f0f2a4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import multiprocessing\n",
    "\n",
    "# # Get the number of available CPU cores\n",
    "# num_cores = multiprocessing.cpu_count()\n",
    "\n",
    "# print(f\"Number of available CPU cores: {num_cores}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4638590c-749d-4c6c-85c4-3af63200d242",
   "metadata": {},
   "source": [
    "# Choose different loss and architecture configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c4deceee-9448-4e7a-8d21-e621f522852e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # #Load model and check summary\n",
    "# model = load_model(f'checkpoints/Wk_1/Wk1_EX5',compile=False) #don't need the custom loss function for predictions\n",
    "# model.summary() \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afaa26b2-3d09-43c4-90c2-b3adf94d4126",
   "metadata": {
    "tags": []
   },
   "source": [
    "# This script will load data based on specific lead times that we want to experiment with and what Experiments we choose to run"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fe39e5b-a435-4b47-8272-b0fc8c20c1c8",
   "metadata": {},
   "source": [
    "# Week 1 (lead index 6 of the forecast)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cf62daf-7f99-475f-bc39-5eefe7c31436",
   "metadata": {
    "tags": []
   },
   "source": [
    "| Ex. Number/Name | Obs. RZSM Inputs | Obs. Other Inputs                    | UNET predicted Inputs (N>=2)     |Reforecast Inputs| Prediction Lead Week/Variables | Activation function | Loss function | Batch size |\n",
    "| ----------------| -----------------| ------------------------------------ | -------------------      |--------          | -------------------| ---------------------| ------------------------| ------------|\n",
    "| 0 - EX0         | None             | None                                 | None                     | RZSM, Wk 1-N| Wk N     -  RZSM |              Relu             | CRPS experimental| 66\n",
    "| 1 - EX1         | Wk. lags 1-3    | pwat,spfh,tmax,z200,diff_temp lags 1-3 | RZSM Wk 1-N |        None |  Wk N     -  RZSM |             Relu             | CRPS experimental | 66\n",
    "| 2 - EX2         | Wk. lags 1-6   | pwat,spfh,tmax,z200,diff_temp lags 1-3  | RZSM Wk 1-N          |  None |  Wk N     -  RZSM |       Relu             | CRPS experimental| 66\n",
    "| 3 - EX3         | Wk. lags 1-9    | pwat,spfh,tmax,z200,diff_temp lags 1-3 | RZSM Wk 1-N         |  None |  Wk N     -  RZSM |       Relu             | CRPS experimental| 66\n",
    "| 4 - EX4         | Wk. lags 1-12    | pwat,spfh,tmax,z200,diff_temp lags 1-3| RZSM Wk 1-N         |  None |  Wk N     -  RZSM |      Relu             | CRPS experimental| 66\n",
    "| 5 - EX5         | Wk. lags 1-3   | None                                   | None                   | RZSM, week N | Wk N     -  RZSM  |         Relu             | CRPS experimental| 66\n",
    "| 6 - EX6         | Wk. lags 1-6   | None                                     | None                   |RZSM, week N  | Wk N     -  RZSM  |        Relu             | CRPS experimental| 66\n",
    "| 7 - EX7         | Wk. lags 1-9    | None                                | None                   |RZSM, week N  | Wk N     -  RZSM  |         Relu             | CRPS experimental |66\n",
    "| 8 - EX8         | Wk. lags 1-12    | None                                  | None                   |RZSM, week N  | Wk N     -  RZSM |         Relu             | CRPS experimental | 66\n",
    "| 9 - EX9         | Wk. lags 1-3    |pwat,spfh,tmax,z200,diff_temp lags 1-3  | RZSM Wk 1-N                  |RZSM  week N  | Wk N     -  RZSM  |         Relu             | CRPS experimental| 66\n",
    "| 10 - EX10       | Wk. lags 1-6    |pwat,spfh,tmax,z200,diff_temp  lags 1-3 | RZSM Wk 1-N                  |RZSM  week N  |Wk N     -  RZSM   |         Relu             | CRPS experimental| 66\n",
    "| 11 - EX11       | Wk. lags 1-9    |pwat,spfh,tmax,z200,diff_temp  lags 1-3 | RZSM Wk 1-N                  |RZSM  week N  | Wk N     -  RZSM  |         Relu             | CRPS experimental| 66\n",
    "| 12 - EX12       | Wk. lags 1-12   |pwat,spfh,tmax,z200,diff_temp lags 1-3  | RZSM Wk 1-N                  |RZSM  week N  | Wk N     -  RZSM  |         Relu             | CRPS experimental| 66\n",
    "| 13 - EX13       | None             | None                                 | None                     | RZSM week N| Wk N     -  RZSM |              Relu             | CRPS experimental| 66\n",
    "| 14 - EX14         | Wk. lags 1-3    | pwat,spfh,tmax,z200,diff_temp lags 1-3 | None |        None |  Wk N     -  RZSM |             Relu             | CRPS experimental | 66\n",
    "| 15 - EX15         | Wk. lags 1-6   | pwat,spfh,tmax,z200,diff_temp lags 1-3  | None             |  None |  Wk N     -  RZSM |       Relu             | CRPS experimental| 66\n",
    "| 16 - EX16         | Wk. lags 1-9    | pwat,spfh,tmax,z200,diff_temp lags 1-3 | None            |  None|  Wk N     -  RZSM |       Relu             | CRPS experimental| 66\n",
    "| 17 - EX17        | Wk. lags 1-12    | pwat,spfh,tmax,z200,diff_temp lags 1-3| None            |  None|  Wk N     -  RZSM |      Relu             | CRPS experimental| 66\n",
    "| 18 - EX18         | Wk. lags 1-3   | None                                   | RZSM Wk 1-N                 | RZSM, week N | Wk N     -  RZSM  |         Relu             | CRPS experimental| 66\n",
    "| 19 - EX19         | Wk. lags 1-6   | None                                     | RZSM Wk 1-N                  |RZSM, week N  | Wk N     -  RZSM  |        Relu             | CRPS experimental| 66\n",
    "| 20 - EX20         | Wk. lags 1-9    | None                                | RZSM Wk 1-N                  |RZSM, week N  | Wk N     -  RZSM  |         Relu             | CRPS experimental |66\n",
    "| 21 - EX21         | Wk. lags 1-12    | None                                  | RZSM Wk 1-N                   |RZSM, week N  | Wk N     -  RZSM |         Relu             | CRPS experimental | 66\n",
    "| 22 - EX22         | Wk. lags 1-3   | None                                   | None                   | None | Wk N     -  RZSM  |         Relu             | CRPS experimental| 66\n",
    "| 23 - EX23         | Wk. lags 1-6   | None                                     | None                   |None  | Wk N     -  RZSM  |        Relu             | CRPS experimental| 66\n",
    "| 24 - EX24         | Wk. lags 1-9    | None                                | None                   |None  | Wk N     -  RZSM  |         Relu             | CRPS experimental |66\n",
    "| 25 - EX25         | Wk. lags 1-12    | None                                  | None                   |None  | Wk N     -  RZSM |         Relu             | CRPS experimental | 66\n",
    "| 26 - EX26         | None    | None                                  | None                   |Wk 1-N (choose best models)  | Wk N     -  RZSM |         Relu             | CRPS experimental | 66\n",
    "| 27 - EX27         | Wk. lags 1-3    |pwat,spfh,tmax,z200,diff_temp lags 1-3  |  None                   |Wk1 RZSM,tmax, diff_temp, z200, pwat, spfh  | Wk N     -  RZSM  |         Relu             | CRPS experimental| 66 (like EX9)\n",
    "| 28 - EX28         | Wk. lags 1-6    |pwat,spfh,tmax,z200,diff_temp lags 1-3  |  None                   |Wk1 RZSM,tmax, diff_temp, z200, pwat, spfh  | Wk N     -  RZSM  |         Relu             | CRPS experimental| 66 (like EX10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f3bc1a4-0171-4e83-9601-76c524bbf735",
   "metadata": {
    "tags": []
   },
   "source": [
    "# EX 1-4 - Testing if the prediction of previous week adds value (but don't include the current week that is trying to be predicted). Observation driven but with a prediction.\n",
    "# EX 14-17 - Testing if the prediction of previous week adds value (but don't include the current week that is trying to be predicted). Purely observation driven.\n",
    "# EX 5-8 - Testing if adding other observations (pwat, spfh, etc) has an increase or decrease in skill.\n",
    "# EX 18-21 - Seeing if adding the previous week gains additional skill\n",
    "# EX 22-25 - Purely observation driven. Only soil moisture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1674ec3d-e9f4-415d-84b7-cfcd0a50e0dc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "input_directory = f'Data/model_npy_inputs/{region_name}/Model_input_data' #For inputs into the model\n",
    "verification_directory = f'Data/model_npy_inputs/{region_name}/Verification_data' #For observation verification\n",
    "start_of_forecast_init = '2000-01-05'\n",
    "end_of_forecast_init = '2019-12-25'\n",
    "\n",
    "global training_size_shape\n",
    "training_size_shape = np.array((9185,48,96))\n",
    "\n",
    "global validation_testing_size_shape\n",
    "validation_testing_size_shape = np.array((1144,48,96))\n",
    "\n",
    "'''This decides how many lag weeks we have for data such as pwat, z200, tmax, etc'''\n",
    "global observation_lag_list_not_RZSM\n",
    "#This is for observations pwat, z200, spfh, tmax, diff_temp variables used as predictors\n",
    "#These are the day lags which were already computed as the 7-day rolling mean\n",
    "\n",
    "observation_lag_list_not_RZSM = [-1,-7,-14] \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5e3530f0-bd36-49f6-95c7-809be77583f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_all_data_EX0(lead, num_lags_obs_RZSM, include_lags_obs_pwat_spfh_tmax, include_reforecast_or_not, observation_lag_list_not_RZSM, lag_integer_list, input_directory,training_size_shape,validation_testing_size_shape,RZSM_or_Tmax_or_both,addtl_experiment,experiment_test):\n",
    "\n",
    "    soil_var = 'soilw_bgrnd' #This is the observation verification variable name\n",
    "    \n",
    "    channel_list = []\n",
    "\n",
    "    if addtl_experiment == False:\n",
    "        assert lead >=1, 'Lead must be >=1, do not look at Week 0'\n",
    "        \n",
    "        lead_list = np.arange(1,lead+1)\n",
    "\n",
    "        print(f'Only adding Reforecast data as input for leads {list(lead_list)}.')\n",
    "\n",
    "        training_input = np.empty(shape = (training_size_shape[0],training_size_shape[1],training_size_shape[2],lead)) #We are adding both RZSM and/or Tmax (so use * 2)\n",
    "        validation_input = np.empty(shape = (validation_testing_size_shape[0],validation_testing_size_shape[1],validation_testing_size_shape[2],lead))\n",
    "        testing_input = np.empty(shape = (validation_testing_size_shape[0],validation_testing_size_shape[1],validation_testing_size_shape[2],lead))\n",
    "\n",
    "        #Add reforecast data\n",
    "        for idx,lead in enumerate(lead_list):\n",
    "            channel_list.append(f'RZSM_ref_lead{lead}')\n",
    "\n",
    "            training_input, validation_input, testing_input = pred.add_reforecast_by_lag(training_input, validation_input, testing_input, lead, input_directory,soil_var, idx)\n",
    "\n",
    "        print(f'Index idx value is {idx}. Done adding RZSM obs.')    \n",
    "\n",
    "    \n",
    "    elif addtl_experiment == True:\n",
    "        print(f'Only adding Reforecast data as input for lead {lead}.')\n",
    "\n",
    "        lead_add = 1 #We are only adding the current week of reforecast\n",
    "        lead_list = [lead]\n",
    "\n",
    "        training_input = np.empty(shape = (training_size_shape[0],training_size_shape[1],training_size_shape[2],lead_add)) #We are adding both RZSM and Tmax (so use * 2)\n",
    "        validation_input = np.empty(shape = (validation_testing_size_shape[0],validation_testing_size_shape[1],validation_testing_size_shape[2],lead_add))\n",
    "        testing_input = np.empty(shape = (validation_testing_size_shape[0],validation_testing_size_shape[1],validation_testing_size_shape[2],lead_add))\n",
    "\n",
    "        channel_list.append(f'RZSM_ref_lead{lead}')\n",
    "\n",
    "        idx = 0\n",
    "        training_input, validation_input, testing_input = pred.add_reforecast_by_lag(training_input, validation_input, testing_input, lead, input_directory,soil_var, idx)\n",
    "\n",
    "    return(training_input, validation_input, testing_input, channel_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "734ec27f-2cfe-4c54-8735-c54b34588e05",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# def load_all_data_EX1_EX2_EX3_EX4_after_week_0(lead, num_lags_obs_RZSM, include_lags_obs_pwat_spfh_tmax, include_reforecast_or_not, \n",
    "#                                            observation_lag_list_not_RZSM, lag_integer_list, input_directory,training_size_shape,\n",
    "#                                            validation_testing_size_shape,experiment_name,RZSM_or_Tmax_or_both,addtl_experiment,experiment_test, experiment_name_out):\n",
    "#     channel_list = []\n",
    "    \n",
    "#     #Reforecast predictors\n",
    "#     var_list = ['pwat_eatm', 'spfh_2m', 'tmax_2m', 'diff_temp_2m', 'hgt_pres']\n",
    "\n",
    "#     assert lead >=1, 'Lead must be >=1, we are not testing week 0 anymore'\n",
    "\n",
    "#     if addtl_experiment == False:\n",
    "#         #Get the number of extra channels to add from previous weeks predictions\n",
    "#         if RZSM_or_Tmax_or_both == 'both':\n",
    "#             add_channels = lead * 2\n",
    "#         else:\n",
    "#             #Also add the number of channels according to the lead. If lead == 1, then only add lead 1 current week. If lead == 2, add one channel for week 2 and one channel for the prediction from Week 1\n",
    "#             if lead > 1:\n",
    "#                 add_channels = lead - 1\n",
    "#             else:\n",
    "#                 add_channels = 0\n",
    "\n",
    "\n",
    "\n",
    "#         training_input = np.empty(shape = (training_size_shape[0],training_size_shape[1],training_size_shape[2],len(lag_integer_list)+len(var_list)*3+add_channels))\n",
    "#         validation_input = np.empty(shape = (validation_testing_size_shape[0],validation_testing_size_shape[1],validation_testing_size_shape[2],len(lag_integer_list)+len(var_list)*3+add_channels))\n",
    "#         testing_input = np.empty(shape = (validation_testing_size_shape[0],validation_testing_size_shape[1],validation_testing_size_shape[2],len(lag_integer_list)+len(var_list)*3+add_channels))\n",
    "\n",
    "#         print(f'Training shape input is {training_input.shape}')\n",
    "\n",
    "#         #Add RZSM observations first\n",
    "#         for idx,lag in enumerate(lag_integer_list):\n",
    "#             channel_list.append(f'RZSM_obs_lag{lag}')\n",
    "#             training_input, validation_input, testing_input = pred.add_obs_RZSM_by_lag(training_input, validation_input, testing_input, lag, input_directory, idx)\n",
    "\n",
    "#         print(f'Index idx value is {idx}. Done adding RZSM obs.')\n",
    "        \n",
    "#         RZSM_train_obs, RZSM_validation_obs = pred.return_masking_objects_for_RZSM(input_directory)\n",
    "\n",
    "        \n",
    "#         for variable in var_list:\n",
    "#             channel_name_output = pred.return_channel_name(variable)\n",
    "#             for lag in observation_lag_list_not_RZSM:\n",
    "#                 channel_list.append(f'{channel_name_output}_obs_lag{lag}')\n",
    "#                 idx+=1\n",
    "#                 #Observations adding\n",
    "#                 training_input, validation_input, testing_input = pred.add_obs_other_observations_by_lag(training_input, validation_input, testing_input, lag, input_directory, variable, idx)\n",
    "     \n",
    "        \n",
    "#             print(f'Index idx value is {idx}. Done adding {variable} obs.')\n",
    "    \n",
    "#         if lead in [0,1]:\n",
    "#             pass\n",
    "#         else:\n",
    "#             #Now we need to load our data from the previous weeks\n",
    "#             for lead_previous in range(1,lead):\n",
    "#                 print(f'Working on previous lead: Week {lead_previous}')\n",
    "#                 # break\n",
    "    \n",
    "#                 pred_dir = f'predictions_XGBOOST/{region_name}/Wk{lead_previous}_training_validation'\n",
    "#                 testing_dir = f'predictions_XGBOOST/{region_name}/Wk{lead_previous}_testing'\n",
    "    \n",
    "#                 os.system(f'mkdir -p {pred_dir}')\n",
    "    \n",
    "#                 training_prediction_name= f'{pred_dir}/Wk{lead_previous}_training_{experiment_name_out}.npy'\n",
    "#                 validation_prediction_name = f'{pred_dir}/Wk{lead_previous}_validation_{experiment_name_out}.npy'\n",
    "#                 testing_prediction_name = f'{testing_dir}/Wk{lead_previous}_testing_{experiment_name_out}.npy'\n",
    "    \n",
    "#                 testing_prediction = np.load(testing_prediction_name)\n",
    "                \n",
    "\n",
    "#                 print(f'Loading data from previous week lead {lead_previous}')\n",
    "#                 training_prediction = np.load(training_prediction_name)\n",
    "#                 validation_prediction =np.load(validation_prediction_name)\n",
    "\n",
    "#                 else:\n",
    "#                     print(f'Creating prediction data from previous week lead {lead_previous}')\n",
    "#                     '''If they don't exist..... load model for previous week'''\n",
    "#                     model = load_model(f'checkpoints/Wk{lead_previous}/Wk{lead_previous}_{experiment_name_out}',compile=False) #don't need the custom loss function for predictions\n",
    "    \n",
    "#                     training_input_previous = np.load(f'Data/model_npy_inputs/{region_name}/Wk{lead_previous}_EX_input_data/{experiment_name_out}_training_input.npy')\n",
    "#                     validation_input_previous = np.load(f'Data/model_npy_inputs/{region_name}/Wk{lead_previous}_EX_input_data/{experiment_name_out}_validation_input.npy')\n",
    "#                     testing_input_previous = np.load(f'Data/model_npy_inputs/{region_name}/Wk{lead_previous}_EX_input_data/{experiment_name_out}_testing_input.npy')\n",
    "    \n",
    "#                     '''Make predictions and save data to load for previous use'''\n",
    "#                     training_prediction = model.predict(training_input_previous) #Just for unit checking\n",
    "#                     np.save(training_prediction_name,training_prediction)\n",
    "    \n",
    "#                     validation_prediction = model.predict(validation_input_previous)\n",
    "#                     np.save(validation_prediction_name,validation_prediction)\n",
    "    \n",
    "#                 ############# ADD BACK TO CREATED ARRAY ###############################\n",
    "#                 '''Now get the best UNET index prediction for RZSM and Tmax. Because the UNET plus plus produces 4 different outputs'''\n",
    "#                 min_RZSM_index,min_tmax_index = f.load_loss_csv_bias_correction(lead_previous,experiment_name_out,RZSM_or_Tmax_or_both,region_name)\n",
    "    \n",
    "#                 if np.array(training_prediction).shape[0] == 8 and RZSM_or_Tmax_or_both == 'both':\n",
    "#                     min_tmax_index = min_tmax_index+4 #Because index values 0-3 are RZSM and 4-7 are Tmax\n",
    "#                 elif np.array(training_prediction).shape[0] == 6 and RZSM_or_Tmax_or_both == 'both':\n",
    "#                     min_tmax_index = min_tmax_index + 3 #Because index values are 0-2 for RZSM and 3-5 for Tmax\n",
    "#                 '''Now split the training and validation data back into RZSM and/or Tmax'''\n",
    "    \n",
    "    \n",
    "#                 train_RZSM = np.array(training_prediction)[min_RZSM_index,:,:,:,:]\n",
    "#                 val_RZSM = np.array(validation_prediction)[min_RZSM_index,:,:,:,:]\n",
    "#                 test_RZSM = np.array(testing_prediction)[min_RZSM_index,:,:,:,:]\n",
    "\n",
    "    \n",
    "#                 '''Make sure we mask RZSM values which aren't on land'''\n",
    "#                 train_RZSM = np.where(RZSM_train_obs==0,0,train_RZSM)\n",
    "#                 val_RZSM = np.where(RZSM_validation_obs==0,0,val_RZSM)\n",
    "#                 test_RZSM = np.where(RZSM_validation_obs==0,0,test_RZSM)\n",
    "    \n",
    "#                 #Now add back to the data\n",
    "#                 '''Now add back to the newly created dataset'''\n",
    "#                 idx+=1\n",
    "#                 channel_list.append(f'RZSM_prediction_lead{lead_previous}')\n",
    "#                 print(f'Adding RZSM training, validation, testing into index {idx}')\n",
    "#                 training_input[:,:,:,idx] = train_RZSM[:,:,:,0]\n",
    "#                 validation_input[:,:,:,idx] = val_RZSM[:,:,:,0]\n",
    "#                 testing_input[:,:,:,idx] = test_RZSM[:,:,:,0]\n",
    "    \n",
    "#             if RZSM_or_Tmax_or_both == 'both':\n",
    "#                 channel_list.append(f'tmax_prediction_lead{lead_previous}')\n",
    "#                 idx+=1\n",
    "#                 print(f'Adding Tmax training, validation, testing into index {idx}')\n",
    "#                 training_input[:,:,:,idx] = train_tmax[:,:,:,0]\n",
    "#                 validation_input[:,:,:,idx] = val_tmax[:,:,:,0]\n",
    "#                 testing_input[:,:,:,idx] = test_tmax[:,:,:,0]\n",
    "    \n",
    "\n",
    "#             print('Final channel of input is the following (just make sure it has zeros for RZSM)')\n",
    "#             print(training_input[0,:,:,-1])\n",
    "\n",
    "#     elif addtl_experiment == True:\n",
    "#         #Get the number of extra channels to add from previous weeks predictions\n",
    "#         add_channels = 0\n",
    "\n",
    "\n",
    "#         training_input = np.empty(shape = (training_size_shape[0],training_size_shape[1],training_size_shape[2],len(lag_integer_list)+len(observation_lag_list_not_RZSM)*5+add_channels))\n",
    "#         validation_input = np.empty(shape = (validation_testing_size_shape[0],validation_testing_size_shape[1],validation_testing_size_shape[2],len(lag_integer_list)+len(observation_lag_list_not_RZSM)*5+add_channels))\n",
    "#         testing_input = np.empty(shape = (validation_testing_size_shape[0],validation_testing_size_shape[1],validation_testing_size_shape[2],len(lag_integer_list)+len(observation_lag_list_not_RZSM)*5+add_channels))\n",
    "\n",
    "\n",
    "#         #Add RZSM observations first\n",
    "#         for idx,lag in enumerate(lag_integer_list):\n",
    "#             channel_list.append(f'RZSM_obs_lag{lag}')\n",
    "#             training_input, validation_input, testing_input = pred.add_obs_RZSM_by_lag(training_input, validation_input, testing_input, lag, input_directory, idx)\n",
    "\n",
    "#         print(f'Index idx value is {idx}. Done adding RZSM obs.')    \n",
    "        \n",
    "#         RZSM_train_obs, RZSM_validation_obs = pred.return_masking_objects_for_RZSM(input_directory)\n",
    "\n",
    "\n",
    "#         for variable in var_list:\n",
    "#             channel_name_output = pred.return_channel_name(variable)\n",
    "#             for lag in observation_lag_list_not_RZSM:\n",
    "#                 channel_list.append(f'{channel_name_output}_obs_lag{lag}')\n",
    "#                 idx+=1\n",
    "#                 #Observations adding\n",
    "#                 training_input, validation_input, testing_input = pred.add_obs_other_observations_by_lag(training_input, validation_input, testing_input, lag, input_directory, variable, idx)\n",
    "     \n",
    "        \n",
    "#             print(f'Index idx value is {idx}. Done adding {variable} obs.')\n",
    "\n",
    "#         print('Final channel of input is the following (just make sure it has zeros for RZSM)')\n",
    "#         print(training_input[0,:,:,-1])\n",
    "\n",
    "#     return(training_input, validation_input, testing_input,channel_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b76505fe-47ac-4edc-aab5-108a48d4f8e2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_all_data_EX5_EX6_EX7_EX8_experiments(lead, num_lags_obs_RZSM, include_lags_obs_pwat_spfh_tmax, \n",
    "                                              include_reforecast_or_not, observation_lag_list_not_RZSM, lag_integer_list,\n",
    "                                              input_directory,training_size_shape,validation_testing_size_shape,RZSM_or_Tmax_or_both,experiment_test,experiment_name,experiment_name_out):\n",
    "    print('\\nUsing observations as predictions and forecast lead week 1\\n')\n",
    "    #Observations RZSM\n",
    "    '''We need to combine all the RZSM files into 1 single dictionary for later processing'''\n",
    "    \n",
    "    channel_list = []\n",
    "\n",
    "    assert lead >=1, 'We are only looking at weekly leads 1-5, cannot do 0 lead'\n",
    "    \n",
    "    #Reforecast predictors\n",
    "    var_list = ['pwat_eatm', 'spfh_2m', 'tmax_2m', 'diff_temp_2m', 'hgt_pres']\n",
    "    \n",
    "    print(f'Experiment name is {experiment_name_out}')\n",
    "    \n",
    "    if experiment_name in ['EX22','EX23','EX24','EX25']:\n",
    "        #This is only a bias correction using observations (no reforecast input at all)\n",
    "        lead_add = 0\n",
    "    elif experiment_name in ['EX5','EX6','EX7','EX8']:\n",
    "        #This is only a bias correction using observations and the current week of reforecast as inputs\n",
    "        lead_add = 1\n",
    "    elif experiment_name in ['EX18','EX19','EX20','EX21']:\n",
    "        if lead ==1:\n",
    "            lead_add = 1 #Only adding the current week of forecast\n",
    "        else:\n",
    "            lead_add = lead #Adding previous weeks forecast and the current week\n",
    "\n",
    "    print(f'Adding {lead_add} to channel list from reforecast.')\n",
    "\n",
    "        \n",
    "    training_input = np.empty(shape = (training_size_shape[0],training_size_shape[1],training_size_shape[2],len(lag_integer_list)+ lead_add))\n",
    "    validation_input = np.empty(shape = (validation_testing_size_shape[0],validation_testing_size_shape[1],validation_testing_size_shape[2],len(lag_integer_list) + lead_add))\n",
    "    testing_input = np.empty(shape = (validation_testing_size_shape[0],validation_testing_size_shape[1],validation_testing_size_shape[2],len(lag_integer_list)+ lead_add))\n",
    "    \n",
    "    print(f'Training shape: {training_input.shape}')\n",
    "    \n",
    "    #Add RZSM observations first\n",
    "    for idx,lag in enumerate(lag_integer_list):\n",
    "        channel_list.append(f'RZSM_obs_lag{lag}')\n",
    "        training_input, validation_input, testing_input = pred.add_obs_RZSM_by_lag(training_input, validation_input, testing_input, lag, input_directory, idx)\n",
    "\n",
    "    print(f'Index idx value is {idx}. Done adding RZSM obs.')\n",
    "    \n",
    "    #For masking\n",
    "    RZSM_train_obs, RZSM_validation_obs = pred.return_masking_objects_for_RZSM(input_directory)\n",
    "\n",
    "    if experiment_name in ['EX5','EX6','EX7','EX8']:\n",
    "        #We only need to add the current reforecast week\n",
    "        #Add final predictor for the current week of RZSM within reforecast\n",
    "        idx+=1\n",
    "        soil_var = 'soilw_bgrnd'\n",
    "        channel_name_output = pred.return_channel_name(soil_var)\n",
    "        channel_list.append(f'{channel_name_output}_ref_lead{lead}')\n",
    "    \n",
    "        print(f'And finally adding RZSM week {lead} from reforecast as a predictor')\n",
    "        \n",
    "        training_input, validation_input, testing_input = pred.add_reforecast_by_lag(training_input, validation_input, testing_input, lead, input_directory,soil_var, idx)\n",
    "        \n",
    "        return(training_input, validation_input, testing_input, channel_list)\n",
    "\n",
    "    elif experiment_name in ['EX22','EX23','EX24','EX25']:\n",
    "         #We are not adding any additional predictors\n",
    "         return(training_input, validation_input, testing_input, channel_list)\n",
    "        \n",
    "    \n",
    "    else:\n",
    "        assert lead >= 2, 'If trying to run EX18-EX21, DO NOT RUN with week 1 data. Start with Week 2'\n",
    "\n",
    "\n",
    "\n",
    "        #Now we need to load our data from the previous weeks\n",
    "        for lead_previous in range(1,lead):\n",
    "\n",
    "            #To not have to re-run a bunch more models, we can re-use the training from a previous week\n",
    "            if lead_previous == 1:\n",
    "                if experiment_name == 'EX18':\n",
    "                    prev_experiment = f'EX5_{save_loss_name}_RZSM'\n",
    "                        \n",
    "                elif experiment_name == 'EX19':\n",
    "                    prev_experiment = f'EX6_{save_loss_name}_RZSM'    \n",
    "                    \n",
    "                elif experiment_name == 'EX20':\n",
    "                    prev_experiment = f'EX7_{save_loss_name}_RZSM'  \n",
    "                    \n",
    "                elif experiment_name == 'EX21':\n",
    "                    prev_experiment = f'EX8_{save_loss_name}_RZSM'\n",
    "            elif lead > 2:\n",
    "                prev_experiment = experiment_name_out\n",
    "            \n",
    "            print(f'Working on previous lead: Week {lead_previous}')\n",
    "            # break\n",
    "\n",
    "            pred_dir = f'predictions_XGBOOST/{region_name}/Wk{lead_previous}_training_validation'\n",
    "            testing_dir = f'predictions_XGBOOST/{region_name}/Wk{lead_previous}_testing'\n",
    "\n",
    "            os.system(f'mkdir -p {pred_dir}')\n",
    "\n",
    "            training_prediction_name= f'{pred_dir}/Wk{lead_previous}_training_{prev_experiment}.npy'\n",
    "            validation_prediction_name = f'{pred_dir}/Wk{lead_previous}_validation_{prev_experiment}.npy'\n",
    "            testing_prediction_name = f'{testing_dir}/Wk{lead_previous}_testing_{prev_experiment}.npy'\n",
    "\n",
    "\n",
    "            testing_prediction = np.load(testing_prediction_name)\n",
    "            '''Load the training and validation predictions if they exist'''\n",
    "            \n",
    "            if os.path.exists(training_prediction_name):\n",
    "                print(f'Loading data from previous week lead {lead_previous}')\n",
    "                training_prediction = np.load(training_prediction_name)\n",
    "                validation_prediction =np.load(validation_prediction_name)\n",
    "\n",
    "            else:\n",
    "                print(f'Creating prediction data from previous week lead {lead_previous} from {prev_experiment}.')\n",
    "                '''If they don't exist..... load model for previous week'''\n",
    "                model = load_model(f'checkpoints/Wk_{lead_previous}/Wk{lead_previous}_{prev_experiment}',compile=False) #don't need the custom loss function for predictions\n",
    "\n",
    "                training_input_previous = np.load(f'Data/model_npy_inputs/{region_name}/Wk{lead_previous}_EX_input_data/{prev_experiment}_training_input.npy')\n",
    "                validation_input_previous = np.load(f'Data/model_npy_inputs/{region_name}/Wk{lead_previous}_EX_input_data/{prev_experiment}_validation_input.npy')\n",
    "                testing_input_previous = np.load(f'Data/model_npy_inputs/{region_name}/Wk{lead_previous}_EX_input_data/{prev_experiment}_testing_input.npy')\n",
    "\n",
    "                '''Make predictions and save data to load for previous use'''\n",
    "                training_prediction = model.predict(training_input_previous) #Just for unit checking\n",
    "                np.save(training_prediction_name,training_prediction)\n",
    "\n",
    "                validation_prediction = model.predict(validation_input_previous)\n",
    "                np.save(validation_prediction_name,validation_prediction)\n",
    "\n",
    "            ############# ADD BACK TO CREATED ARRAY ###############################\n",
    "            '''Now get the best UNET index prediction for RZSM and Tmax. Because the UNET plus plus produces 4 different outputs'''\n",
    "            min_RZSM_index,min_tmax_index = f.load_loss_csv_bias_correction(lead_previous,prev_experiment,RZSM_or_Tmax_or_both, region_name)\n",
    "\n",
    "            if np.array(training_prediction).shape[0] == 8 and RZSM_or_Tmax_or_both == 'both':\n",
    "                min_tmax_index = min_tmax_index+4 #Because index values 0-3 are RZSM and 4-7 are Tmax\n",
    "            elif np.array(training_prediction).shape[0] == 6 and RZSM_or_Tmax_or_both == 'both':\n",
    "                min_tmax_index = min_tmax_index + 3 #Because index values are 0-2 for RZSM and 3-5 for Tmax\n",
    "            '''Now split the training and validation data back into RZSM and/or Tmax'''\n",
    "\n",
    "\n",
    "            train_RZSM = np.array(training_prediction)[min_RZSM_index,:,:,:,:]\n",
    "            val_RZSM = np.array(validation_prediction)[min_RZSM_index,:,:,:,:]\n",
    "            test_RZSM = np.array(testing_prediction)[min_RZSM_index,:,:,:,:]\n",
    "\n",
    "\n",
    "            '''Make sure we mask RZSM values which aren't on land'''\n",
    "            train_RZSM = np.where(RZSM_train_obs==0,0,train_RZSM)\n",
    "            val_RZSM = np.where(RZSM_validation_obs==0,0,val_RZSM)\n",
    "            test_RZSM = np.where(RZSM_validation_obs==0,0,test_RZSM)\n",
    "\n",
    "            #Now add back to the data\n",
    "            '''Now add back to the newly created dataset'''\n",
    "            idx+=1\n",
    "            channel_list.append(f'RZSM_prediction_lead{lead_previous}')\n",
    "            print(f'Adding RZSM training, validation, testing into index {idx}')\n",
    "            training_input[:,:,:,idx] = train_RZSM[:,:,:,0]\n",
    "            validation_input[:,:,:,idx] = val_RZSM[:,:,:,0]\n",
    "            testing_input[:,:,:,idx] = test_RZSM[:,:,:,0]\n",
    "\n",
    "\n",
    "        #Add final predictor for the current week of RZSM within reforecast\n",
    "        idx+=1\n",
    "        soil_var = 'soilw_bgrnd'\n",
    "        channel_name_output = pred.return_channel_name(soil_var)\n",
    "        channel_list.append(f'{channel_name_output}_ref_lead{lead}')\n",
    "    \n",
    "        print(f'And finally adding RZSM week {lead} from reforecast as a predictor')\n",
    "        \n",
    "        training_input, validation_input, testing_input = pred.add_reforecast_by_lag(training_input, validation_input, testing_input, lead, input_directory,soil_var, idx)\n",
    "    \n",
    "        print(f'Index idx value is {idx}. Done adding {soil_var} reforecast.')\n",
    "\n",
    "        print('Final channel of input is the following (just make sure it has zeros for RZSM)')\n",
    "        print(training_input[0,:,:,-1])\n",
    "\n",
    "\n",
    "        return(training_input, validation_input, testing_input, channel_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c30f7d9a-2690-4223-904a-83158fa830ce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_all_data_EX9_EX10_EX11_EX12_after_week_0(lead, num_lags_obs_RZSM, include_lags_obs_pwat_spfh_tmax, include_reforecast_or_not, \n",
    "                                           observation_lag_list_not_RZSM, lag_integer_list, input_directory,training_size_shape,\n",
    "                                           validation_testing_size_shape,experiment_name,RZSM_or_Tmax_or_both, experiment_test,region_name,experiment_name_out):\n",
    "    '''We need to combine all the RZSM files and all the observation data (pwat, spfh, tmax, diff_temp, z200) into one file. Also adding the RZSM reforecast data from RZSM and Tmax '''\n",
    "\n",
    "    channel_list = []\n",
    "    \n",
    "    #Reforecast predictors\n",
    "    var_list = ['pwat_eatm', 'spfh_2m', 'tmax_2m', 'diff_temp_2m', 'hgt_pres']\n",
    "\n",
    "    if experiment_test == 0:\n",
    "        add_channels = lead  \n",
    "        reforecast_predictors = False\n",
    "    elif (experiment_test >= 1) and (lead in [1,2]):\n",
    "        #This is adding 5 additional predictors (tmax, diff_temp, z200, pwat, spfh)\n",
    "        #Also add the number of channels according to the lead. If lead == 1, then only add lead 1 current week. If lead == 2, add one channel for week 2 and one channel for the prediction from Week 1\n",
    "        add_channels = lead  + len(var_list)\n",
    "        reforecast_predictors = True\n",
    "    elif (experiment_test >= 1) and (lead > 2):\n",
    "        add_channels = lead \n",
    "        reforecast_predictors = False\n",
    "            \n",
    "   \n",
    "    training_input = np.empty(shape = (training_size_shape[0],training_size_shape[1],training_size_shape[2],len(lag_integer_list)+len(var_list)*3+add_channels))\n",
    "    validation_input = np.empty(shape = (validation_testing_size_shape[0],validation_testing_size_shape[1],validation_testing_size_shape[2],len(lag_integer_list)+len(var_list)*3+add_channels))\n",
    "    testing_input = np.empty(shape = (validation_testing_size_shape[0],validation_testing_size_shape[1],validation_testing_size_shape[2],len(lag_integer_list)+len(var_list)*3+add_channels))\n",
    "    \n",
    "    print(f'Training input shape = {training_input.shape}')\n",
    "    \n",
    "    #Add RZSM observations first\n",
    "    for idx,lag in enumerate(lag_integer_list):\n",
    "        channel_list.append(f'RZSM_obs_lag{lag}')\n",
    "        training_input, validation_input, testing_input = pred.add_obs_RZSM_by_lag(training_input, validation_input, testing_input, lag, input_directory, idx)\n",
    "        \n",
    "    print(f'Index idx value is {idx}. Done adding RZSM obs.')    \n",
    "    \n",
    "    RZSM_train_obs, RZSM_validation_obs = pred.return_masking_objects_for_RZSM(input_directory)\n",
    "\n",
    "    for variable in var_list:\n",
    "        channel_name_output = pred.return_channel_name(variable)\n",
    "        for lag in observation_lag_list_not_RZSM:\n",
    "            channel_list.append(f'{channel_name_output}_obs_lag{lag}')\n",
    "            idx+=1\n",
    "            #Observations adding\n",
    "            training_input, validation_input, testing_input = pred.add_obs_other_observations_by_lag(training_input, validation_input, testing_input, lag, input_directory, variable, idx)\n",
    " \n",
    "    \n",
    "        print(f'Index idx value is {idx}. Done adding {variable} obs.')\n",
    "    \n",
    "    ############################### NOW ADD THE PREDICTION DATA FROM PREVIOUS WEEK ################################################\n",
    "    #Now we need to load our data from the previous weeks \n",
    "    \n",
    "    if lead in [0, 1]:\n",
    "        #DO NOT INCLUDE LEAD 0 AS A PREDICTOR (FROM PREVIOUS WEEK)\n",
    "        pass\n",
    "    else:\n",
    "\n",
    "        for lead_previous in range(1,lead):\n",
    "            print(f'Adding previous RZSM prediction from week {lead_previous} as an input channel')\n",
    "            # break\n",
    "            \n",
    "            pred_dir = f'predictions_XGBOOST/{region_name}/Wk{lead_previous}_training_validation'\n",
    "            testing_dir = f'predictions_XGBOOST/{region_name}/Wk{lead_previous}_testing'\n",
    "            \n",
    "            os.system(f'mkdir -p {pred_dir}')\n",
    "            \n",
    "            training_prediction_name= f'{pred_dir}/Wk{lead_previous}_training_{experiment_name_out}.npy'\n",
    "            validation_prediction_name = f'{pred_dir}/Wk{lead_previous}_validation_{experiment_name_out}.npy'\n",
    "            testing_prediction_name = f'{testing_dir}/Wk{lead_previous}_testing_{experiment_name_out}.npy'\n",
    "            \n",
    "            test_RZSM = np.load(testing_prediction_name)\n",
    "            #Need to change the dimensions to match the other inputs\n",
    "            #test_RZSM is shape (104,48,96)\n",
    "            #Need to change to (1144,48,96)\n",
    "\n",
    "            new_shape_test = np.zeros(shape = (104,11,48,96))\n",
    "            for i in range(11):\n",
    "                new_shape_test[:,i,:,:] = test_RZSM\n",
    "            new_shape_test = np.reshape(new_shape_test,(1144,48,96))\n",
    "            \n",
    "            print(f'Loading data from previous week lead {lead_previous}')\n",
    "            \n",
    "            train_RZSM = np.load(training_prediction_name)\n",
    "            new_shape_train = np.zeros(shape = (835,11,48,96))\n",
    "            for i in range(11):\n",
    "                new_shape_train[:,i,:,:] = train_RZSM\n",
    "            new_shape_train = np.reshape(new_shape_train,(9185,48,96))\n",
    "\n",
    "            val_RZSM =np.load(validation_prediction_name)\n",
    "            new_shape_val = np.zeros(shape = (104,11,48,96))\n",
    "            for i in range(11):\n",
    "                new_shape_val[:,i,:,:] = val_RZSM\n",
    "            new_shape_val = np.reshape(new_shape_val,(1144,48,96))\n",
    "            \n",
    "    \n",
    "            #Now add back to the data\n",
    "            '''Now add back to the newly created dataset'''\n",
    "            idx+=1\n",
    "            channel_list.append(f'RZSM_prediction_lead{lead_previous}')\n",
    "            print(f'Adding RZSM training, validation, testing into index {idx}')\n",
    "            training_input[:,:,:,idx] = new_shape_train[:,:,:]\n",
    "            validation_input[:,:,:,idx] = new_shape_val[:,:,:]\n",
    "            testing_input[:,:,:,idx] = new_shape_test[:,:,:]\n",
    "\n",
    "    \n",
    "    ############################### NOW ADD THE REFORECAST DATA FROM THE WEEK TO BE PREDICTED ################################################\n",
    "    \n",
    "    #Add predictors from the reforecast model\n",
    "    if (lead in [1,2]) and (experiment_test == 1):\n",
    "        print(f'Adding current reforecast data from week {lead} for vars {(var_list)}')  \n",
    "        #Only add these for week 1 and 2. \n",
    "        for variable in var_list:\n",
    "            idx+=1\n",
    "            channel_name_output = pred.return_channel_name(variable)\n",
    "            \n",
    "            channel_list.append(f'{channel_name_output}_ref_lead{lead}')\n",
    "            \n",
    "            training_input, validation_input, testing_input = pred.add_reforecast_by_lag(training_input, validation_input, testing_input, lead, input_directory, variable, idx)\n",
    "    \n",
    "            print(f'Index idx value is {idx}. Done adding {variable} reforecast.')\n",
    "\n",
    "    #Add final predictor for the current week of RZSM within reforecast\n",
    "    idx+=1\n",
    "    soil_var = 'soilw_bgrnd'\n",
    "    channel_name_output = pred.return_channel_name(soil_var)\n",
    "    channel_list.append(f'{channel_name_output}_ref_lead{lead}')\n",
    "\n",
    "    print(f'And finally adding RZSM week {lead} from reforecast as a predictor')\n",
    "    \n",
    "    training_input, validation_input, testing_input = pred.add_reforecast_by_lag(training_input, validation_input, testing_input, lead, input_directory,soil_var, idx)\n",
    "\n",
    "    print(f'Index idx value is {idx}. Done adding {soil_var} reforecast.')\n",
    "\n",
    "    print('Final channel of input is the following (just make sure it has zeros for RZSM)')\n",
    "    print(training_input[0,:,:,-1])\n",
    "\n",
    "    return(training_input, validation_input, testing_input,channel_list)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c8f158ec-5304-457d-b60f-485f78f4a95b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_only_predictions_EX26(lead, input_directory,training_size_shape,validation_testing_size_shape,RZSM_or_Tmax_or_both,experiment_name,region_name,\n",
    "                               experiment_name_out):\n",
    "    '''We need to combine all the RZSM files and all the observation data (pwat, spfh, tmax, diff_temp, z200) into one file. Also adding the RZSM reforecast data from RZSM and Tmax '''\n",
    "\n",
    "    channel_list = []\n",
    "\n",
    "    assert lead >=2, 'We cannot make a prediction if lead week is 1 because we dont have an input. So make lead week >= 2.'\n",
    "\n",
    "    #Get the number of extra channels to add from previous weeks predictions\n",
    "    add_channels = lead # We are only adding the previous weeks lag and the current week. \n",
    "\n",
    "    training_input = np.empty(shape = (training_size_shape[0],training_size_shape[1],training_size_shape[2],add_channels))\n",
    "    validation_input = np.empty(shape = (validation_testing_size_shape[0],validation_testing_size_shape[1],validation_testing_size_shape[2],add_channels))\n",
    "    testing_input = np.empty(shape = (validation_testing_size_shape[0],validation_testing_size_shape[1],validation_testing_size_shape[2],add_channels))\n",
    "    \n",
    "    print(f'Training input shape = {training_input.shape}')\n",
    "    \n",
    "    #For masking\n",
    "    RZSM_train_obs, RZSM_validation_obs = pred.return_masking_objects_for_RZSM(input_directory)\n",
    "\n",
    "    ############################### NOW ADD THE PREDICTION DATA FROM PREVIOUS WEEK ################################################\n",
    "        #Now we need to load our data from the previous weeks\n",
    "    for idx,lead_previous in enumerate(range(1,lead)):\n",
    "        # break\n",
    "        \n",
    "        pred_dir = f'predictions/{region_name}/Wk{lead_previous}_training_validation'\n",
    "        testing_dir = f'predictions/{region_name}/Wk{lead_previous}_testing'\n",
    "        \n",
    "        os.system(f'mkdir -p {pred_dir}')\n",
    "        \n",
    "        previous_model = return_fully_autoregressive_EX26(lead)\n",
    "            \n",
    "        \n",
    "        training_prediction_name= f'{pred_dir}/Wk{lead_previous}_training_{previous_model[idx]}.npy'\n",
    "        validation_prediction_name = f'{pred_dir}/Wk{lead_previous}_validation_{previous_model[idx]}.npy'\n",
    "        testing_prediction_name = f'{testing_dir}/Wk{lead_previous}_testing_{previous_model[idx]}.npy'\n",
    "        \n",
    "        testing_prediction = np.load(testing_prediction_name)\n",
    "        '''Load the training and validation predictions if they exist'''\n",
    "        \n",
    "        if os.path.exists(training_prediction_name):\n",
    "            print(f'Loading data from previous week lead {lead_previous}')\n",
    "            training_prediction = np.load(training_prediction_name)\n",
    "            validation_prediction =np.load(validation_prediction_name)\n",
    "            \n",
    "        else:\n",
    "            print(f'Creating prediction data from previous week lead {lead_previous}')\n",
    "            '''If they don't exist..... load model for previous week'''\n",
    "            model = load_model(f'checkpoints/Wk_{lead_previous}/Wk{lead_previous}_{experiment_name}',compile=False) #don't need the custom loss function for predictions\n",
    "            \n",
    "            training_input_previous = np.load(f'Data/model_npy_inputs/{region_name}/Wk{lead_previous}_EX_input_data/{experiment_name_out}_training_input.npy')\n",
    "            validation_input_previous = np.load(f'Data/model_npy_inputs/{region_name}/Wk{lead_previous}_EX_input_data/{experiment_name_out}_validation_input.npy')\n",
    "            testing_input_previous = np.load(f'Data/model_npy_inputs{region_name}//Wk{lead_previous}_EX_input_data/{experiment_name_out}_testing_input.npy')\n",
    "            \n",
    "            '''Make predictions and save data to load for previous use'''\n",
    "            training_prediction = model.predict(training_input_previous) #Just for unit checking\n",
    "            np.save(training_prediction_name,training_prediction)\n",
    "            \n",
    "            validation_prediction = model.predict(validation_input_previous)\n",
    "            np.save(validation_prediction_name,validation_prediction)\n",
    "        \n",
    "        \n",
    "        ############# ADD BACK TO CREATED ARRAY ###############################\n",
    "        '''Now get the best UNET index prediction for RZSM and Tmax. Because the UNET plus plus produces 4 different outputs'''\n",
    "        min_RZSM_index,min_tmax_index = f.load_loss_csv_bias_correction(lead_previous,previous_model[idx],RZSM_or_Tmax_or_both, region_name)\n",
    "\n",
    "        if np.array(training_prediction).shape[0] == 8 and RZSM_or_Tmax_or_both == 'both':\n",
    "            min_tmax_index = min_tmax_index+4 #Because index values 0-3 are RZSM and 4-7 are Tmax\n",
    "        elif np.array(training_prediction).shape[0] == 6 and RZSM_or_Tmax_or_both == 'both':\n",
    "            min_tmax_index = min_tmax_index + 3 #Because index values are 0-2 for RZSM and 3-5 for Tmax\n",
    "        '''Now split the training and validation data back into RZSM and/or Tmax'''\n",
    "        \n",
    "        \n",
    "        train_RZSM = np.array(training_prediction)[min_RZSM_index,:,:,:,:]\n",
    "        val_RZSM = np.array(validation_prediction)[min_RZSM_index,:,:,:,:]\n",
    "        test_RZSM = np.array(testing_prediction)[min_RZSM_index,:,:,:,:]\n",
    "\n",
    "\n",
    "        '''Make sure we mask RZSM values which aren't on land'''\n",
    "        train_RZSM = np.where(RZSM_train_obs==0,0,train_RZSM)\n",
    "        val_RZSM = np.where(RZSM_validation_obs==0,0,val_RZSM)\n",
    "        test_RZSM = np.where(RZSM_validation_obs==0,0,test_RZSM)\n",
    "\n",
    "        #Now add back to the data\n",
    "        '''Now add back to the newly created dataset'''\n",
    "        channel_list.append(f'RZSM_prediction_lead{lead_previous}')\n",
    "        print(f'Adding RZSM training, validation, testing into index {idx}')\n",
    "        training_input[:,:,:,idx] = train_RZSM[:,:,:,0]\n",
    "        validation_input[:,:,:,idx] = val_RZSM[:,:,:,0]\n",
    "        testing_input[:,:,:,idx] = test_RZSM[:,:,:,0]\n",
    "\n",
    "        idx+=1\n",
    "\n",
    "    \n",
    "    ############################### NOW ADD THE REFORECAST DATA FROM THE WEEK TO BE PREDICTED ################################################\n",
    "    \n",
    "    #Add RZSM reforecast week N\n",
    "    soil_var = 'soilw_bgrnd'\n",
    "    channel_name_output = pred.return_channel_name(soil_var)\n",
    "    channel_list.append(f'{channel_name_output}_ref_lead{lead}')\n",
    "\n",
    "    print(f'And finally adding RZSM week {lead} from reforecast as a predictor')\n",
    "    \n",
    "    training_input, validation_input, testing_input = pred.add_reforecast_by_lag(training_input, validation_input, testing_input, lead, input_directory,soil_var, idx)\n",
    "\n",
    "    print(f'Index idx value is {idx}. Done adding {soil_var} reforecast.')\n",
    "\n",
    "    print('Final channel of input is the following (just make sure it has zeros for RZSM)')\n",
    "    print(training_input[0,:,:,-1])\n",
    "\n",
    "    return(training_input, validation_input, testing_input,channel_list)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "705e8a43-188b-46c5-a45f-02a2637c28c8",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def make_UNET_stacked_inputs(lead, num_lags_obs_RZSM, include_lags_obs_pwat_spfh_tmax, include_reforecast_or_not, \n",
    "                             observation_lag_list_not_RZSM, lag_integer_list, input_directory,training_size_shape,\n",
    "                             validation_testing_size_shape,experiment_name,RZSM_or_Tmax_or_both,addtl_experiment,experiment_test,region_name,experiment_name_out):\n",
    "    \n",
    "    \n",
    "    #Set restrictions. For EX0, we only want to bias correct the forecasts with week lead 1 RZSM and tmax\n",
    "    if experiment_name == 'EX0' or experiment_name == 'EX13':\n",
    "        \n",
    "        #Step 1 load data \n",
    "        print(f'\\nWorking on setting up data for Experiment {experiment_name} for lead {lead}\\n')\n",
    "        \n",
    "        final_input_train, final_input_validation, final_input_testing,channel_list =  loadData.load_all_data_EX0(lead, num_lags_obs_RZSM, include_lags_obs_pwat_spfh_tmax, include_reforecast_or_not, \n",
    "                                                                                                     observation_lag_list_not_RZSM, lag_integer_list, input_directory,training_size_shape,\n",
    "                                                                                                     validation_testing_size_shape,RZSM_or_Tmax_or_both,addtl_experiment,experiment_test)\n",
    "\n",
    "        print(f'\\nInput channels will be only week 1 Tmax and RZSM through the current lead {lead} which are also going to be predicted. There are no observations in this experiment\\n')\n",
    "        \n",
    "        print('Done')\n",
    "        \n",
    "        \n",
    "    \n",
    "    ############################################### EXPERIMENTS 1-4 ####################################################################################\n",
    "    elif experiment_name in ['EX1','EX2','EX3','EX4','EX14','EX15','EX16','EX17']:\n",
    "\n",
    "        print(f'\\nWorking on setting up data for Experiment {experiment_name} for lead {lead}\\n')\n",
    "        \n",
    "        if lead == 0:\n",
    "            #Step 1 load data \n",
    "            final_input_train, final_input_validation, final_input_testing,channel_list = loadData.load_all_data_EX1_EX2_EX3_EX4(lead, num_lags_obs_RZSM, include_lags_obs_pwat_spfh_tmax, \n",
    "                                                                                                                    include_reforecast_or_not, observation_lag_list_not_RZSM, lag_integer_list, input_directory,\n",
    "                                                                                                                   training_size_shape,validation_testing_size_shape,RZSM_or_Tmax_or_both,\n",
    "                                                                                                                                   region_name=region_name)\n",
    "        else:\n",
    "            final_input_train, final_input_validation, final_input_testing,channel_list = load_all_data_EX1_EX2_EX3_EX4_after_week_0(lead, num_lags_obs_RZSM, include_lags_obs_pwat_spfh_tmax, include_reforecast_or_not, \n",
    "                                                                                                                                       observation_lag_list_not_RZSM, lag_integer_list, input_directory,training_size_shape,\n",
    "                                                                                                                                       validation_testing_size_shape,experiment_name,RZSM_or_Tmax_or_both,addtl_experiment,experiment_test,\n",
    "                                                                                                                                    experiment_name_out=experiment_name_out)\n",
    "\n",
    "        \n",
    "                \n",
    "        print('Done')\n",
    "        \n",
    "        \n",
    "    \n",
    "    ############################################### EXPERIMENTS 5-8 ####################################################################################\n",
    "    elif experiment_name in ['EX5','EX6','EX7','EX8','EX18','EX19','EX20','EX21','EX22','EX23','EX24','EX25']:\n",
    "\n",
    "        print(f'\\nWorking on setting up data for Experiment {experiment_name} for lead {lead}\\n')\n",
    "        \n",
    "        # #Step 1 load data \n",
    "        # if addtl_experiment == False:\n",
    "        #     final_input_train, final_input_validation, final_input_testing,channel_list = loadData.load_all_data_EX5_EX6_EX7_EX8(lead, num_lags_obs_RZSM, include_lags_obs_pwat_spfh_tmax, \n",
    "        #                                                                                                    include_reforecast_or_not, observation_lag_list_not_RZSM, lag_integer_list,\n",
    "        #                                                                                                    input_directory,training_size_shape,validation_testing_size_shape,RZSM_or_Tmax_or_both,\n",
    "                                                                                                                                   # region_name=region_name)\n",
    "        # else:\n",
    "        final_input_train, final_input_validation, final_input_testing,channel_list = load_all_data_EX5_EX6_EX7_EX8_experiments(lead, num_lags_obs_RZSM, include_lags_obs_pwat_spfh_tmax, include_reforecast_or_not, \n",
    "                                                                                      observation_lag_list_not_RZSM, lag_integer_list, input_directory,training_size_shape,\n",
    "                                                                                      validation_testing_size_shape,RZSM_or_Tmax_or_both,experiment_test,experiment_name,experiment_name_out=experiment_name_out)\n",
    "\n",
    "        print('Done')\n",
    "        \n",
    "        \n",
    "    \n",
    "    ############################################### EXPERIMENTS 9-12 ####################################################################################\n",
    "    elif (experiment_name == 'EX9') or (experiment_name == 'EX10') or (experiment_name == 'EX11') or (experiment_name == 'EX12') or (experiment_name == 'EX27') or (experiment_name == 'EX28'):\n",
    "        \n",
    "        print(f'\\nWorking on setting up data for Experiment {experiment_name} for lead {lead}\\n')\n",
    "\n",
    "        if lead == 0:\n",
    "            final_input_train, final_input_validation, final_input_testing,channel_list = loadData.load_all_data_EX9_EX10_EX11_EX12(lead, num_lags_obs_RZSM, include_lags_obs_pwat_spfh_tmax, \n",
    "                                                                                                              include_reforecast_or_not, observation_lag_list_not_RZSM, lag_integer_list, \n",
    "                                                                                                              input_directory,training_size_shape,validation_testing_size_shape,RZSM_or_Tmax_or_both, \n",
    "                                                                                                                                    experiment_test = experiment_test,\n",
    "                                                                                                                                   region_name=region_name)\n",
    "        else:\n",
    "            final_input_train, final_input_validation, final_input_testing,channel_list = load_all_data_EX9_EX10_EX11_EX12_after_week_0(lead, num_lags_obs_RZSM, include_lags_obs_pwat_spfh_tmax, include_reforecast_or_not, \n",
    "                                                                                                       observation_lag_list_not_RZSM, lag_integer_list, input_directory,training_size_shape,\n",
    "                                                                                                   validation_testing_size_shape,experiment_name,RZSM_or_Tmax_or_both,\n",
    "                                                                                                                                       experiment_test = experiment_test,\n",
    "                                                                                                                                       region_name = region_name,experiment_name_out=experiment_name_out)\n",
    "    elif (experiment_name == 'EX26'):\n",
    "\n",
    "        print(f'\\nWorking on setting up data for Experiment {experiment_name} for lead {lead}\\n')\n",
    "\n",
    "        final_input_train, final_input_validation, final_input_testing,\n",
    "        channel_list = load_only_predictions_EX26(lead, input_directory,training_size_shape,validation_testing_size_shape,RZSM_or_Tmax_or_both,experiment_name,region_name,\n",
    "                               experiment_name_out)\n",
    "        print('Done')\n",
    "\n",
    "\n",
    "    return (final_input_train,final_input_validation,final_input_testing,channel_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "84042a9e-5635-447c-a16a-679fcbd7624a",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#To try and save on memory, only load certain files at a time\n",
    "def return_only_train_validation(lead, num_lags_obs_RZSM, include_lags_obs_pwat_spfh_tmax, include_reforecast_or_not, \n",
    "                                 observation_lag_list_not_RZSM, lag_integer_list, input_directory,training_size_shape,\n",
    "                                 validation_testing_size_shape,experiment_name):\n",
    "    \n",
    "    reforecast_train_input, reforecast_validation_input, reforecast_testing_input,channel_list \\\n",
    "    = make_UNET_stacked_inputs(lead, num_lags_obs_RZSM, include_lags_obs_pwat_spfh_tmax, \n",
    "                               include_reforecast_or_not, observation_lag_list_not_RZSM, \n",
    "                               lag_integer_list, input_directory,training_size_shape,validation_testing_size_shape,experiment_name,region_name)\n",
    "\n",
    "    return(reforecast_train_input, reforecast_validation_input,reforecast_testing_input,channel_list)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def return_testing_data_model_training(lead, num_lags_obs_RZSM, include_lags_obs_pwat_spfh_tmax, \n",
    "                               include_reforecast_or_not, observation_lag_list_not_RZSM, \n",
    "                               lag_integer_list, input_directory,training_size_shape,validation_testing_size_shape,experiment_name):\n",
    "\n",
    "    reforecast_train_input, reforecast_validation_input, reforecast_testing_input,channel_list = make_UNET_stacked_inputs(lead, num_lags_obs_RZSM, include_lags_obs_pwat_spfh_tmax, \n",
    "                               include_reforecast_or_not, observation_lag_list_not_RZSM, \n",
    "                               lag_integer_list, input_directory,training_size_shape,validation_testing_size_shape,experiment_name,region_name)\n",
    "    return(reforecast_testing_input,channel_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "08e37a45-e7c7-4e62-b3cf-31ef129dbb24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_experiment_name_and_lags_and_channel_dir(include_reforecast_or_not, num_lags_obs_RZSM, include_lags_obs_pwat_spfh_tmax, addtl_experiment, experiment_test, region_name):\n",
    "    \n",
    "    experiment_name = CE.return_experiment_name(include_reforecast_or_not,num_lags_obs_RZSM,include_lags_obs_pwat_spfh_tmax,addtl_experiment,experiment_test)\n",
    "\n",
    "    save_experiment_name = f'{experiment_name}_RZSM'\n",
    "\n",
    "    experiment_name_out = f'{experiment_name}_XGBOOST_RZSM' #Need to manually change this if using different loss functions to keep track of things\n",
    "    \n",
    "    global lag_integer_list\n",
    "    lag_integer_list =  CE.return_num_day_lags_from_weekly_lags(num_lags_obs_RZSM) #For number of RZSM observation lags\n",
    "\n",
    "    #Where to save channel information\n",
    "    save_experiment_dir = f'Data/model_npy_inputs/{region_name}/Wk{lead}_EX_input_data'\n",
    "    \n",
    "    channel_save_dir = f'channel_list_information/Wk{lead}'\n",
    "    \n",
    "    checkpoint_filepath = f'checkpoints_XGBOOST/{region_name}/Wk{lead}/Wk{lead}_{experiment_name_out}'\n",
    "    \n",
    "    losses_dir = f'Losses_with_OBS_XGBOOST/{region_name}/Wk{lead}'\n",
    "    \n",
    "    save_checkpoint_dir =f'checkpoints_XGBOOST/{region_name}/Wk{lead}'\n",
    "    \n",
    "    os.system(f'mkdir -p {checkpoint_filepath} {channel_save_dir} {save_experiment_dir} {losses_dir} {save_checkpoint_dir}')\n",
    "\n",
    "    \n",
    "    #Set up files for either saving or loading\n",
    "    training_input_file = f'{save_experiment_dir}/{save_experiment_name}_XGBOOST_training_input.npy'\n",
    "    validation_input_file = f'{save_experiment_dir}/{save_experiment_name}_XGBOOST_validation_input.npy'\n",
    "    testing_input_file = f'{save_experiment_dir}/{save_experiment_name}_XGBOOST_testing_input.npy'\n",
    "\n",
    "    \n",
    "    return(save_experiment_name,experiment_name_out,experiment_name,lag_integer_list,channel_save_dir,\n",
    "           training_input_file,validation_input_file,testing_input_file,checkpoint_filepath,\n",
    "          losses_dir,save_checkpoint_dir,save_experiment_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "93274b84-b5c7-4103-9412-2dd052ae1c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_model_inputs(region_name,lead,include_reforecast_or_not,num_lags_obs_RZSM,include_lags_obs_pwat_spfh_tmax,addtl_experiment,experiment_test):\n",
    "\n",
    "    save_experiment_name, experiment_name_out, experiment_name,lag_integer_list, \\\n",
    "    channel_save_dir, training_input_file, validation_input_file, \\\n",
    "    testing_input_file,checkpoint_filepath, losses_dir,save_checkpoint_dir, \\\n",
    "    save_experiment_dir = return_experiment_name_and_lags_and_channel_dir(include_reforecast_or_not, num_lags_obs_RZSM, include_lags_obs_pwat_spfh_tmax, addtl_experiment, experiment_test, region_name)\n",
    "\n",
    "    if os.path.exists(training_input_file) and os.path.exists(validation_input_file) and os.path.exists(testing_input_file):\n",
    "        pass\n",
    "    else:\n",
    "        reforecast_train_input, reforecast_validation_input, reforecast_testing_input, channel_list \\\n",
    "        = make_UNET_stacked_inputs(lead, num_lags_obs_RZSM, include_lags_obs_pwat_spfh_tmax, include_reforecast_or_not, \n",
    "                             observation_lag_list_not_RZSM, lag_integer_list, input_directory,training_size_shape,\n",
    "                             validation_testing_size_shape,experiment_name,RZSM_or_Tmax_or_both,addtl_experiment,experiment_test,region_name,experiment_name_out)\n",
    "    \n",
    "        #Save data to file\n",
    "        np.save(training_input_file,tf.convert_to_tensor(reforecast_train_input,dtype=tf.float32))\n",
    "        np.save(validation_input_file,tf.convert_to_tensor(reforecast_validation_input,dtype=tf.float32))\n",
    "        np.save(testing_input_file,tf.convert_to_tensor(reforecast_testing_input,dtype=tf.float32))\n",
    "        \n",
    "        image_size = reforecast_train_input.shape[1:]           \n",
    "        #Save channel list information to txt file\n",
    "    \n",
    "        with open(f'{channel_save_dir}/{save_experiment_name}_channel_list.txt', 'w') as file:\n",
    "            for idx,element in enumerate(channel_list):\n",
    "                if '-' in element:\n",
    "                    source_='OBSERVATIONS'\n",
    "                else:\n",
    "                    source_='REFORECAST'\n",
    "    \n",
    "                file.write(f'Channel_{idx} is from {source_} with lead or lag {str(element)}' + '\\n')\n",
    "\n",
    "    return(f'Completed writing lead {lead} model input data to {save_experiment_dir}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2076b03f-80ee-49ad-b256-3450efcd55df",
   "metadata": {},
   "source": [
    "# Run the model for each experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ddec9e60-e784-4dd7-88e9-d3c2aa086c60",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "'''For experiments, you need to run the script once to make the data. Then restart the kernel to load the data. \n",
    "Otherwise the memory leaks are too high'''\n",
    "def run_EXPERIMENT(lead, num_lags_obs_RZSM,include_lags_obs_pwat_spfh_tmax ,include_reforecast_or_not,addtl_experiment,experiment_test,region_name):\n",
    "    if lead_week == 5:\n",
    "        patience=15\n",
    "    else:\n",
    "        patience = 10\n",
    "\n",
    "    #Options for num_lags_obs_RZSM weekly lags [ 3,6,9,12 ] ** this inc\n",
    "    #Options for num_lags_obs_pwat_spfh_tmax weekly lags [0 weeks or 2 weeks ]\n",
    "\n",
    "    train(epochs = 150, \n",
    "          batch_size = 66, \n",
    "          lead=lead_week, \n",
    "          initial_learning_rate=0.0001,\n",
    "          beta_1 = 0.9,\n",
    "          shuffle=False,\n",
    "          patience=patience,\n",
    "          kernel_norm = None,\n",
    "          deep_supervision = True,\n",
    "          num_lags_obs_RZSM=num_lags_obs_RZSM, \n",
    "          include_lags_obs_pwat_spfh_tmax=include_lags_obs_pwat_spfh_tmax,\n",
    "          include_reforecast_or_not=include_reforecast_or_not,\n",
    "          number_of_UNET_backbone_max_pool=4,\n",
    "          permutation_test = False,\n",
    "          make_additional_predictions_from_model_for_testing = False,\n",
    "          input_directory=input_directory,\n",
    "          training_size_shape=training_size_shape,\n",
    "          validation_testing_size_shape=validation_testing_size_shape,\n",
    "          addtl_experiment = addtl_experiment,\n",
    "          experiment_test =experiment_test,\n",
    "          region_name = region_name)\n",
    "    return(0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "03e1d8a6-4f31-445e-8ce8-3393ce515359",
   "metadata": {},
   "outputs": [],
   "source": [
    "#These are models which only include the reforecast predictions. We are not including any observations into them.\n",
    "\n",
    "EX0 ={'region_name':region_name, 'num_lags_obs_RZSM': 0, 'include_lags_obs_pwat_spfh_tmax': False, 'include_reforecast_or_not': True, 'addtl_experiment': False, 'experiment_test':0 }\n",
    "EX13={'region_name':region_name, 'num_lags_obs_RZSM': 0, 'include_lags_obs_pwat_spfh_tmax': False, 'include_reforecast_or_not': True, 'addtl_experiment': False, 'experiment_test':1 }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4c1a1677-e926-450e-b8f7-6d3f4c93f63b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Include all predictors for obs but DO NOT include the current reforecast RZSM \n",
    "\n",
    "EX1 ={'region_name':region_name, 'num_lags_obs_RZSM': 3, 'include_lags_obs_pwat_spfh_tmax': True, 'include_reforecast_or_not': False, 'addtl_experiment': False, 'experiment_test':0 }\n",
    "EX2 ={'region_name':region_name, 'num_lags_obs_RZSM': 6, 'include_lags_obs_pwat_spfh_tmax': True, 'include_reforecast_or_not': False, 'addtl_experiment': False, 'experiment_test':0 }\n",
    "EX3 ={'region_name':region_name, 'num_lags_obs_RZSM': 9, 'include_lags_obs_pwat_spfh_tmax': True, 'include_reforecast_or_not': False, 'addtl_experiment': False, 'experiment_test':0 }\n",
    "EX4 ={'region_name':region_name, 'num_lags_obs_RZSM': 12, 'include_lags_obs_pwat_spfh_tmax': True, 'include_reforecast_or_not': False, 'addtl_experiment': False, 'experiment_test':0 }\n",
    "\n",
    "\n",
    "#Include all predictors for obs but DO include the current reforecast RZSM \n",
    "EX14 ={'region_name':region_name, 'num_lags_obs_RZSM': 3, 'include_lags_obs_pwat_spfh_tmax': True, 'include_reforecast_or_not': False, 'addtl_experiment': True, 'experiment_test':1 }\n",
    "EX15 ={'region_name':region_name, 'num_lags_obs_RZSM': 6, 'include_lags_obs_pwat_spfh_tmax': True, 'include_reforecast_or_not': False, 'addtl_experiment': True, 'experiment_test':2 }\n",
    "EX16 ={'region_name':region_name, 'num_lags_obs_RZSM': 9, 'include_lags_obs_pwat_spfh_tmax': True, 'include_reforecast_or_not': False, 'addtl_experiment': False, 'experiment_test':3 }\n",
    "EX17 ={'region_name':region_name, 'num_lags_obs_RZSM': 12, 'include_lags_obs_pwat_spfh_tmax': True, 'include_reforecast_or_not': False, 'addtl_experiment': False, 'experiment_test':4 }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "40665067-ac31-4ba4-afff-47017b4b33de",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Include only OBS RZSM predictors and the current reforecast RZSM week \n",
    "\n",
    "EX5 ={'region_name':region_name, 'num_lags_obs_RZSM': 3, 'include_lags_obs_pwat_spfh_tmax': False, 'include_reforecast_or_not': True, 'addtl_experiment': False, 'experiment_test':0 }\n",
    "EX6 ={'region_name':region_name, 'num_lags_obs_RZSM': 6, 'include_lags_obs_pwat_spfh_tmax': False, 'include_reforecast_or_not': True, 'addtl_experiment': False, 'experiment_test':0 }\n",
    "EX7 ={'region_name':region_name, 'num_lags_obs_RZSM': 9, 'include_lags_obs_pwat_spfh_tmax': False, 'include_reforecast_or_not': True, 'addtl_experiment': False, 'experiment_test':0 }\n",
    "EX8 ={'region_name':region_name, 'num_lags_obs_RZSM': 12, 'include_lags_obs_pwat_spfh_tmax': False, 'include_reforecast_or_not': True, 'addtl_experiment': False, 'experiment_test':0 }\n",
    "\n",
    "#Include only OBS RZSM predictors, previous weeks prediction, and current reforecast RZSM week \n",
    "EX18 ={'region_name':region_name, 'num_lags_obs_RZSM': 3, 'include_lags_obs_pwat_spfh_tmax': False, 'include_reforecast_or_not': True, 'addtl_experiment': True, 'experiment_test':1 }\n",
    "EX19 ={'region_name':region_name, 'num_lags_obs_RZSM': 6, 'include_lags_obs_pwat_spfh_tmax': False, 'include_reforecast_or_not': True, 'addtl_experiment': True, 'experiment_test':2 }\n",
    "EX20 ={'region_name':region_name, 'num_lags_obs_RZSM': 9, 'include_lags_obs_pwat_spfh_tmax': False, 'include_reforecast_or_not': True, 'addtl_experiment': True, 'experiment_test':3 }\n",
    "EX21 ={'region_name':region_name, 'num_lags_obs_RZSM': 12, 'include_lags_obs_pwat_spfh_tmax': False, 'include_reforecast_or_not': True, 'addtl_experiment': True, 'experiment_test':4 }\n",
    "\n",
    "#Include only OBS RZSM predictors DO NOT INCLUDE ANY REFORECAST OR PREDICTION\n",
    "EX22 ={'region_name':region_name, 'num_lags_obs_RZSM': 3, 'include_lags_obs_pwat_spfh_tmax': False, 'include_reforecast_or_not': True, 'addtl_experiment': True, 'experiment_test':5 }\n",
    "EX23 ={'region_name':region_name, 'num_lags_obs_RZSM': 6, 'include_lags_obs_pwat_spfh_tmax': False, 'include_reforecast_or_not': True, 'addtl_experiment': True, 'experiment_test':6 }\n",
    "EX24 ={'region_name':region_name, 'num_lags_obs_RZSM': 9, 'include_lags_obs_pwat_spfh_tmax': False, 'include_reforecast_or_not': True, 'addtl_experiment': True, 'experiment_test':7 }\n",
    "EX25 ={'region_name':region_name, 'num_lags_obs_RZSM': 12, 'include_lags_obs_pwat_spfh_tmax': False, 'include_reforecast_or_not': True, 'addtl_experiment': True, 'experiment_test':8 }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cc90eaef-f15d-49e6-8ae1-be3f15b7671b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Include only OBS RZSM predictors, OBS other variables, previous predictions of RZSM, and current reforecast lead\n",
    "\n",
    "EX9 ={'region_name':region_name, 'num_lags_obs_RZSM': 3, 'include_lags_obs_pwat_spfh_tmax': True, 'include_reforecast_or_not': True, 'addtl_experiment': False, 'experiment_test':0 }\n",
    "EX10 ={'region_name':region_name, 'num_lags_obs_RZSM': 6, 'include_lags_obs_pwat_spfh_tmax': True, 'include_reforecast_or_not': True, 'addtl_experiment': False, 'experiment_test':0 }\n",
    "EX11 ={'region_name':region_name, 'num_lags_obs_RZSM': 9, 'include_lags_obs_pwat_spfh_tmax': True, 'include_reforecast_or_not': True, 'addtl_experiment': False, 'experiment_test':0 }\n",
    "EX12 ={'region_name':region_name, 'num_lags_obs_RZSM': 12, 'include_lags_obs_pwat_spfh_tmax': True, 'include_reforecast_or_not': True, 'addtl_experiment': False, 'experiment_test':0 }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d7676e44-292d-4d97-b09b-420e6d82cf4c",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# EX26 ={'region_name':region_name, 'num_lags_obs_RZSM': 3, 'include_lags_obs_pwat_spfh_tmax': True, 'include_reforecast_or_not': True, 'addtl_experiment': False, 'experiment_test':0 }\n",
    "\n",
    "# run_EXPERIMENT(num_lags_obs_RZSM=0,include_lags_obs_pwat_spfh_tmax=False,include_reforecast_or_not=True, addtl_experiment = False, experiment_test = 26)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a82df4c6-6153-4b5e-a9bd-882db0499056",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#This like EX9 and EX10 except now we are adding additional reforecast predictors from week 1 and 2\n",
    "\n",
    "EX27 ={'region_name':region_name, 'num_lags_obs_RZSM': 3, 'include_lags_obs_pwat_spfh_tmax': True, 'include_reforecast_or_not': True, 'addtl_experiment': False, 'experiment_test':1 }\n",
    "EX28 ={'region_name':region_name, 'num_lags_obs_RZSM': 6, 'include_lags_obs_pwat_spfh_tmax': True, 'include_reforecast_or_not': True, 'addtl_experiment': False, 'experiment_test':1 }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "00cb6df8-c287-443a-980e-ff3a166c7459",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def reshape_to_original(file,train_val_test):\n",
    "    if train_val_test == 'train':\n",
    "        return(np.reshape(file,(file.shape[0]//11, file.shape[0]//835, file.shape[1],file.shape[2],file.shape[3])))\n",
    "    else:\n",
    "        return(np.reshape(file,(file.shape[0]//11, file.shape[0]//104, file.shape[1],file.shape[2],file.shape[3])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e1b85443-730e-4efb-8239-4940395e16ba",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def reshape_OBS_to_original(file,train_val_test):\n",
    "    if train_val_test == 'train':\n",
    "        return(np.reshape(file,(file.shape[0]//11, file.shape[0]//835, file.shape[1],file.shape[2])))\n",
    "    else:\n",
    "        return(np.reshape(file,(file.shape[0]//11, file.shape[0]//104, file.shape[1],file.shape[2])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "69a6c155-3732-496c-bb15-aa8e5a75e334",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# def convert_to_dataframe_for_input(training_input,validation_input,testing_input):\n",
    "#     '''This would be needed if we are tyring to compute XGBoost over the entire CONUS'''\n",
    "#     training_input.shape\n",
    "#     #First we want to convert back to the original format (training is 835,11,48,96, N)\n",
    "\n",
    "#     train_out = np.zeros(shape=(835*48*96,training_input.shape[-1]))\n",
    "\n",
    "#     #Training\n",
    "#     row_start = 0\n",
    "#     for date in range(training_input.shape[0]):\n",
    "#         for Y in range(training_input.shape[2]):\n",
    "#             for X in range(training_input.shape[3]):\n",
    "#                 # break\n",
    "#                 data_channels = training_input[date,0,Y,X,:].flatten()\n",
    "#                 train_out[row_start,:] = data_channels\n",
    "#                 row_start +=1\n",
    "\n",
    "#         train_out = np.zeros(shape=(835*48*96,training_input.shape[-1]))\n",
    "\n",
    "#     #Validation\n",
    "#     val_out = np.zeros(shape=(104*48*96,validation_input.shape[-1]))\n",
    "    \n",
    "#     row_start = 0\n",
    "#     for date in range(validation_input.shape[0]):\n",
    "#         for Y in range(validation_input.shape[2]):\n",
    "#             for X in range(validation_input.shape[3]):\n",
    "#                 # break\n",
    "#                 data_channels = validation_input[date,0,Y,X,:].flatten()\n",
    "#                 val_out[row_start,:] = data_channels\n",
    "#                 row_start +=1\n",
    "\n",
    "\n",
    "#     #Validation\n",
    "#     test_out = np.zeros(shape=(104*48*96,testing_input.shape[-1]))\n",
    "    \n",
    "#     row_start = 0\n",
    "#     for date in range(testing_input.shape[0]):\n",
    "#         for Y in range(testing_input.shape[2]):\n",
    "#             for X in range(testing_input.shape[3]):\n",
    "#                 # break\n",
    "#                 data_channels = testing_input[date,0,Y,X,:].flatten()\n",
    "#                 val_out[row_start,:] = data_channels\n",
    "#                 row_start +=1\n",
    "    \n",
    "#     return(train_out,val_out,test_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5ca1475a-b268-432c-add4-3ae911a1e883",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_for_cell(i_Y, i_X, x_train_full, x_val_full, x_test_full, y_train_full, y_val_full, y_test_full, sim_channel_list):\n",
    "\n",
    "    params = {\n",
    "        'objective': 'reg:squarederror',\n",
    "        'eval_metric': 'rmse',\n",
    "        'max_depth': 8,\n",
    "        'eta': 0.1,\n",
    "        'verbosity': 0,  # This silences the printing\n",
    "        'n_jobs': num_cores,\n",
    "    }\n",
    "    \n",
    "    space = {\n",
    "        'max_depth': hp.quniform('max_depth', 4, 10, 1),\n",
    "        'eta': hp.uniform('eta', 0.01, 0.3),\n",
    "        'subsample': hp.uniform('subsample', 0.5, 1),\n",
    "        'colsample_bytree': hp.uniform('colsample_bytree', 0.5, 1),\n",
    "    }\n",
    "        \n",
    "    \n",
    "    # Prepare data slices based on i_Y and i_X\n",
    "    x_train = x_train_full[:, i_Y, i_X, :]\n",
    "    x_val = x_val_full[:, i_Y, i_X, :]\n",
    "    x_test = x_test_full[:, i_Y, i_X, :]\n",
    "    \n",
    "    y_train = y_train_full[:, i_Y, i_X]\n",
    "    y_val = y_val_full[:, i_Y, i_X]\n",
    "    y_test = y_test_full[:, i_Y, i_X]\n",
    "\n",
    "    # Prepare DMatrix objects\n",
    "    dtrain = xgb.DMatrix(x_train, label=y_train)\n",
    "    dval = xgb.DMatrix(x_val, label=y_val)\n",
    "\n",
    "    # Hyperparameter tuning setup\n",
    "    trials = Trials()\n",
    "    best_hyperparams = fmin(fn=lambda params: XGBoost_run(params, dtrain, dval),\n",
    "                            space=space,\n",
    "                            algo=tpe.suggest,\n",
    "                            max_evals=50,\n",
    "                            trials=trials)\n",
    "    best_hyperparams['max_depth'] = int(best_hyperparams.get('max_depth', 6))\n",
    "\n",
    "    # Update model parameters with best_hyperparams\n",
    "    params.update(best_hyperparams)\n",
    "\n",
    "    # Train model with best hyperparameters\n",
    "    bst = xgb.train(params, dtrain, num_boost_round=500, evals=[(dtrain, 'train'), (dval, 'val')],\n",
    "                    early_stopping_rounds=30, verbose_eval=False)\n",
    "\n",
    "    # Make predictions\n",
    "    prediction_output_test = bst.predict(xgb.DMatrix(x_test), iteration_range=(0, bst.best_iteration + 1))\n",
    "    prediction_output_val = bst.predict(xgb.DMatrix(x_val), iteration_range=(0, bst.best_iteration + 1))\n",
    "    prediction_output_train = bst.predict(xgb.DMatrix(x_train), iteration_range=(0, bst.best_iteration + 1))\n",
    "\n",
    "\n",
    "    # Assuming bst is your trained XGBoost model\n",
    "    feature_importance = bst.get_score(importance_type='weight')  # You can also use 'gain' or 'cover'\n",
    "    # print(feature_importance)\n",
    "\n",
    "    #Now replace the feature importance labels with the actual channels\n",
    "    out_dict = {}\n",
    "    for idx,(k,v) in enumerate(feature_importance.items()):\n",
    "        # break\n",
    "        out_dict[sim_channel_list[idx]] = v\n",
    "        \n",
    "    #Now save into a dataset\n",
    "    feature_importance_out = json.dumps(out_dict)\n",
    "    \n",
    "    # Construct result dictionary\n",
    "    results_dict = {\n",
    "        'test_prediction': prediction_output_test,\n",
    "        'validation_prediction': prediction_output_val,\n",
    "        'training_prediction': prediction_output_train,\n",
    "        'i_Y': i_Y,\n",
    "        'i_X': i_X,\n",
    "        'feature_importance':feature_importance_out,\n",
    "        # Add feature importance or other results as needed\n",
    "    }\n",
    "\n",
    "    return results_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4cd2532b-7b5b-418d-9015-9f74b94b4c37",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# def train_model_for_cell(i_Y, i_X):\n",
    "#     # This function would contain the code to train a model for a single grid cell\n",
    "#     # It should return whatever results you need, such as predictions or performance metrics\n",
    "\n",
    "#     #For hyperparameter tuning\n",
    "    # space = {\n",
    "    #     'max_depth': hp.quniform('max_depth', 4, 10, 1),\n",
    "    #     'eta': hp.uniform('eta', 0.01, 0.3),\n",
    "    #     'subsample': hp.uniform('subsample', 0.5, 1),\n",
    "    #     'colsample_bytree': hp.uniform('colsample_bytree', 0.5, 1),\n",
    "    # }\n",
    "    \n",
    "#     # Specify model parameters\n",
    "    # params = {\n",
    "    #     'objective': 'reg:squarederror',\n",
    "    #     'eval_metric': 'rmse',\n",
    "    #     'max_depth': 8,\n",
    "    #     'eta': 0.1,\n",
    "    #     'verbosity': 0,  # This silences the printing\n",
    "    #     'n_jobs': num_cores,\n",
    "    # }\n",
    "#     # Number of boosting rounds (or trees)\n",
    "#     num_boost_round = 500\n",
    "\n",
    "#     x_train = x_train_full[:,i_Y,i_X,:] \n",
    "#     x_val = x_val_full[:,i_Y,i_X,:]\n",
    "#     x_test = x_test_full[:,i_Y,i_X,:]\n",
    "#     x_train.shape\n",
    "\n",
    "#     #For obs\n",
    "#     y_train = y_train_full[:,i_Y,i_X,:]\n",
    "#     y_val = y_val_full[:,i_Y,i_X,:]\n",
    "#     y_test = y_test_full[:,i_Y,i_X,:]\n",
    "\n",
    "#     dtrain = xgb.DMatrix(x_train, label=y_train)\n",
    "#     dval = xgb.DMatrix(x_val, label=y_val)\n",
    "#     # dtest = xgb.DMatrix(x_test, label=y_test)\n",
    "\n",
    "#     trials = Trials()\n",
    "#     best_hyperparams = fmin(fn=XGBoost_run, space=space, algo=tpe.suggest, max_evals=50, trials=trials)\n",
    "#     best_hyperparams['max_depth'] = int(best_hyperparams.get('max_depth', 6))  # Default to 6 if not set\n",
    "\n",
    "#     # Specify model parameters\n",
    "#     params = {\n",
    "#         'objective': 'reg:squarederror',\n",
    "#         'eval_metric': 'rmse',\n",
    "#         'verbosity': 0,  # This silences the printing\n",
    "#         **best_hyperparams,  # Unpack the best hyperparameters here\n",
    "#         'n_jobs': num_cores,\n",
    "#     }\n",
    "    \n",
    "#     # Train model\n",
    "#     bst = xgb.train(params, dtrain, num_boost_round, [(dtrain, 'train'), (dval, 'val')], early_stopping_rounds=30, verbose_eval=False)\n",
    "#     # Make predictions\n",
    "\n",
    "    \n",
    "#     #Make predictions\n",
    "#     prediction_output_test = bst.predict(xgb.DMatrix(x_test),iteration_range=(0, bst.best_iteration + 1))\n",
    "#     prediction_output_val = bst.predict(xgb.DMatrix(x_val),iteration_range=(0, bst.best_iteration + 1))\n",
    "#     prediction_output_train = bst.predict(xgb.DMatrix(x_train),iteration_range=(0, bst.best_iteration + 1))\n",
    "\n",
    "#     # Assuming bst is your trained XGBoost model\n",
    "#     feature_importance = bst.get_score(importance_type='weight')  # You can also use 'gain' or 'cover'\n",
    "#     # print(feature_importance)\n",
    "\n",
    "#     #Now replace the feature importance labels with the actual channels\n",
    "#     out_dict = {}\n",
    "#     for idx,(k,v) in enumerate(feature_importance.items()):\n",
    "#         # break\n",
    "#         out_dict[sim_channel_list[idx]] = v\n",
    "        \n",
    "#     #Now save into a dataset\n",
    "#     feature_importance_out = json.dumps(out_dict)\n",
    "\n",
    "#     results_dict = {\n",
    "#         'test_prediction':prediction_output_test,\n",
    "#         'validation_prediction':prediction_output_val,\n",
    "#         'training_prediction':prediction_output_train,\n",
    "#         'feature_importance':feature_importance_out,\n",
    "#         'i_Y':i_Y,\n",
    "#         'i_X':i_X,\n",
    "#     }\n",
    "\n",
    "#     return(results_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "aff16604-6f7d-42ae-81ef-ea4457a686ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def XGBoost_run(params, dtrain, dval):\n",
    "    # Extract parameters from the params argument\n",
    "    max_depth = int(params['max_depth'])\n",
    "    eta = params['eta']\n",
    "    subsample = params['subsample']\n",
    "    colsample_bytree = params['colsample_bytree']\n",
    "\n",
    "    # Add other fixed parameters here\n",
    "    fixed_params = {\n",
    "        'objective': 'reg:squarederror',\n",
    "        'eval_metric': 'rmse',\n",
    "        'verbosity': 0,\n",
    "    }\n",
    "    \n",
    "    # Combine both fixed and tunable parameters\n",
    "    all_params = {**fixed_params, 'max_depth': max_depth, 'eta': eta, 'subsample': subsample, 'colsample_bytree': colsample_bytree}\n",
    "    \n",
    "    # Initialize variables for storing best scores (or use a more appropriate metric according to your needs)\n",
    "    best_score = float('inf')\n",
    "    \n",
    "    # Assuming training_input, validation_input, etc., are globally available or passed in some other way\n",
    "    # For each grid cell, let's run an XGBoost model\n",
    "\n",
    "    # x_train = bn.nanmean(training_input[:,:,i_Y,i_X,:], axis=1)\n",
    "    # y_train = np.expand_dims(obs_final_train[:,0,i_Y,i_X], -1)\n",
    "    # dtrain = xgb.DMatrix(x_train, label=y_train)\n",
    "    \n",
    "    # # Repeat for validation data\n",
    "    # x_val = bn.nanmean(validation_input[:,:,i_Y,i_X,:], axis=1)\n",
    "    # y_val = np.expand_dims(obs_final_validation[:,0,i_Y,i_X], -1)\n",
    "    # dval = xgb.DMatrix(x_val, label=y_val)\n",
    "\n",
    "    # Train the model\n",
    "    bst = xgb.train(all_params, dtrain, num_boost_round=500, evals=[(dval, 'val')], early_stopping_rounds=30, verbose_eval=False)\n",
    "    \n",
    "    # Update best_score if necessary (here using early stopping's best score)\n",
    "    if bst.best_score < best_score:\n",
    "        best_score = bst.best_score\n",
    "\n",
    "    return {'loss': best_score, 'status': STATUS_OK}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cec62c27-2e6f-4b9e-ba55-35a3619224cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_observations_and_model_inputs_and_RUN(lead, include_reforecast_or_not, num_lags_obs_RZSM, include_lags_obs_pwat_spfh_tmax, addtl_experiment, experiment_test, region_name):\n",
    "\n",
    "        \n",
    "    \n",
    "    day_num = (lead_week * 7) - 1\n",
    "\n",
    "    print('Opening a template dataset to add predictions and feature importance')\n",
    "    global template\n",
    "    template = xr.open_mfdataset(f'{source}/GEFSv12_reforecast/soilw_bgrnd/baseline_RZSM_anomaly/*.n*',combine='nested',concat_dim=['S']).sel(L=[day_num])\n",
    "    temp_out = template.copy(deep=True)\n",
    "    temp_out = temp_out.isel(S=0).expand_dims({'S':1})\n",
    "    \n",
    "    # Assuming obs_RZSM_percentile is an xarray Dataset\n",
    "    if 'feature_importance' not in temp_out:\n",
    "        temp_out['feature_importance'] = xr.DataArray(np.empty(temp_out.RZSM.shape, dtype='object'), dims=template.RZSM.dims)\n",
    "    \n",
    "    del temp_out['RZSM']\n",
    "    \n",
    "    temp_out = temp_out.isel(S=0,M=0,L=0)\n",
    "    \n",
    "    \n",
    "    # print(addtl_experiment)\n",
    "    #Training data\n",
    "    #Needed for calculating the loss for individual UNET predictions (each has 4 predictions for each variable)\n",
    "    def return_training_verification_data(RZSM_or_tmax):\n",
    "        #We had multiple verification inputs in the past, but now we just reduced to RZSM\n",
    "        if RZSM_or_tmax == 'RZSM':\n",
    "            return(np.array(tf.expand_dims(obs_final_train,-1)))\n",
    "\n",
    "    \n",
    "    #Validation data\n",
    "    def return_validation_verification_data(RZSM_or_tmax):\n",
    "        #We had multiple verification inputs in the past, but now we just reduced to RZSM\n",
    "        if RZSM_or_tmax == 'RZSM':\n",
    "            return(np.array(tf.expand_dims(obs_final_validation,-1)))\n",
    "\n",
    "    \n",
    "    \n",
    "    def print_shape(file,name):\n",
    "        print(f'Shape of {name} is {file.shape}')\n",
    "\n",
    "    print('Loading parameters such as experiment name, lag integer list, etc. ')\n",
    "    save_experiment_name, experiment_name_out, experiment_name,lag_integer_list, \\\n",
    "    channel_save_dir, training_input_file, validation_input_file, \\\n",
    "    testing_input_file,checkpoint_filepath, losses_dir,save_checkpoint_dir, \\\n",
    "    save_experiment_dir = return_experiment_name_and_lags_and_channel_dir(include_reforecast_or_not, num_lags_obs_RZSM, include_lags_obs_pwat_spfh_tmax, addtl_experiment, experiment_test, region_name)\n",
    "\n",
    "    print(f'Working on experiment {experiment_name_out}')\n",
    "\n",
    "    with open(f'{channel_save_dir}/{save_experiment_name}_channel_list.txt', 'r') as file:\n",
    "        # Read all lines from the file into a list\n",
    "        channel_list = file.readlines()\n",
    "\n",
    "    global obs_final_train,obs_final_validation,obs_final_testing\n",
    "\n",
    "    obs_final_train,obs_final_validation,obs_final_testing = f.load_verification_observations_updated(lead,verification_directory)\n",
    "\n",
    "    \n",
    "    \n",
    "    obs_final_train = reshape_OBS_to_original(obs_final_train,'train')\n",
    "    obs_final_train.shape\n",
    "    obs_final_validation = reshape_OBS_to_original(obs_final_validation,'validation')\n",
    "    obs_final_validation.shape\n",
    "    obs_final_testing = reshape_OBS_to_original(obs_final_testing,'test')\n",
    "    obs_final_testing.shape\n",
    "    \n",
    "    global training_input,validation_input,testing_input\n",
    "    \n",
    "    training_input = reshape_to_original(np.load(training_input_file),'train')\n",
    "    training_input.shape\n",
    "    validation_input = reshape_to_original(np.load(validation_input_file),'validation')\n",
    "    testing_input = reshape_to_original(np.load(testing_input_file),'testing')\n",
    "\n",
    "    final_prediction_output_test = np.empty(shape=(testing_input.shape[0],testing_input.shape[2],testing_input.shape[3]))\n",
    "    final_prediction_output_test.shape\n",
    "    final_prediction_output_val = np.empty(shape=(validation_input.shape[0],validation_input.shape[2],validation_input.shape[3]))\n",
    "    final_prediction_output_train = np.empty(shape=(training_input.shape[0],training_input.shape[2],training_input.shape[3]))\n",
    "\n",
    "\n",
    "    print('Finalizing the datasets as inputs into the algorithm')\n",
    "\n",
    "    global x_train_full, x_val_full, x_test_full\n",
    "    \n",
    "    x_train_full = bn.nanmean(training_input,axis=1) #We only want the ensemble mean (mainly because the observations are repeated for each ensemble member)\n",
    "    x_val_full = bn.nanmean(validation_input,axis=1)\n",
    "    x_test_full = bn.nanmean(testing_input,axis=1)\n",
    "    x_train_full.shape\n",
    "\n",
    "    #For obs\n",
    "    global y_train_full, y_val_full, y_test_full\n",
    "    \n",
    "    y_train_full =  bn.nanmean(obs_final_train,axis=1)\n",
    "    y_val_full =  bn.nanmean(obs_final_validation,axis=1)\n",
    "    y_test_full =  bn.nanmean(obs_final_testing,axis=1)\n",
    "    \n",
    "    y_train_full = np.expand_dims(y_train_full,-1)\n",
    "    y_train_full.shape\n",
    "    y_val_full = np.expand_dims(y_val_full,-1)\n",
    "    y_test_full = np.expand_dims(y_test_full,-1)\n",
    "    \n",
    "    cell_indices = [(i_Y, i_X) for i_Y in range(training_input.shape[2]) for i_X in range(training_input.shape[3])]\n",
    "\n",
    "    # #small test\n",
    "    # cell_indices = [(i_Y, i_X) for i_Y in range(2) for i_X in range(2)]\n",
    "\n",
    "    global sim_channel_list\n",
    "    sim_channel_list = [i.split('\\n')[0].split('lag ')[-1] for i in channel_list]\n",
    "\n",
    "    print('\\n Starting multiprocessing algorithm.')\n",
    "    # Use a ProcessPoolExecutor to parallelize the training\n",
    "    # with ProcessPoolExecutor(max_workers=num_cores) as executor:\n",
    "    #     futures = [executor.submit(train_model_for_cell, i_Y, i_X) for i_Y, i_X in cell_indices]\n",
    "\n",
    "    with ProcessPoolExecutor(max_workers=num_cores) as executor:\n",
    "        futures = [\n",
    "            executor.submit(\n",
    "                train_model_for_cell, \n",
    "                i_Y, i_X, \n",
    "                x_train_full, x_val_full, x_test_full, \n",
    "                y_train_full, y_val_full, y_test_full, sim_channel_list\n",
    "            ) for i_Y, i_X in cell_indices\n",
    "        ]\n",
    "\n",
    "        # Initialize a counter\n",
    "        completed_count = 0\n",
    "        total_tasks = len(futures)\n",
    "        \n",
    "        # As each future completes, do something with its result\n",
    "        for future in concurrent.futures.as_completed(futures):\n",
    "            # break\n",
    "            result = future.result()\n",
    "\n",
    "            final_prediction_output_test[:,result['i_Y'],result['i_X']] = result['test_prediction']\n",
    "            final_prediction_output_val[:,result['i_Y'],result['i_X']] = result['validation_prediction']\n",
    "            final_prediction_output_train[:,result['i_Y'],result['i_X']] = result['training_prediction']\n",
    "            \n",
    "            temp_out['feature_importance'][result['i_Y'],result['i_X']] = result['feature_importance']\n",
    "            \n",
    "            completed_count += 1\n",
    "            print(f\"Completed {completed_count} out of {total_tasks} tasks.\")\n",
    "    #Now save the final output\n",
    "\n",
    "    train_val_dir = f'predictions_XGBOOST/{region_name}/Wk{lead}_training_validation'\n",
    "    test_dir = f'predictions_XGBOOST/{region_name}/Wk{lead}_testing'\n",
    "\n",
    "    os.system(f'mkdir -p {test_dir} {train_val_dir}')\n",
    "    \n",
    "    # predictions.shape\n",
    "    np.save(f'{test_dir}/Wk{lead}_testing_{experiment_name_out}.npy',final_prediction_output_test)\n",
    "\n",
    "    np.save(f'{train_val_dir}/Wk{lead}_training_{experiment_name_out}.npy',final_prediction_output_train)\n",
    "\n",
    "    np.save(f'{train_val_dir}/Wk{lead}_validation_{experiment_name_out}.npy',final_prediction_output_val)\n",
    "\n",
    "    save_feature_importance = f'xgboost_feature_importance/{region_name}/Wk{lead}'\n",
    "    os.system(f'mkdir -p {save_feature_importance}')\n",
    "\n",
    "    save_name = f'{save_feature_importance}/{experiment_name_out}.nc'\n",
    "    os.system(f'rm {save_name}') #sometimes it won't overwrite\n",
    "    template.to_netcdf(f'{save_name}')\n",
    "\n",
    "    \n",
    "    return(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5b03ba3d-c7da-44b0-88b6-2640278ec02c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def run_model_and_prediction(experiment):\n",
    "    global lead_week\n",
    "    for lead_week in [1,2,3,4,5]:\n",
    "        global lead\n",
    "        lead=lead_week\n",
    "    \n",
    "        generate_model_inputs(region_name=experiment['region_name'], lead = lead_week, num_lags_obs_RZSM=experiment['num_lags_obs_RZSM'],\n",
    "                              include_lags_obs_pwat_spfh_tmax=experiment['include_lags_obs_pwat_spfh_tmax'],include_reforecast_or_not=experiment['include_reforecast_or_not'], \n",
    "                              addtl_experiment = experiment['addtl_experiment'], experiment_test = experiment['experiment_test'])\n",
    "\n",
    "\n",
    "        load_observations_and_model_inputs_and_RUN(region_name=experiment['region_name'], lead = lead_week, num_lags_obs_RZSM=experiment['num_lags_obs_RZSM'],\n",
    "                              include_lags_obs_pwat_spfh_tmax=experiment['include_lags_obs_pwat_spfh_tmax'],include_reforecast_or_not=experiment['include_reforecast_or_not'], \n",
    "                              addtl_experiment = experiment['addtl_experiment'], experiment_test = experiment['experiment_test'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b434237b-0434-4113-81b9-c3a3dc7f86b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# full_list = [EX1,EX2,EX5,EX6,EX9,EX10,EX14,EX15,EX22,EX27,EX28]\n",
    "full_list = [EX28]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38a70df7-3037-4194-8646-556e62a0764d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for experiment in full_list:\n",
    "    run_model_and_prediction(experiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b4dc784-9c8f-402e-a68d-f67fd2fb47cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model_make_11_predictions(experiment):\n",
    "    #test \n",
    "    # experiment = EX28\n",
    "\n",
    "    #First load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f55daf7e-97f1-4d1f-b0cb-825556b224cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for testing\n",
    "lead,lead_week = 1,1\n",
    "experiment=EX10\n",
    "experiment['region_name']\n",
    "lead = lead_week\n",
    "num_lags_obs_RZSM=experiment['num_lags_obs_RZSM']\n",
    "include_lags_obs_pwat_spfh_tmax=experiment['include_lags_obs_pwat_spfh_tmax']\n",
    "include_reforecast_or_not=experiment['include_reforecast_or_not']\n",
    "addtl_experiment = experiment['addtl_experiment']\n",
    "experiment_test = experiment['experiment_test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99cf919b-fec7-4c55-9f1c-36ece3ee4f73",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tf212gpu]",
   "language": "python",
   "name": "conda-env-tf212gpu-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
