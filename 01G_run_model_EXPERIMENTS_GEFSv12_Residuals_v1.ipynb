{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b51fd071-9238-4e03-982e-68dafa29e04f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-02 12:46:47.837949: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-02 12:46:48.655369: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/glade/work/klesinger/conda-envs/tf212gpu_new/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-02 12:46:53.598027: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 30315 MB memory:  -> device: 0, name: Tesla V100-SXM2-32GB, pci bus id: 0000:61:00.0, compute capability: 7.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Mixed precision compatibility check (mixed_float16): OK\n",
      "Your GPU will likely run quickly with dtype policy mixed_float16 as it has compute capability of at least 7.0. Your GPU: Tesla V100-SXM2-32GB, compute capability 7.0\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload \n",
    "%autoreload 2\n",
    "%reload_ext autoreload\n",
    "\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "import datetime as dt\n",
    "from PIL import Image\n",
    "import sys\n",
    "import functions as f\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from keras.models import Model\n",
    "from keras import backend as K\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from IPython.display import Image \n",
    "from tensorflow.python.data.ops import dataset_ops\n",
    "import dask\n",
    "from keras.models import load_model\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from io import StringIO\n",
    "import shap\n",
    "from keras.layers import Input\n",
    "import keras as k\n",
    "from contextlib import redirect_stdout\n",
    "from PIL import Image\n",
    "import matplotlib.gridspec as gridspec\n",
    "import cv2\n",
    "import channelExperiment as CE\n",
    "import loadDataWeek0 as loadData\n",
    "import bottleneck as bn\n",
    "from tensorflow.keras import mixed_precision\n",
    "import csv\n",
    "import addPredictors as pred\n",
    "import loadValues as lv\n",
    "import masks\n",
    "import denseValue\n",
    "import verifications\n",
    "import preprocessUtils as putils\n",
    "import matplotlib.pyplot as plt\n",
    "import losses\n",
    "import modelRzsmReluExtraConvResidual as UNETRzsm\n",
    "\n",
    "global region_name,testing_scenario,save_loss_name\n",
    "region_name = 'CONUS' #['australia','CONUS', 'china']\n",
    "\n",
    "'''Make sure to fill in this information depending on what test we are doing'''\n",
    "make_single_prediction_from_model_for_testing=False\n",
    "make_additional_predictions_from_model_for_testing = False\n",
    "permutation_test_graphs_create=True\n",
    "bias_correction_predict = False\n",
    "\n",
    "#Tensorflow RT things\n",
    "policy = mixed_precision.Policy('mixed_float16')\n",
    "mixed_precision.set_global_policy(policy)\n",
    "tf.config.optimizer.set_jit(True) # Enable XLA.\n",
    "\n",
    "\n",
    "global RZSM_or_Tmax_or_both\n",
    "RZSM_or_Tmax_or_both = 'RZSM' # for getting the predictor from either RZSM and Tmax ('both') or only RZSM ('RZSM')\n",
    "\n",
    "global num_predictions_testing\n",
    "num_predictions_testing = 25\n",
    "\n",
    "global num_train_val_predictions\n",
    "num_train_val_predictions=10\n",
    "\n",
    "#for permutation plot\n",
    "max_RZSM_value,max_tmax_value = 0.05,5\n",
    "\n",
    "#set for the larger memeory ones\n",
    "# os.environ['TF_GPU_ALLOCATOR'] = 'cuda_malloc_async'\n",
    "\n",
    "\n",
    "global ref_source,final_testing_year\n",
    "ref_source = 'GEFSv12'\n",
    "final_testing_year = 2019\n",
    "\n",
    "testing_scenario = 'regularResidual' #['dense', 'regular', 'transformer', 'super_pixel', 'attention', 'denseLarge', 'basic', 'regularResidual']\n",
    "\n",
    "save_loss_name = 'regularResidual'\n",
    "loss_fn = losses.crps2d_tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4638590c-749d-4c6c-85c4-3af63200d242",
   "metadata": {},
   "source": [
    "# Choose different loss and architecture configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c30eb77c-8143-4556-b370-ff75098f35f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "afaa26b2-3d09-43c4-90c2-b3adf94d4126",
   "metadata": {
    "tags": []
   },
   "source": [
    "# This script will load data based on specific lead times that we want to experiment with and what Experiments we choose to run"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fe39e5b-a435-4b47-8272-b0fc8c20c1c8",
   "metadata": {},
   "source": [
    "# Week 1 (lead index 6 of the forecast)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cf62daf-7f99-475f-bc39-5eefe7c31436",
   "metadata": {
    "tags": []
   },
   "source": [
    "| Ex. Number/Name | Obs. RZSM Inputs | Obs. Other Inputs                    | UNET predicted Inputs (N>=2)     |Reforecast Inputs| Prediction Lead Week/Variables | Activation function | Loss function | Batch size |\n",
    "| ----------------| -----------------| ------------------------------------ | -------------------      |--------          | -------------------| ---------------------| ------------------------| ------------|\n",
    "| 0 - EX0         | None             | None                                 | None                     | RZSM, Wk 1-N| Wk N     -  RZSM |              Relu             | CRPS experimental| 66\n",
    "| 1 - EX1         | Wk. lags 1-3    | pwat,spfh,tmax,z200,diff_temp lags 1-3 | RZSM Wk 1-N |        None |  Wk N     -  RZSM |             Relu             | CRPS experimental | 66\n",
    "| 2 - EX2         | Wk. lags 1-6   | pwat,spfh,tmax,z200,diff_temp lags 1-3  | RZSM Wk 1-N          |  None |  Wk N     -  RZSM |       Relu             | CRPS experimental| 66\n",
    "| 3 - EX3         | Wk. lags 1-9    | pwat,spfh,tmax,z200,diff_temp lags 1-3 | RZSM Wk 1-N         |  None |  Wk N     -  RZSM |       Relu             | CRPS experimental| 66\n",
    "| 4 - EX4         | Wk. lags 1-12    | pwat,spfh,tmax,z200,diff_temp lags 1-3| RZSM Wk 1-N         |  None |  Wk N     -  RZSM |      Relu             | CRPS experimental| 66\n",
    "| 5 - EX5         | Wk. lags 1-3   | None                                   | None                   | RZSM, week N | Wk N     -  RZSM  |         Relu             | CRPS experimental| 66\n",
    "| 6 - EX6         | Wk. lags 1-6   | None                                     | None                   |RZSM, week N  | Wk N     -  RZSM  |        Relu             | CRPS experimental| 66\n",
    "| 7 - EX7         | Wk. lags 1-9    | None                                | None                   |RZSM, week N  | Wk N     -  RZSM  |         Relu             | CRPS experimental |66\n",
    "| 8 - EX8         | Wk. lags 1-12    | None                                  | None                   |RZSM, week N  | Wk N     -  RZSM |         Relu             | CRPS experimental | 66\n",
    "| 9 - EX9         | Wk. lags 1-3    |pwat,spfh,tmax,z200,diff_temp lags 1-3  | RZSM Wk 1-N                  |RZSM  week N  | Wk N     -  RZSM  |         Relu             | CRPS experimental| 66\n",
    "| 10 - EX10       | Wk. lags 1-6    |pwat,spfh,tmax,z200,diff_temp  lags 1-3 | RZSM Wk 1-N                  |RZSM  week N  |Wk N     -  RZSM   |         Relu             | CRPS experimental| 66\n",
    "| 11 - EX11       | Wk. lags 1-9    |pwat,spfh,tmax,z200,diff_temp  lags 1-3 | RZSM Wk 1-N                  |RZSM  week N  | Wk N     -  RZSM  |         Relu             | CRPS experimental| 66\n",
    "| 12 - EX12       | Wk. lags 1-12   |pwat,spfh,tmax,z200,diff_temp lags 1-3  | RZSM Wk 1-N                  |RZSM  week N  | Wk N     -  RZSM  |         Relu             | CRPS experimental| 66\n",
    "| 13 - EX13       | None             | None                                 | None                     | RZSM week N| Wk N     -  RZSM |              Relu             | CRPS experimental| 66\n",
    "| 14 - EX14         | Wk. lags 1-3    | pwat,spfh,tmax,z200,diff_temp lags 1-3 | None |        None |  Wk N     -  RZSM |             Relu             | CRPS experimental | 66\n",
    "| 15 - EX15         | Wk. lags 1-6   | pwat,spfh,tmax,z200,diff_temp lags 1-3  | None             |  None |  Wk N     -  RZSM |       Relu             | CRPS experimental| 66\n",
    "| 16 - EX16         | Wk. lags 1-9    | pwat,spfh,tmax,z200,diff_temp lags 1-3 | None            |  None|  Wk N     -  RZSM |       Relu             | CRPS experimental| 66\n",
    "| 17 - EX17        | Wk. lags 1-12    | pwat,spfh,tmax,z200,diff_temp lags 1-3| None            |  None|  Wk N     -  RZSM |      Relu             | CRPS experimental| 66\n",
    "| 18 - EX18         | Wk. lags 1-3   | None                                   | RZSM Wk 1-N                 | RZSM, week N | Wk N     -  RZSM  |         Relu             | CRPS experimental| 66\n",
    "| 19 - EX19         | Wk. lags 1-6   | None                                     | RZSM Wk 1-N                  |RZSM, week N  | Wk N     -  RZSM  |        Relu             | CRPS experimental| 66\n",
    "| 20 - EX20         | Wk. lags 1-9    | None                                | RZSM Wk 1-N                  |RZSM, week N  | Wk N     -  RZSM  |         Relu             | CRPS experimental |66\n",
    "| 21 - EX21         | Wk. lags 1-12    | None                                  | RZSM Wk 1-N                   |RZSM, week N  | Wk N     -  RZSM |         Relu             | CRPS experimental | 66\n",
    "| 22 - EX22         | Wk. lags 1-3   | None                                   | None                   | None | Wk N     -  RZSM  |         Relu             | CRPS experimental| 66\n",
    "| 23 - EX23         | Wk. lags 1-6   | None                                     | None                   |None  | Wk N     -  RZSM  |        Relu             | CRPS experimental| 66\n",
    "| 24 - EX24         | Wk. lags 1-9    | None                                | None                   |None  | Wk N     -  RZSM  |         Relu             | CRPS experimental |66\n",
    "| 25 - EX25         | Wk. lags 1-12    | None                                  | None                   |None  | Wk N     -  RZSM |         Relu             | CRPS experimental | 66\n",
    "| 26 - EX26         | None    | None                                  | None                   |Wk 1-N (choose best models)  | Wk N     -  RZSM |         Relu             | CRPS experimental | 66\n",
    "| 27 - EX27         | Wk. lags 1-3    |pwat,spfh,tmax,z200,diff_temp lags 1-3  |  None                   |Wk1 RZSM,tmax, diff_temp, z200, pwat, spfh  | Wk N     -  RZSM  |         Relu             | CRPS experimental| 66 (like EX9)\n",
    "| 28 - EX28         | Wk. lags 1-6    |pwat,spfh,tmax,z200,diff_temp lags 1-3  |  None                   |Wk1 RZSM,tmax, diff_temp, z200, pwat, spfh  | Wk N     -  RZSM  |         Relu             | CRPS experimental| 66 (like EX10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f3bc1a4-0171-4e83-9601-76c524bbf735",
   "metadata": {
    "tags": []
   },
   "source": [
    "# EX 1-4 - Testing if the prediction of previous week adds value (but don't include the current week that is trying to be predicted). Observation driven but with a prediction.\n",
    "# EX 14-17 - Testing if the prediction of previous week adds value (but don't include the current week that is trying to be predicted). Purely observation driven.\n",
    "# EX 5-8 - Testing if adding other observations (pwat, spfh, etc) has an increase or decrease in skill.\n",
    "# EX 18-21 - Seeing if adding the previous week gains additional skill\n",
    "# EX 22-25 - Purely observation driven. Only soil moisture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1674ec3d-e9f4-415d-84b7-cfcd0a50e0dc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "input_directory = f'Data/model_npy_inputs/{region_name}/Model_input_data' #For inputs into the model\n",
    "verification_directory = f'Data/model_npy_inputs/{region_name}/Verification_data' #For observation verification\n",
    "start_of_forecast_init = '2000-01-05'\n",
    "end_of_forecast_init = '2019-12-25'\n",
    "\n",
    "global training_size_shape\n",
    "training_size_shape = np.array((9185,48,96))\n",
    "\n",
    "global validation_testing_size_shape\n",
    "validation_testing_size_shape = np.array((1144,48,96))\n",
    "\n",
    "'''This decides how many lag weeks we have for data such as pwat, z200, tmax, etc'''\n",
    "global observation_lag_list_not_RZSM\n",
    "#This is for observations pwat, z200, spfh, tmax, diff_temp variables used as predictors\n",
    "#These are the day lags which were already computed as the 7-day rolling mean\n",
    "\n",
    "observation_lag_list_not_RZSM = [-1,-7,-14] \n",
    "\n",
    "global train_start, train_end, val_start, val_end, test_start, test_end\n",
    "train_start = '2000-01-01'\n",
    "train_end = '2015-12-31'\n",
    "\n",
    "val_start = '2016-01-01'\n",
    "val_end = '2017-12-31'\n",
    "\n",
    "test_start = '2018-01-01'\n",
    "test_end = '2019-12-31'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0af35c3-5e81-4ee6-87a6-f80ed1193199",
   "metadata": {},
   "source": [
    "# Only testing EX9 first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c30f7d9a-2690-4223-904a-83158fa830ce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_all_data_EX9_EX10_EX11_EX12_after_week_0(lead, num_lags_obs_RZSM, include_lags_obs_pwat_spfh_tmax, include_reforecast_or_not, \n",
    "                                           observation_lag_list_not_RZSM, lag_integer_list, input_directory,training_size_shape,\n",
    "                                           validation_testing_size_shape,experiment_name,RZSM_or_Tmax_or_both, experiment_test,region_name,experiment_name_out):\n",
    "    '''We need to combine all the RZSM files and all the observation data (pwat, spfh, tmax, diff_temp, z200) into one file. Also adding the RZSM reforecast data from RZSM and Tmax '''\n",
    "\n",
    "    channel_list = []\n",
    "    \n",
    "    #Reforecast predictors\n",
    "    var_list = ['pwat_eatm', 'spfh_2m', 'tmax_2m', 'diff_temp_2m', 'hgt_pres']\n",
    "\n",
    "    if experiment_test == 0:\n",
    "        add_channels = lead  \n",
    "        reforecast_predictors = False\n",
    "    elif (experiment_test >= 1) and (lead in [1,2]):\n",
    "        #This is adding 5 additional predictors (tmax, diff_temp, z200, pwat, spfh)\n",
    "        #Also add the number of channels according to the lead. If lead == 1, then only add lead 1 current week. If lead == 2, add one channel for week 2 and one channel for the prediction from Week 1\n",
    "        add_channels = lead  + len(var_list)\n",
    "        reforecast_predictors = True\n",
    "    elif (experiment_test >= 1) and (lead > 2):\n",
    "        add_channels = lead \n",
    "        reforecast_predictors = False\n",
    "            \n",
    "   \n",
    "    training_input = np.empty(shape = (training_size_shape[0],training_size_shape[1],training_size_shape[2],len(lag_integer_list)+len(var_list)*3+add_channels))\n",
    "    validation_input = np.empty(shape = (validation_testing_size_shape[0],validation_testing_size_shape[1],validation_testing_size_shape[2],len(lag_integer_list)+len(var_list)*3+add_channels))\n",
    "    testing_input = np.empty(shape = (validation_testing_size_shape[0],validation_testing_size_shape[1],validation_testing_size_shape[2],len(lag_integer_list)+len(var_list)*3+add_channels))\n",
    "    \n",
    "    print(f'Training input shape = {training_input.shape}')\n",
    "    \n",
    "    #Add RZSM observations first\n",
    "    for idx,lag in enumerate(lag_integer_list):\n",
    "        channel_list.append(f'RZSM_obs_lag{lag}')\n",
    "        training_input, validation_input, testing_input = pred.add_obs_RZSM_by_lag(training_input, validation_input, testing_input, lag, input_directory, idx, final_testing_year)\n",
    "        \n",
    "    print(f'Index idx value is {idx}. Done adding RZSM obs.')    \n",
    "    \n",
    "    RZSM_train_obs, RZSM_validation_obs = pred.return_masking_objects_for_RZSM(input_directory, final_testing_year)\n",
    "\n",
    "    for variable in var_list:\n",
    "        channel_name_output = pred.return_channel_name(variable)\n",
    "        for lag in observation_lag_list_not_RZSM:\n",
    "            channel_list.append(f'{channel_name_output}_obs_lag{lag}')\n",
    "            idx+=1\n",
    "            #Observations adding\n",
    "            training_input, validation_input, testing_input = pred.add_obs_other_observations_by_lag(training_input, validation_input, testing_input, lag, input_directory, variable, idx,final_testing_year)\n",
    " \n",
    "    \n",
    "        print(f'Index idx value is {idx}. Done adding {variable} obs.')\n",
    "    \n",
    "    ############################### NOW ADD THE PREDICTION DATA FROM PREVIOUS WEEK ################################################\n",
    "    #Now we need to load our data from the previous weeks \n",
    "    \n",
    "    if lead in [0, 1]:\n",
    "        #DO NOT INCLUDE LEAD 0 AS A PREDICTOR (FROM PREVIOUS WEEK)\n",
    "        pass\n",
    "    else:\n",
    "\n",
    "        for lead_previous in range(1,lead):\n",
    "            # break\n",
    "            print(f'Adding previous RZSM prediction from week {lead_previous} as an input channel')\n",
    "            # break\n",
    "            \n",
    "            pred_dir = f'predictions/{region_name}/Wk{lead_previous}_training_validation'\n",
    "            testing_dir = f'predictions/{region_name}/Wk{lead_previous}_testing'\n",
    "            \n",
    "            os.system(f'mkdir -p {pred_dir}')\n",
    "            \n",
    "            training_prediction_name= f'{pred_dir}/Wk{lead_previous}_training_{experiment_name_out}.npy'\n",
    "            validation_prediction_name = f'{pred_dir}/Wk{lead_previous}_validation_{experiment_name_out}.npy'\n",
    "            testing_prediction_name = f'{testing_dir}/Wk{lead_previous}_testing_{experiment_name_out}.npy'\n",
    "            \n",
    "            testing_prediction = np.load(testing_prediction_name)\n",
    "            \n",
    "            '''Load the training and validation predictions if they exist'''\n",
    "            if os.path.exists(training_prediction_name):\n",
    "                print(f'Loading data from previous week lead {lead_previous}')\n",
    "                training_prediction = np.load(training_prediction_name)\n",
    "                validation_prediction =np.load(validation_prediction_name)\n",
    "                \n",
    "            else:\n",
    "                print(f'Creating prediction data from previous week lead {lead_previous}')\n",
    "                '''If they don't exist..... load model for previous week'''\n",
    "                model = load_model(f'checkpoints/Wk_{lead_previous}/Wk{lead_previous}_{experiment_name_out}',compile=False) #don't need the custom loss function for predictions\n",
    "                \n",
    "                training_input_previous = np.load(f'Data/model_npy_inputs/{region_name}/Wk{lead_previous}_EX_input_data/{experiment_name_out}_training_input.npy')\n",
    "                validation_input_previous = np.load(f'Data/model_npy_inputs/{region_name}/Wk{lead_previous}_EX_input_data/{experiment_name_out}_validation_input.npy')\n",
    "                testing_input_previous = np.load(f'Data/model_npy_inputs/{region_name}/Wk{lead_previous}_EX_input_data/{experiment_name_out}_testing_input.npy')\n",
    "                \n",
    "                '''Make predictions and save data to load for previous use'''\n",
    "                training_prediction = model.predict(training_input_previous) #Just for unit checking\n",
    "                np.save(training_prediction_name,training_prediction)\n",
    "                \n",
    "                validation_prediction = model.predict(validation_input_previous)\n",
    "                np.save(validation_prediction_name,validation_prediction)\n",
    "\n",
    "            train_RZSM = training_prediction\n",
    "            val_RZSM = validation_prediction\n",
    "            test_RZSM = testing_prediction\n",
    "\n",
    "            #Now add back to the data\n",
    "            '''Now add back to the newly created dataset'''\n",
    "            idx+=1\n",
    "            channel_list.append(f'RZSM_prediction_lead{lead_previous}')\n",
    "            print(f'Adding RZSM training, validation, testing into index {idx}')\n",
    "            training_input[:,:,:,idx] = train_RZSM[:,:,:,0]\n",
    "            validation_input[:,:,:,idx] = val_RZSM[:,:,:,0]\n",
    "            testing_input[:,:,:,idx] = test_RZSM[:,:,:,0]\n",
    "\n",
    "\n",
    "    #Add final predictor for the current week of RZSM within reforecast\n",
    "    idx+=1\n",
    "    soil_var = 'soilw_bgrnd'\n",
    "    channel_name_output = pred.return_channel_name(soil_var)\n",
    "    channel_list.append(f'{channel_name_output}_ref_lead{lead}')\n",
    "\n",
    "    print(f'And finally adding RZSM week {lead} from reforecast as a predictor')\n",
    "    \n",
    "    training_input, validation_input, testing_input = pred.add_reforecast_by_lag(training_input, validation_input, testing_input, lead, input_directory,soil_var, idx, ref_source, final_testing_year)\n",
    "\n",
    "    print(f'Index idx value is {idx}. Done adding {soil_var} reforecast.')\n",
    "\n",
    "    print('Final channel of input is the following (just make sure it has zeros for RZSM)')\n",
    "    print(training_input[0,:,:,-1])\n",
    "\n",
    "    return(training_input, validation_input, testing_input,channel_list)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "705e8a43-188b-46c5-a45f-02a2637c28c8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def make_UNET_stacked_inputs(lead, num_lags_obs_RZSM, include_lags_obs_pwat_spfh_tmax, include_reforecast_or_not, \n",
    "                             observation_lag_list_not_RZSM, lag_integer_list, input_directory,training_size_shape,\n",
    "                             validation_testing_size_shape,experiment_name,RZSM_or_Tmax_or_both,addtl_experiment,experiment_test,region_name,experiment_name_out):\n",
    "    \n",
    "\n",
    "    \n",
    "    ############################################### EXPERIMENTS 9-12 ####################################################################################\n",
    "    if (experiment_name == 'EX9') or (experiment_name == 'EX10') or (experiment_name == 'EX11') or (experiment_name == 'EX12') or (experiment_name == 'EX27') or (experiment_name == 'EX28'):\n",
    "        \n",
    "        print(f'\\nWorking on setting up data for Experiment {experiment_name} for lead {lead}\\n')\n",
    "\n",
    "        if lead == 0:\n",
    "            final_input_train, final_input_validation, final_input_testing,channel_list = loadData.load_all_data_EX9_EX10_EX11_EX12(lead, num_lags_obs_RZSM, include_lags_obs_pwat_spfh_tmax, \n",
    "                                                                                                              include_reforecast_or_not, observation_lag_list_not_RZSM, lag_integer_list, \n",
    "                                                                                                              input_directory,training_size_shape,validation_testing_size_shape,RZSM_or_Tmax_or_both, \n",
    "                                                                                                                                    experiment_test = experiment_test,\n",
    "                                                                                                                                   region_name=region_name)\n",
    "        else:\n",
    "            final_input_train, final_input_validation, final_input_testing,channel_list = load_all_data_EX9_EX10_EX11_EX12_after_week_0(lead, num_lags_obs_RZSM, include_lags_obs_pwat_spfh_tmax, include_reforecast_or_not, \n",
    "                                                                                                       observation_lag_list_not_RZSM, lag_integer_list, input_directory,training_size_shape,\n",
    "                                                                                                   validation_testing_size_shape,experiment_name,RZSM_or_Tmax_or_both,\n",
    "                                                                                                                                       experiment_test = experiment_test,\n",
    "                                                                                                                                       region_name = region_name,experiment_name_out=experiment_name_out)\n",
    "\n",
    "    return (final_input_train,final_input_validation,final_input_testing,channel_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "84042a9e-5635-447c-a16a-679fcbd7624a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#To try and save on memory, only load certain files at a time\n",
    "def return_only_train_validation(lead, num_lags_obs_RZSM, include_lags_obs_pwat_spfh_tmax, include_reforecast_or_not, \n",
    "                                 observation_lag_list_not_RZSM, lag_integer_list, input_directory,training_size_shape,\n",
    "                                 validation_testing_size_shape,experiment_name):\n",
    "    \n",
    "    reforecast_train_input, reforecast_validation_input, reforecast_testing_input,channel_list \\\n",
    "    = make_UNET_stacked_inputs(lead, num_lags_obs_RZSM, include_lags_obs_pwat_spfh_tmax, \n",
    "                               include_reforecast_or_not, observation_lag_list_not_RZSM, \n",
    "                               lag_integer_list, input_directory,training_size_shape,validation_testing_size_shape,experiment_name,region_name)\n",
    "\n",
    "    return(reforecast_train_input, reforecast_validation_input,reforecast_testing_input,channel_list)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def return_testing_data_model_training(lead, num_lags_obs_RZSM, include_lags_obs_pwat_spfh_tmax, \n",
    "                               include_reforecast_or_not, observation_lag_list_not_RZSM, \n",
    "                               lag_integer_list, input_directory,training_size_shape,validation_testing_size_shape,experiment_name):\n",
    "\n",
    "    reforecast_train_input, reforecast_validation_input, reforecast_testing_input,channel_list = make_UNET_stacked_inputs(lead, num_lags_obs_RZSM, include_lags_obs_pwat_spfh_tmax, \n",
    "                               include_reforecast_or_not, observation_lag_list_not_RZSM, \n",
    "                               lag_integer_list, input_directory,training_size_shape,validation_testing_size_shape,experiment_name,region_name)\n",
    "    return(reforecast_testing_input,channel_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f023cfa8-d5b4-4bc2-8031-d4d71d939e39",
   "metadata": {},
   "source": [
    "# Load Data files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b606d2ec-7c9c-46a8-96df-1810e8c991b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Testing\n",
    "# region_name=region_name\n",
    "# lead = lead_week\n",
    "# num_lags_obs_RZSM=3\n",
    "# include_lags_obs_pwat_spfh_tmax=True\n",
    "# include_reforecast_or_not=True\n",
    "# addtl_experiment = False\n",
    "# experiment_test = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "08e37a45-e7c7-4e62-b3cf-31ef129dbb24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_experiment_name_and_lags_and_channel_dir(include_reforecast_or_not, num_lags_obs_RZSM, include_lags_obs_pwat_spfh_tmax, addtl_experiment, experiment_test, region_name):\n",
    "    \n",
    "    experiment_name = CE.return_experiment_name(include_reforecast_or_not,num_lags_obs_RZSM,include_lags_obs_pwat_spfh_tmax,addtl_experiment,experiment_test)\n",
    "\n",
    "    save_experiment_name = f'{experiment_name}_{save_loss_name}_RZSM'\n",
    "    experiment_name_out =  save_experiment_name\n",
    "    \n",
    "    global lag_integer_list\n",
    "    lag_integer_list =  CE.return_num_day_lags_from_weekly_lags(num_lags_obs_RZSM) #For number of RZSM observation lags\n",
    "\n",
    "    #Where to save channel information\n",
    "    save_experiment_dir = f'Data/model_npy_inputs/{region_name}/Wk{lead}_EX_input_data'\n",
    "    \n",
    "    channel_save_dir = f'channel_list_information/Wk{lead}'\n",
    "    \n",
    "    checkpoint_filepath = f'checkpoints/{region_name}/Wk{lead}/Wk{lead}_{experiment_name_out}'\n",
    "    \n",
    "    losses_dir = f'Losses_with_OBS/{region_name}/Wk{lead}'\n",
    "    \n",
    "    save_checkpoint_dir =f'checkpoints/{region_name}/Wk{lead}'\n",
    "    \n",
    "    os.system(f'mkdir -p {checkpoint_filepath} {channel_save_dir} {save_experiment_dir} {losses_dir} {save_checkpoint_dir}')\n",
    "\n",
    "    \n",
    "    #Set up files for either saving or loading\n",
    "    training_input_file = f'{save_experiment_dir}/{save_experiment_name}_training_input.npy'\n",
    "    validation_input_file = f'{save_experiment_dir}/{save_experiment_name}_validation_input.npy'\n",
    "    testing_input_file = f'{save_experiment_dir}/{save_experiment_name}_testing_input.npy'\n",
    "\n",
    "    \n",
    "    return(save_experiment_name,experiment_name_out,experiment_name,lag_integer_list,channel_save_dir,\n",
    "           training_input_file,validation_input_file,testing_input_file,checkpoint_filepath,\n",
    "          losses_dir,save_checkpoint_dir,save_experiment_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "93274b84-b5c7-4103-9412-2dd052ae1c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_model_inputs(region_name,lead,include_reforecast_or_not,num_lags_obs_RZSM,include_lags_obs_pwat_spfh_tmax,addtl_experiment,experiment_test):\n",
    "\n",
    "    save_experiment_name, experiment_name_out, experiment_name,lag_integer_list, \\\n",
    "    channel_save_dir, training_input_file, validation_input_file, \\\n",
    "    testing_input_file,checkpoint_filepath, losses_dir,save_checkpoint_dir, \\\n",
    "    save_experiment_dir = return_experiment_name_and_lags_and_channel_dir(include_reforecast_or_not, num_lags_obs_RZSM, include_lags_obs_pwat_spfh_tmax, addtl_experiment, experiment_test, region_name)\n",
    "\n",
    "    if os.path.exists(training_input_file) and os.path.exists(validation_input_file) and os.path.exists(testing_input_file):\n",
    "        pass\n",
    "    else:\n",
    "        reforecast_train_input, reforecast_validation_input, reforecast_testing_input, channel_list \\\n",
    "        = make_UNET_stacked_inputs(lead, num_lags_obs_RZSM, include_lags_obs_pwat_spfh_tmax, include_reforecast_or_not, \n",
    "                             observation_lag_list_not_RZSM, lag_integer_list, input_directory,training_size_shape,\n",
    "                             validation_testing_size_shape,experiment_name,RZSM_or_Tmax_or_both,addtl_experiment,experiment_test,region_name,experiment_name_out)\n",
    "    \n",
    "        #Save data to file\n",
    "        np.save(training_input_file,tf.convert_to_tensor(reforecast_train_input,dtype=tf.float32))\n",
    "        np.save(validation_input_file,tf.convert_to_tensor(reforecast_validation_input,dtype=tf.float32))\n",
    "        np.save(testing_input_file,tf.convert_to_tensor(reforecast_testing_input,dtype=tf.float32))\n",
    "        \n",
    "        image_size = reforecast_train_input.shape[1:]           \n",
    "        #Save channel list information to txt file\n",
    "    \n",
    "        with open(f'{channel_save_dir}/{save_experiment_name}_channel_list.txt', 'w') as file:\n",
    "            for idx,element in enumerate(channel_list):\n",
    "                if '-' in element:\n",
    "                    source_='OBSERVATIONS'\n",
    "                else:\n",
    "                    source_='REFORECAST'\n",
    "    \n",
    "                file.write(f'Channel_{idx} is from {source_} with lead or lag {str(element)}' + '\\n')\n",
    "\n",
    "    return(f'Completed writing lead {lead} model input data to {save_experiment_dir}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b1cc6fa0-f9ae-4c0a-89db-5bbb73ddff50",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train(epochs, batch_size, lead, initial_learning_rate, beta_1,shuffle,patience, kernel_norm,deep_supervision,\n",
    "         num_lags_obs_RZSM,include_lags_obs_pwat_spfh_tmax,include_reforecast_or_not,\n",
    "          number_of_UNET_backbone_max_pool,permutation_test,make_additional_predictions_from_model_for_testing,\n",
    "         input_directory,training_size_shape,validation_testing_size_shape,addtl_experiment,experiment_test,region_name):\n",
    "    \n",
    "#For testing\n",
    "# lead=1\n",
    "# num_lags_obs_RZSM = 3\n",
    "# include_lags_obs_pwat_spfh_tmax = True\n",
    "# include_reforecast_or_not=True\n",
    "# deep_supervision = True\n",
    "# initial_learning_rate = 0.0001\n",
    "# beta_1 = 0.9\n",
    "# batch_size=66\n",
    "# epochs=1\n",
    "# shuffle=False\n",
    "# kernel_norm =  None\n",
    "# patience=10\n",
    "# permutation_test = False\n",
    "    \n",
    "    # print(addtl_experiment)\n",
    "    #Training data\n",
    "    #Needed for calculating the loss for individual UNET predictions (each has 4 predictions for each variable)\n",
    "    def return_training_verification_data(RZSM_or_tmax):\n",
    "        #We had multiple verification inputs in the past, but now we just reduced to RZSM\n",
    "        if RZSM_or_tmax == 'RZSM':\n",
    "            return(np.array(tf.expand_dims(obs_final_train,-1)))\n",
    "\n",
    "    \n",
    "    #Validation data\n",
    "    def return_validation_verification_data(RZSM_or_tmax):\n",
    "        #We had multiple verification inputs in the past, but now we just reduced to RZSM\n",
    "        if RZSM_or_tmax == 'RZSM':\n",
    "            return(np.array(tf.expand_dims(obs_final_validation,-1)))\n",
    "\n",
    "    \n",
    "    \n",
    "    def print_shape(file,name):\n",
    "        print(f'Shape of {name} is {file.shape}')\n",
    "        \n",
    "    save_experiment_name, experiment_name_out, experiment_name,lag_integer_list, \\\n",
    "    channel_save_dir, training_input_file, validation_input_file, \\\n",
    "    testing_input_file,checkpoint_filepath, losses_dir,save_checkpoint_dir, \\\n",
    "    save_experiment_dir = return_experiment_name_and_lags_and_channel_dir(include_reforecast_or_not, num_lags_obs_RZSM, include_lags_obs_pwat_spfh_tmax, addtl_experiment, experiment_test, region_name)\n",
    "\n",
    "    obs_final_train,obs_final_validation,obs_final_testing = f.load_verification_observations_residuals(lead,verification_directory)\n",
    "    \n",
    "\n",
    "    print('Loading previously created data')\n",
    "\n",
    "    reforecast_train_input_tensor = tf.data.Dataset.from_tensor_slices(({'input_image':np.load(training_input_file)},\n",
    "                                                                        {'RZSM_output_1': return_training_verification_data('RZSM'), 'RZSM_output_2': return_training_verification_data('RZSM'), }))\n",
    "    reforecast_validation_input_tensor = tf.data.Dataset.from_tensor_slices(({'input_image':np.load(validation_input_file)},\n",
    "                                                                        {'RZSM_output_1': return_validation_verification_data('RZSM'), 'RZSM_output_2': return_validation_verification_data('RZSM'),}))\n",
    "\n",
    "    image_size = np.array(list(reforecast_train_input_tensor.element_spec)[0]['input_image'].shape)\n",
    " \n",
    "\n",
    "    with open(f'{channel_save_dir}/{save_experiment_name}_channel_list.txt', 'r') as file:\n",
    "        # Read all lines from the file into a list\n",
    "        channel_list = file.readlines()\n",
    "\n",
    "    # print_shape(reforecast_train_input,'Training input')\n",
    "    # print_shape(reforecast_validation_input,'Validation input')\n",
    "    # print_shape(reforecast_testing_input,'Testing input')\n",
    "    # print_shape(obs_final_train,'Observation verification training')\n",
    "    # print_shape(obs_final_validation,'Observation verification validation')\n",
    "    # print_shape(obs_final_testing,'Observation verification testing')\n",
    "    \n",
    "\n",
    "    print('Actual channel order list')\n",
    "    print(channel_list)\n",
    "\n",
    "    inputs = Input(shape=image_size, name='input_image')\n",
    "    \n",
    "    print('\\nCompiling model\\n')\n",
    "\n",
    "    build_model = UNETRzsm.model_build_func(inputs=inputs, output_channels=1, \n",
    "                           using_deep_supervision=deep_supervision, \n",
    "                           kernel_norm = kernel_norm , var_name='RZSM',\n",
    "                          number_of_UNET_backbone_max_pool = number_of_UNET_backbone_max_pool)\n",
    "    model = Model(inputs=inputs,\n",
    "             outputs = build_model,\n",
    "             name=\"UNET_RZSM\")\n",
    "\n",
    "\n",
    "    model.compile(loss= {'RZSM_output_1':loss_fn, 'RZSM_output_2':loss_fn},\n",
    "              metrics = 'mae', optimizer = k.optimizers.Adam(learning_rate=initial_learning_rate, beta_1=beta_1),run_eagerly=True)\n",
    "\n",
    "    '''For some reason I can't save anymore to my home space, so let's just move it to scratch'''\n",
    "\n",
    "    checkpoint_filepath_out = f'/glade/derecho/scratch/klesinger/{checkpoint_filepath}'\n",
    "    save_checkpoint_dir_out = f'/glade/derecho/scratch/klesinger/{save_checkpoint_dir}'\n",
    "\n",
    "    os.system(f'rm {checkpoint_filepath} -r') #must do this so that we can make a soft link\n",
    "    os.system(f'mkdir -p {save_checkpoint_dir_out} {save_checkpoint_dir}')\n",
    "    \n",
    "    model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath_out,\n",
    "    save_weights_only=True,\n",
    "    mode='min',\n",
    "    save_best_only=True)\n",
    "    \n",
    "    rlrop = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=5)\n",
    "    \n",
    "    my_callbacks = [tf.keras.callbacks.EarlyStopping(patience=patience),model_checkpoint_callback, rlrop] \n",
    "    \n",
    "    unet_history=model.fit(\n",
    "        x=reforecast_train_input_tensor.batch(batch_size), \n",
    "        batch_size=batch_size, epochs=epochs, initial_epoch=0, shuffle=shuffle, callbacks=my_callbacks, \\\n",
    "        validation_data=reforecast_validation_input_tensor.batch(batch_size))\n",
    "\n",
    "    loss_out_df = pd.DataFrame(unet_history.history)\n",
    "    loss_out_df.to_csv(f'{losses_dir}/Wk{lead}_{experiment_name_out}')\n",
    "\n",
    "\n",
    "    ########### MODEL CHECKPOINTS ############################\n",
    "\n",
    "    model.save(f'/glade/work/klesinger/FD_RZSM_deep_learning/{save_checkpoint_dir}/Wk{lead}_{experiment_name_out}')\n",
    "\n",
    "    #If saving to a scratch location\n",
    "    # model.save(f'{save_checkpoint_dir_out}/Wk{lead}_{experiment_name_out}')\n",
    "    # os.system(f'ln -s {save_checkpoint_dir_out}/Wk{lead}_{experiment_name_out} /glade/work/klesinger/FD_RZSM_deep_learning/{save_checkpoint_dir}/Wk{lead}_{experiment_name_out}')\n",
    "              \n",
    "    return(0)\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "26c37ba1-26be-47ea-b851-417c89a79bc2",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # #Testing for model runs\n",
    "# permutation_test=False\n",
    "# lead=1\n",
    "# num_lags_obs_RZSM =3\n",
    "# include_lags_obs_pwat_spfh_tmax = True\n",
    "# include_reforecast_or_not=True\n",
    "# deep_supervision = True\n",
    "# initial_learning_rate = 0.0001\n",
    "# beta_1 = 0.9\n",
    "# batch_size=66\n",
    "# epochs=1\n",
    "# shuffle=False\n",
    "# kernel_norm =  None\n",
    "# patience=10\n",
    "# number_of_UNET_backbone_max_pool=4\n",
    "# make_additional_predictions_from_model_for_testing=False\n",
    "# addtl_experiment = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2076b03f-80ee-49ad-b256-3450efcd55df",
   "metadata": {},
   "source": [
    "# Run the model for each experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ddec9e60-e784-4dd7-88e9-d3c2aa086c60",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "'''For experiments, you need to run the script once to make the data. Then restart the kernel to load the data. \n",
    "Otherwise the memory leaks are too high'''\n",
    "def run_EXPERIMENT(lead, num_lags_obs_RZSM,include_lags_obs_pwat_spfh_tmax ,include_reforecast_or_not,addtl_experiment,experiment_test,region_name):\n",
    "    if lead_week == 5:\n",
    "        patience=15\n",
    "    else:\n",
    "        patience = 10\n",
    "\n",
    "    #Options for num_lags_obs_RZSM weekly lags [ 3,6,9,12 ] ** this inc\n",
    "    #Options for num_lags_obs_pwat_spfh_tmax weekly lags [0 weeks or 2 weeks ]\n",
    "\n",
    "    train(epochs = 300, \n",
    "          batch_size = 66, \n",
    "          lead=lead_week, \n",
    "          initial_learning_rate=0.0001,\n",
    "          beta_1 = 0.9,\n",
    "          shuffle=False,\n",
    "          patience=patience,\n",
    "          kernel_norm = None,\n",
    "          deep_supervision = True,\n",
    "          num_lags_obs_RZSM=num_lags_obs_RZSM, \n",
    "          include_lags_obs_pwat_spfh_tmax=include_lags_obs_pwat_spfh_tmax,\n",
    "          include_reforecast_or_not=include_reforecast_or_not,\n",
    "          number_of_UNET_backbone_max_pool=4,\n",
    "          permutation_test = False,\n",
    "          make_additional_predictions_from_model_for_testing = False,\n",
    "          input_directory=input_directory,\n",
    "          training_size_shape=training_size_shape,\n",
    "          validation_testing_size_shape=validation_testing_size_shape,\n",
    "          addtl_experiment = addtl_experiment,\n",
    "          experiment_test =experiment_test,\n",
    "          region_name = region_name)\n",
    "    return(0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "265b844f-a2ea-4ae5-b1e3-a269cd0867cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reverse_min_max_scaling(file,region_name,lead,final_testing_year):\n",
    "    if final_testing_year == 2012:\n",
    "        add_ = f\"_{test_year}\"\n",
    "    elif final_testing_year == 2019:\n",
    "        add_ = \"\"\n",
    "\n",
    "    source = 'GEFSv12'\n",
    "    max_min_source = f'Data/min_max_values/{region_name}'\n",
    "    \n",
    "    max_, min_ = np.load(f'{max_min_source}/residual_{source}_lead{lead}_max{add_}.npy'), np.load(f'{max_min_source}/residual_{source}_lead{lead}_min{add_}.npy')\n",
    "    return(file *(max_-min_)+min_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a0cb1309-91f7-4ce8-bc2b-f4a3432913b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_single_predictions_testing(lead, include_reforecast_or_not, num_lags_obs_RZSM, include_lags_obs_pwat_spfh_tmax,addtl_experiment,experiment_test, region_name, test):\n",
    "    \n",
    "    save_experiment_name, experiment_name_out, experiment_name,lag_integer_list, \\\n",
    "    channel_save_dir, training_input_file, validation_input_file, \\\n",
    "    testing_input_file,checkpoint_filepath, losses_dir,save_checkpoint_dir, \\\n",
    "    save_experiment_dir = return_experiment_name_and_lags_and_channel_dir(include_reforecast_or_not, num_lags_obs_RZSM, include_lags_obs_pwat_spfh_tmax, addtl_experiment, experiment_test, region_name)\n",
    "\n",
    "    print(f'Testing input file is: {testing_input_file}')\n",
    "    ########### MAKE PREDICTIONS ON TRAINING, TESTING, VALIDATION SET ############################\n",
    "    # model = load_model(f'checkpoints/Wk_{lead}/Wk{lead}_{experiment_name_out}',compile=False)\n",
    "\n",
    "    print(f'Starting single prediction for Experiment {experiment_name_out}')\n",
    "\n",
    "    day_num = (lead*7) - 1\n",
    "\n",
    "    \n",
    "    try:\n",
    "        model = load_model(checkpoint_filepath,compile=False) #don't need the custom loss function for predictions\n",
    "        \n",
    "        #Load data\n",
    "        reforecast_testing_input = np.load(testing_input_file)\n",
    "        \n",
    "        ########### SAVE PREDICTIONS (SINGLE PREDICTIONS) ############################\n",
    "        test_dir = f'predictions/{region_name}/Wk{lead}_testing'\n",
    "    \n",
    "        os.system(f'mkdir -p {test_dir}')\n",
    "    \n",
    "        mask = masks.load_mask(region_name)\n",
    "        mask = mask.transpose('Y','X','S')\n",
    "    \n",
    "        print('\\nCurrently only predicting the test dataset\\n')\n",
    "        predictions = model.predict(reforecast_testing_input)\n",
    "\n",
    "        #Only grab the last channel\n",
    "        predictions = np.array(predictions)[-1,:,:,:,:] #this is in min max format\n",
    "        \n",
    "        \n",
    "        #Convert back prior to min max\n",
    "        residuals = reverse_min_max_scaling(predictions,region_name,day_num,final_testing_year)\n",
    "        residuals = np.where(mask['NCA-LDAS_mask'] == 1,residuals,0)\n",
    "        # residuals.max()\n",
    "        # residuals.min()\n",
    "        \n",
    "        #Convert original forecasts back prior to min max. This is the anomaly of the observation.\n",
    "        original = reverse_min_max_scaling(np.expand_dims(test,-1),region_name,day_num,final_testing_year)\n",
    "        original = np.where(mask['NCA-LDAS_mask'] == 1,original,0)\n",
    "    \n",
    "        '''Add residuals to original datasets min max'''\n",
    "        test_out = residuals - original\n",
    "        test_out = np.where(original == 0, 0, test_out)\n",
    "        # predictions.shape\n",
    "        np.save(f'{test_dir}/Wk{lead}_testing_{experiment_name_out}.npy',test_out)\n",
    "    except NameError:\n",
    "        print('Error loading model')\n",
    "        pass\n",
    "    except OSError:\n",
    "        print('Error loading model')\n",
    "        pass\n",
    "    \n",
    "    return(f'Completed Experiment {experiment_name_out}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b43bdde2-35f0-411e-8565-887afdb79625",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def make_single_predictions_training_validation(lead, include_reforecast_or_not, num_lags_obs_RZSM, include_lags_obs_pwat_spfh_tmax,addtl_experiment,experiment_test, region_name, train, val):\n",
    "    \n",
    "    save_experiment_name, experiment_name_out, experiment_name,lag_integer_list, \\\n",
    "    channel_save_dir, training_input_file, validation_input_file, \\\n",
    "    testing_input_file,checkpoint_filepath, losses_dir,save_checkpoint_dir, \\\n",
    "    save_experiment_dir = return_experiment_name_and_lags_and_channel_dir(include_reforecast_or_not, num_lags_obs_RZSM, include_lags_obs_pwat_spfh_tmax, addtl_experiment, experiment_test, region_name)\n",
    "\n",
    "    ########### MAKE PREDICTIONS ON TRAINING, TESTING, VALIDATION SET ############################\n",
    "    # model = load_model(f'checkpoints/Wk_{lead}/Wk{lead}_{experiment_name_out}',compile=False)\n",
    "\n",
    "    print(f'Starting single prediction for Experiment {experiment_name_out}')\n",
    "       \n",
    "    model = load_model(checkpoint_filepath,compile=False) #don't need the custom loss function for predictions\n",
    "    \n",
    "    #Load data\n",
    "    reforecast_training_input = np.load(training_input_file)\n",
    "    reforecast_validation_input = np.load(validation_input_file)\n",
    "\n",
    "    day_num = (lead*7) - 1\n",
    "    \n",
    "    ########### SAVE PREDICTIONS (SINGLE PREDICTIONS) ############################\n",
    "    train_val_dir = f'predictions/{region_name}/Wk{lead}_training_validation'\n",
    "\n",
    "    os.system(f'mkdir -p {train_val_dir}')\n",
    "\n",
    "    mask = masks.load_mask(region_name)\n",
    "    mask = mask.transpose('Y','X','S')\n",
    "\n",
    "    print('\\nPredicting training and validation input')\n",
    "    predictions = model.predict(reforecast_training_input)\n",
    "    #Only grab the last channel\n",
    "    predictions = np.array(predictions)[-1,:,:,:,:]\n",
    "\n",
    "    #Convert original forecasts back prior to min max\n",
    "    original = reverse_min_max_scaling(np.expand_dims(train,-1),region_name,day_num,final_testing_year)\n",
    "    original = np.where(mask['NCA-LDAS_mask'] == 1,original,0)\n",
    "\n",
    "    '''Add residuals to original datasets min max'''\n",
    "    train_out = predictions - original\n",
    "    train_out = np.where(original == 0, 0, train_out)\n",
    "    # predictions.shape\n",
    "    np.save(f'{train_val_dir}/Wk{lead}_training_{experiment_name_out}.npy',train_out)\n",
    "\n",
    "    #predict the validation data\n",
    "    predictions = model.predict(reforecast_validation_input)\n",
    "    \n",
    "    #Only grab the last channel\n",
    "    predictions = np.array(predictions)[-1,:,:,:,:]\n",
    "    \n",
    "    #Convert original forecasts back prior to min max\n",
    "    original = reverse_min_max_scaling(np.expand_dims(val,-1),region_name,day_num,final_testing_year)\n",
    "    original = np.where(mask['NCA-LDAS_mask'] == 1,original,0)\n",
    "\n",
    "    '''Add residuals to original datasets min max'''\n",
    "    val_out = predictions - original\n",
    "    val_out = np.where(original == 0, 0, val_out)\n",
    "    # predictions.shape\n",
    "    np.save(f'{train_val_dir}/Wk{lead}_validation_{experiment_name_out}.npy',val_out)\n",
    "       \n",
    "    return(f'Completed Experiment {experiment_name_out}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "03e1d8a6-4f31-445e-8ce8-3393ce515359",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#These are models which only include the reforecast predictions. We are not including any observations into them.\n",
    "\n",
    "EX0 ={'region_name':region_name, 'num_lags_obs_RZSM': 0, 'include_lags_obs_pwat_spfh_tmax': False, 'include_reforecast_or_not': True, 'addtl_experiment': False, 'experiment_test':0 }\n",
    "EX13={'region_name':region_name, 'num_lags_obs_RZSM': 0, 'include_lags_obs_pwat_spfh_tmax': False, 'include_reforecast_or_not': True, 'addtl_experiment': False, 'experiment_test':1 }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4c1a1677-e926-450e-b8f7-6d3f4c93f63b",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Include all predictors for obs but DO NOT include the current reforecast RZSM \n",
    "\n",
    "EX1 ={'region_name':region_name, 'num_lags_obs_RZSM': 3, 'include_lags_obs_pwat_spfh_tmax': True, 'include_reforecast_or_not': False, 'addtl_experiment': False, 'experiment_test':0 }\n",
    "EX2 ={'region_name':region_name, 'num_lags_obs_RZSM': 6, 'include_lags_obs_pwat_spfh_tmax': True, 'include_reforecast_or_not': False, 'addtl_experiment': False, 'experiment_test':0 }\n",
    "EX3 ={'region_name':region_name, 'num_lags_obs_RZSM': 9, 'include_lags_obs_pwat_spfh_tmax': True, 'include_reforecast_or_not': False, 'addtl_experiment': False, 'experiment_test':0 }\n",
    "EX4 ={'region_name':region_name, 'num_lags_obs_RZSM': 12, 'include_lags_obs_pwat_spfh_tmax': True, 'include_reforecast_or_not': False, 'addtl_experiment': False, 'experiment_test':0 }\n",
    "\n",
    "\n",
    "#Include all predictors for obs but DO include the current reforecast RZSM \n",
    "EX14 ={'region_name':region_name, 'num_lags_obs_RZSM': 3, 'include_lags_obs_pwat_spfh_tmax': True, 'include_reforecast_or_not': False, 'addtl_experiment': True, 'experiment_test':1 }\n",
    "EX15 ={'region_name':region_name, 'num_lags_obs_RZSM': 6, 'include_lags_obs_pwat_spfh_tmax': True, 'include_reforecast_or_not': False, 'addtl_experiment': True, 'experiment_test':2 }\n",
    "EX16 ={'region_name':region_name, 'num_lags_obs_RZSM': 9, 'include_lags_obs_pwat_spfh_tmax': True, 'include_reforecast_or_not': False, 'addtl_experiment': False, 'experiment_test':3 }\n",
    "EX17 ={'region_name':region_name, 'num_lags_obs_RZSM': 12, 'include_lags_obs_pwat_spfh_tmax': True, 'include_reforecast_or_not': False, 'addtl_experiment': False, 'experiment_test':4 }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "40665067-ac31-4ba4-afff-47017b4b33de",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Include only OBS RZSM predictors and the current reforecast RZSM week \n",
    "\n",
    "EX5 ={'region_name':region_name, 'num_lags_obs_RZSM': 3, 'include_lags_obs_pwat_spfh_tmax': False, 'include_reforecast_or_not': True, 'addtl_experiment': False, 'experiment_test':0 }\n",
    "EX6 ={'region_name':region_name, 'num_lags_obs_RZSM': 6, 'include_lags_obs_pwat_spfh_tmax': False, 'include_reforecast_or_not': True, 'addtl_experiment': False, 'experiment_test':0 }\n",
    "EX7 ={'region_name':region_name, 'num_lags_obs_RZSM': 9, 'include_lags_obs_pwat_spfh_tmax': False, 'include_reforecast_or_not': True, 'addtl_experiment': False, 'experiment_test':0 }\n",
    "EX8 ={'region_name':region_name, 'num_lags_obs_RZSM': 12, 'include_lags_obs_pwat_spfh_tmax': False, 'include_reforecast_or_not': True, 'addtl_experiment': False, 'experiment_test':0 }\n",
    "\n",
    "#Include only OBS RZSM predictors, previous weeks prediction, and current reforecast RZSM week \n",
    "EX18 ={'region_name':region_name, 'num_lags_obs_RZSM': 3, 'include_lags_obs_pwat_spfh_tmax': False, 'include_reforecast_or_not': True, 'addtl_experiment': True, 'experiment_test':1 }\n",
    "EX19 ={'region_name':region_name, 'num_lags_obs_RZSM': 6, 'include_lags_obs_pwat_spfh_tmax': False, 'include_reforecast_or_not': True, 'addtl_experiment': True, 'experiment_test':2 }\n",
    "EX20 ={'region_name':region_name, 'num_lags_obs_RZSM': 9, 'include_lags_obs_pwat_spfh_tmax': False, 'include_reforecast_or_not': True, 'addtl_experiment': True, 'experiment_test':3 }\n",
    "EX21 ={'region_name':region_name, 'num_lags_obs_RZSM': 12, 'include_lags_obs_pwat_spfh_tmax': False, 'include_reforecast_or_not': True, 'addtl_experiment': True, 'experiment_test':4 }\n",
    "\n",
    "#Include only OBS RZSM predictors DO NOT INCLUDE ANY REFORECAST OR PREDICTION\n",
    "EX22 ={'region_name':region_name, 'num_lags_obs_RZSM': 3, 'include_lags_obs_pwat_spfh_tmax': False, 'include_reforecast_or_not': True, 'addtl_experiment': True, 'experiment_test':5 }\n",
    "EX23 ={'region_name':region_name, 'num_lags_obs_RZSM': 6, 'include_lags_obs_pwat_spfh_tmax': False, 'include_reforecast_or_not': True, 'addtl_experiment': True, 'experiment_test':6 }\n",
    "EX24 ={'region_name':region_name, 'num_lags_obs_RZSM': 9, 'include_lags_obs_pwat_spfh_tmax': False, 'include_reforecast_or_not': True, 'addtl_experiment': True, 'experiment_test':7 }\n",
    "EX25 ={'region_name':region_name, 'num_lags_obs_RZSM': 12, 'include_lags_obs_pwat_spfh_tmax': False, 'include_reforecast_or_not': True, 'addtl_experiment': True, 'experiment_test':8 }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cc90eaef-f15d-49e6-8ae1-be3f15b7671b",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Include only OBS RZSM predictors, OBS other variables, previous predictions of RZSM, and current reforecast lead\n",
    "\n",
    "EX9 ={'region_name':region_name, 'num_lags_obs_RZSM': 3, 'include_lags_obs_pwat_spfh_tmax': True, 'include_reforecast_or_not': True, 'addtl_experiment': False, 'experiment_test':0 }\n",
    "EX10 ={'region_name':region_name, 'num_lags_obs_RZSM': 6, 'include_lags_obs_pwat_spfh_tmax': True, 'include_reforecast_or_not': True, 'addtl_experiment': False, 'experiment_test':0 }\n",
    "EX11 ={'region_name':region_name, 'num_lags_obs_RZSM': 9, 'include_lags_obs_pwat_spfh_tmax': True, 'include_reforecast_or_not': True, 'addtl_experiment': False, 'experiment_test':0 }\n",
    "EX12 ={'region_name':region_name, 'num_lags_obs_RZSM': 12, 'include_lags_obs_pwat_spfh_tmax': True, 'include_reforecast_or_not': True, 'addtl_experiment': False, 'experiment_test':0 }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d7676e44-292d-4d97-b09b-420e6d82cf4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# EX26 ={'region_name':region_name, 'num_lags_obs_RZSM': 3, 'include_lags_obs_pwat_spfh_tmax': True, 'include_reforecast_or_not': True, 'addtl_experiment': False, 'experiment_test':0 }\n",
    "\n",
    "# run_EXPERIMENT(num_lags_obs_RZSM=0,include_lags_obs_pwat_spfh_tmax=False,include_reforecast_or_not=True, addtl_experiment = False, experiment_test = 26)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a82df4c6-6153-4b5e-a9bd-882db0499056",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#This like EX9 and EX10 except now we are adding additional reforecast predictors from week 1 and 2\n",
    "\n",
    "EX27 ={'region_name':region_name, 'num_lags_obs_RZSM': 3, 'include_lags_obs_pwat_spfh_tmax': True, 'include_reforecast_or_not': True, 'addtl_experiment': False, 'experiment_test':1 }\n",
    "EX28 ={'region_name':region_name, 'num_lags_obs_RZSM': 6, 'include_lags_obs_pwat_spfh_tmax': True, 'include_reforecast_or_not': True, 'addtl_experiment': False, 'experiment_test':1 }\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ccd3e21-a645-4ce3-862c-d15711d3ca5f",
   "metadata": {},
   "source": [
    "# Permutation test only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3a00e185-77b0-4c1b-bee4-e907faf0d00b",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def setup_plot_permutation(lead,dictionary,metric):\n",
    "    test=pd.DataFrame(dictionary,index=[metric])\n",
    "    return(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c502857f-4068-4278-85e9-21184ae8a4f0",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def plot_barplot_mae_rmse(save_for_plot_mae, save_for_plot_rmse, lead, model_name):\n",
    "    save_permutation_figures = f'Outputs/permutation_tests/barplots/{region_name}/Wk{lead}'\n",
    "    os.system(f'mkdir -p {save_permutation_figures}')\n",
    "    \n",
    "    mae = setup_plot_permutation(lead,save_for_plot_mae,'MAE')\n",
    "    rmse = setup_plot_permutation(lead,save_for_plot_rmse,'RMSE')\n",
    "       \n",
    "    # Plotting\n",
    "    fig, axs = plt.subplots(2)\n",
    "    \n",
    "    # Plot for DataFrame 1\n",
    "    mae.plot(kind='bar', ax=axs[0])\n",
    "    axs[0].set_title('MAE')\n",
    "    \n",
    "    # Plot for DataFrame 2\n",
    "    rmse.plot(kind='bar', ax=axs[1])\n",
    "    axs[1].set_title('RMSE')\n",
    "    \n",
    "    # Adjust layout\n",
    "    # plt.tight_layout()\n",
    "    plt.savefig(f'{save_permutation_figures}/{model_name}.png')\n",
    "    plt.show()\n",
    "\n",
    "    return(0)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9deedd83-197b-46c1-b633-3edc6553e429",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def create_plot_permutation(lead,max_RZSM_value,region_name):\n",
    "    save_permutation_figures = f'Outputs/permutation_tests/{region_name}/plots/Wk{lead}'\n",
    "    os.system(f'mkdir -p {save_permutation_figures}')\n",
    "\n",
    "    \n",
    "    # del plot_['Lead']\n",
    "    plot_ = plot_.T #Must transpose to make it plot properly\n",
    "\n",
    "    fig = plt.figure(figsize=(8,6))\n",
    "\n",
    "    ax = fig.add_subplot(111) # Create matplotlib axes\n",
    "\n",
    "    plot_.RZSM.plot(kind='bar', color='red',width=0.3, ax=ax, position=1)\n",
    "\n",
    "    ax.set_ylabel('RZSM anomaly MAE')\n",
    "    ax.set_ylim(0, max_RZSM_value)\n",
    "\n",
    "    # plot_.plot(kind='bar')\n",
    "    # plt.ylabel(f'{error_}')\n",
    "    plt.suptitle(f'Permutation Test\\nObservation values are in legend\\nWk{lead} {experiment_name_out}',fontsize=10)\n",
    "    \n",
    "    legend1 = ax.legend(loc='upper right', bbox_to_anchor=(1.0, 1))\n",
    "\n",
    "    ax.set_xlabel('\\nPermutated Channels',weight='bold')\n",
    "    plt.tight_layout()\n",
    "\n",
    "    plt.savefig(f'{save_permutation_figures}/{experiment_name_out}.png')\n",
    "    #plt.savefig(f'{save_permutation_figures}/{experiment_name}.tiff', format='tiff', dpi=300)\n",
    "    #tiff.imsave(f'{save_permutation_figures}/{experiment_name}.tiff', data_array)\n",
    "    plt.show()\n",
    "\n",
    "    return(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5fbc67dc-14fb-4ff9-bd67-299585c469ea",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def return_data_and_experiment_numbers(region_name, leads,train_start, train_end, val_start, val_end, test_start, test_end,day_num):\n",
    "        \n",
    "    obs_final_train,obs_final_validation,obs_final_testing = verifications.open_obs_for_verification(region_name, leads,train_start, train_end, val_start, val_end, test_start, test_end)\n",
    "\n",
    "    obs_final_testing = obs_final_testing.sel(L=day_num)\n",
    "    '''Now that we have the observations, we need to loop through each of the testing files and permutate them'''\n",
    "    \n",
    "    save_permutation_figures = f'Outputs/permutation_data{region_name}'\n",
    "    os.system(f'mkdir -p {save_permutation_figures}')\n",
    "\n",
    "    #Get the files from the correct location (we need to loop through each of the models.\n",
    "    # exps = sorted(glob(f'checkpoints/{region_name}/Wk{lead}/*'))\n",
    "    exps = sorted(glob(f'Data/model_npy_inputs/{region_name}/Wk{lead}_EX_input_data/*testing*'))\n",
    "\n",
    "    exps = [i for i in exps if 'RZSM' in i]\n",
    "    exps = [i for i in exps if 'XGBOOST' not in i]\n",
    "\n",
    "    #Make a list of the experiment names. We only need to grab a single file since they all have the same data\n",
    "    '''We are going to seperate by hybrid and obs.driven. So remove EX0 and EX13'''\n",
    "    EX_list = [f'EX{i}' for i in range(26)]\n",
    "    EX_list = EX_list+['EX27']+['EX28']\n",
    "    EX_list = [i for i in EX_list if 'EX0' not in i ]\n",
    "    EX_list = [i for i in EX_list if 'EX13' not in i ]\n",
    "    # EX_list = [i for i in EX_list if 'EX10' not in i ]\n",
    "\n",
    "    return(obs_final_train,obs_final_validation,obs_final_testing,EX_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "17f2063f-795a-42d6-a56b-578e1b0e6029",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def return_the_experiment_input(exps,file,lead):\n",
    "    '''First find the experiment name within the file'''\n",
    "    ex_num = file.split(f'Wk{lead}_')[-1].split('_')[0]\n",
    "\n",
    "    '''Now loop through exps to grab the correct input'''\n",
    "    correct_file = [i for i in exps if ex_num in i]\n",
    "    correct_file = [i for i in correct_file if 'XGBOOST' not in i]\n",
    "\n",
    "    return(np.load(correct_file[0]),ex_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cb6e33bc-03df-45a5-8c5f-27e7c9c0ea03",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def permutation_test_by_lead(lead, test_year):\n",
    "    #test \n",
    "    # lead = 1\n",
    "    # test_year=2019\n",
    "\n",
    "    day_num = (lead*7) -1\n",
    "    \n",
    "    file_path = f'Outputs/permutation_tests/mae_rmse_results'\n",
    "    file_rmse_save = f'{file_path}/Wk{lead}_rmse_vals.pkl'\n",
    "    file_mae_save = f'{file_path}/Wk{lead}_mae_vals.pkl'\n",
    "    complete_rmse = f'{file_path}/Wk{lead}_rmse_complete.pkl'\n",
    "    complete_mae = f'{file_path}/Wk{lead}_mae_complete.pkl'\n",
    "    \n",
    "    os.system(f'mkdir -p {file_path}')\n",
    "\n",
    "    rmse_output, mae_output, rmse_complete, mae_complete = putils.return_rmse_and_mae_pickle_files(file_rmse_save, file_mae_save, complete_mae, complete_rmse)\n",
    "\n",
    "    ###########################################################################\n",
    "\n",
    "    leads = [6,13,20,27,34]\n",
    "\n",
    "    obs_final_train,obs_final_validation,obs_final_testing,EX_list = return_data_and_experiment_numbers(region_name, leads,train_start, train_end, val_start, val_end, test_start, test_end,day_num)\n",
    "\n",
    "    obs_final_testing_arr = obs_final_testing[putils.xarray_varname(obs_final_testing)].to_numpy()\n",
    "    '''These are the actual experiment names below'''\n",
    "    BC,OBS,HYB = verifications.return_experiment_colors_and_names()\n",
    "\n",
    "    '''Loop through each model checkpoint'''\n",
    "    checkpt_dir = f'checkpoints/{region_name}/Wk{lead}'\n",
    "    file_list = sorted(glob(f'{checkpt_dir}/*regular*'))\n",
    "    file_list = [i for i in file_list if '.' not in i] \n",
    "    file_list = [i for i in file_list if '/checkpoint' not in i]\n",
    "    file_list = [i for i in file_list if 'ECMWF' not in i] #don't do ECMWF. We haven't coded it with different varabiles yet\n",
    "    file_list = [i for i in file_list if BC[0] not in i]\n",
    "    file_list = [i for i in file_list if BC[1] not in i]\n",
    "    # file_list = [i for i in file_list if 'EX10' not in i ]\n",
    "    # file_list = [i for i in file_list if 'EX14' not in i ]\n",
    "    # file_list = [i for i in file_list if 'EX11' not in i ]\n",
    "    # file_list = [i for i in file_list if 'EX12' not in i ]\n",
    "    # file_list = [i for i in file_list if 'EX15' not in i ]\n",
    "    file_list = [i for i in file_list if 'EX16' not in i ]\n",
    "    # file_list = [i for i in file_list if 'EX17' not in i ]\n",
    "    # file_list = [i for i in file_list if 'EX18' not in i ]\n",
    "    if lead ==4:\n",
    "        file_list = [i for i in file_list if 'EX12' not in i ]\n",
    "        file_list = [i for i in file_list if 'EX21' not in i ]\n",
    "        file_list = [i for i in file_list if 'EX28' not in i ]\n",
    "\n",
    "    ##########################################################################\n",
    "    if test_year == 2019:\n",
    "        file_list = [i for i in file_list if '2012' not in i]\n",
    "    else:\n",
    "        file_list = [i for i in file_list if str(pd.to_datetime(test_end).year) in i]\n",
    "\n",
    "    '''Experiment saved inputs'''\n",
    "    exps = sorted(glob(f'Data/model_npy_inputs/{region_name}/Wk{lead}_EX_input_data/*testing*'))\n",
    "    exps = [i for i in exps if 'XGBOOST' not in i]\n",
    "    exps = [i for i in exps if 'mean' not in i]\n",
    "\n",
    "    print(f'Working on file list {file_list}')\n",
    "\n",
    "    #For masking\n",
    "    RZSM_train_obs, RZSM_validation_obs = pred.return_masking_objects_for_RZSM(input_directory,final_testing_year)\n",
    "    mask_zero = RZSM_validation_obs.squeeze()\n",
    "    \n",
    "    for file in file_list:\n",
    "        print(f'Working on file experiment {file}')\n",
    "        # break\n",
    "        try:\n",
    "            testing_input,ex_num = return_the_experiment_input(exps,file,lead)\n",
    "            channel_list = f.load_channel_list_permutation(ex_num, lead)\n",
    "            dont_continue=False\n",
    "            \n",
    "        except IndexError:\n",
    "            dont_continue = True\n",
    "\n",
    "        if dont_continue:\n",
    "            pass\n",
    "        else:\n",
    "            if (len(channel_list) == testing_input.shape[-1]):\n",
    "                model = load_model(file,compile=False) \n",
    "                model_name = file.split('/')[-1].split('_testing')[0]\n",
    "                \n",
    "                #These will contain the average MAE and RMSE across CONUS to plot\n",
    "                save_for_plot_mae = {}\n",
    "                save_for_plot_rmse = {}\n",
    "\n",
    "                continue_ = False\n",
    "                \n",
    "                for idx,channel in enumerate(channel_list):\n",
    "                    # break\n",
    "                    '''Check if we have already completed it'''\n",
    "                    unit_test = putils.check_if_already_completed_permuatation(rmse_complete, mae_complete, ex_num,  OBS, HYB, channel, model_name)\n",
    "\n",
    "                    if unit_test == 'Not-Completed':\n",
    "                        # break\n",
    "                        print(f'\\nPermutating channel {channel}\\n')\n",
    "    \n",
    "                        new_input_with_noise,reforecast_nan,var_noise_min,var_noise_max,var_ = f.load_min_max_files_and_rescale_data(testing_input,channel,idx,file,region_name,day_num,test_year,lead)\n",
    "    \n",
    "                        try:\n",
    "                            prediction_ = np.array(model.predict(new_input_with_noise))\n",
    "                            prediction_.shape\n",
    "                            \n",
    "                            '''Just choose the very last prediction made'''\n",
    "                            prediction_ = prediction_[-1,:,:,:,0]\n",
    "        \n",
    "                            yhat = verifications.reverse_min_max_scaling_for_permutations(prediction_,region_name,day_num,'GEFSv12',test_year,'soilw_bgrnd')\n",
    "            \n",
    "                            yhat = np.where(np.isnan(reforecast_nan),np.nan,yhat)\n",
    "                            yhat = np.where(mask_zero == 0, np.nan, yhat)\n",
    "                            # yhat = np.where(np.isnan(reforecast_nan),np.nan,yhat.squeeze())\n",
    "                            yhat = np.reshape(yhat,(yhat.shape[0]//11,11,yhat.shape[1],yhat.shape[2]))\n",
    "                \n",
    "                            RZSM_mae =np.nanmean(np.abs(obs_final_testing_arr -  yhat),axis=(0,1))\n",
    "                \n",
    "                            RZSM_rmse = np.nanmean((obs_final_testing_arr -  yhat)**2,axis=(0,1))\n",
    "    \n",
    "                            save_for_plot_rmse[channel] = np.nanmean(RZSM_rmse)\n",
    "                            save_for_plot_mae[channel] = np.nanmean(RZSM_mae)\n",
    "                        \n",
    "                            '''Now add to the dictionary for RMSE'''\n",
    "                            if ex_num in OBS:\n",
    "                                try:\n",
    "                                    # if output['OBS'][channel]['Value']\n",
    "                                    rmse_output['OBS'][channel]['Value'] = rmse_output['OBS'][channel]['Value'] + RZSM_rmse\n",
    "                                    rmse_output['OBS'][channel]['Num_experiments'] = rmse_output['OBS'][channel]['Num_experiments'] + 1\n",
    "                                    rmse_complete['OBS'][model_name].append(channel)\n",
    "                                except KeyError:\n",
    "                                    rmse_output['OBS'][channel] = {'Num_experiments':1, 'Value':RZSM_rmse}\n",
    "                                    rmse_complete = putils.append_to_complete_list(rmse_complete, model_name, channel, 'OBS')\n",
    "                                    \n",
    "                            elif ex_num in HYB:\n",
    "                                try:\n",
    "                                    rmse_output['HYB'][channel]['Value'] = rmse_output['HYB'][channel]['Value'] + RZSM_rmse\n",
    "                                    rmse_output['HYB'][channel]['Num_experiments'] = rmse_output['HYB'][channel]['Num_experiments'] + 1\n",
    "                                    rmse_complete['HYB'][model_name].append(channel)\n",
    "                                except KeyError:\n",
    "                                    rmse_output['HYB'][channel] = {'Num_experiments':1, 'Value':RZSM_rmse}\n",
    "                                    rmse_complete = putils.append_to_complete_list(rmse_complete, model_name, channel, 'HYB')\n",
    "\n",
    "                                    \n",
    "                            '''Now add to the dictionary for MAE only'''\n",
    "                            if ex_num in OBS:\n",
    "                                try:\n",
    "                                    mae_output['OBS'][channel]['Value'] = mae_output['OBS'][channel]['Value'] + RZSM_mae\n",
    "                                    mae_output['OBS'][channel]['Num_experiments'] = mae_output['OBS'][channel]['Num_experiments'] + 1\n",
    "                                    mae_complete['OBS'][model_name].append(channel)\n",
    "                                except KeyError:\n",
    "                                    mae_output['OBS'][channel] = {'Num_experiments':1, 'Value':RZSM_mae}\n",
    "                                    mae_complete = putils.append_to_complete_list(mae_complete, model_name, channel, 'OBS')\n",
    "\n",
    "                            elif ex_num in HYB:\n",
    "                                try:\n",
    "                                    mae_output['HYB'][channel]['Value'] = mae_output['HYB'][channel]['Value'] + RZSM_mae\n",
    "                                    mae_output['HYB'][channel]['Num_experiments'] = mae_output['HYB'][channel]['Num_experiments'] + 1\n",
    "                                    mae_complete['HYB'][model_name].append(channel)\n",
    "                                except KeyError:\n",
    "                                    mae_output['HYB'][channel] = {'Num_experiments':1, 'Value':RZSM_mae}\n",
    "                                    mae_complete = putils.append_to_complete_list(mae_complete, model_name, channel, 'HYB')\n",
    "\n",
    "    \n",
    "                            continue_ = True\n",
    "                        \n",
    "                        except ValueError:\n",
    "                            continue_ = False\n",
    "                            pass\n",
    "                        \n",
    "                if continue_:\n",
    "                    plot_barplot_mae_rmse(save_for_plot_mae, save_for_plot_rmse, lead, model_name)\n",
    "                    \n",
    "            \n",
    "        '''Saves after each file is completed'''\n",
    "        with open(file_rmse_save, 'wb') as file:\n",
    "            pickle.dump(rmse_output, file)\n",
    "    \n",
    "        with open(file_mae_save, 'wb') as file:\n",
    "            pickle.dump(mae_output, file)\n",
    "        \n",
    "        with open(complete_rmse, 'wb') as file:\n",
    "            pickle.dump(rmse_complete, file)\n",
    "    \n",
    "        with open(complete_mae, 'wb') as file:\n",
    "            pickle.dump(mae_complete, file)\n",
    "\n",
    "    return(f'Completed week {lead}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7fea826c-e4a5-4ae5-b3d7-0494913df970",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# def permutation_test_by_lead_by_experiment(lead, test_year, experiment_number):\n",
    "#     #test \n",
    "#     # lead = 1\n",
    "#     # test_year=2019\n",
    "    \n",
    "#     day_num = (lead*7) -1\n",
    "\n",
    "#     try:\n",
    "#         with open(file_rmse_save, \"rb\") as f:\n",
    "#             rmse_output = pickle.load(f)\n",
    "    \n",
    "#         with open(file_mae_save, \"rb\") as f:\n",
    "#             mae_output = pickle.load(f)    \n",
    "#     except FileNotFoundError:\n",
    "#         rmse_output = {}\n",
    "#         rmse_output['OBS'] = {}\n",
    "#         rmse_output['HYB'] = {}\n",
    "    \n",
    "#         mae_output = {}\n",
    "#         mae_output['OBS'] = {}\n",
    "#         mae_output['HYB'] = {}\n",
    "\n",
    "    \n",
    "#     leads = [6,13,20,27,34]\n",
    "\n",
    "#     obs_final_train,obs_final_validation,obs_final_testing,EX_list = return_data_and_experiment_numbers(region_name, leads,train_start, train_end, val_start, val_end, test_start, test_end,day_num)\n",
    "\n",
    "#     obs_final_testing_arr = obs_final_testing[putils.xarray_varname(obs_final_testing)].to_numpy()\n",
    "#     '''These are the actual experiment names below'''\n",
    "#     BC,OBS,HYB = verifications.return_experiment_colors_and_names()\n",
    "\n",
    "\n",
    "#     '''Loop through each model checkpoint'''\n",
    "#     checkpt_dir = f'checkpoints/{region_name}/Wk{lead}'\n",
    "#     file_list = sorted(glob(f'{checkpt_dir}/*{experiment_number}_regular*'))\n",
    "  \n",
    "    \n",
    "#     if test_year == 2019:\n",
    "#         file_list = [i for i in file_list if '2012' not in i]\n",
    "#     else:\n",
    "#         file_list = [i for i in file_list if str(pd.to_datetime(test_end).year) in i]\n",
    "\n",
    "#     '''Experiment saved inputs'''\n",
    "#     exps = sorted(glob(f'Data/model_npy_inputs/{region_name}/Wk{lead}_EX_input_data/*testing*'))\n",
    "#     exps = [i for i in exps if 'XGBOOST' not in i]\n",
    "#     exps = [i for i in exps if 'mean' not in i]\n",
    "\n",
    "#     print(f'Working on file list {file_list}')\n",
    "\n",
    "#     #For masking\n",
    "#     RZSM_train_obs, RZSM_validation_obs = pred.return_masking_objects_for_RZSM(input_directory,final_testing_year)\n",
    "#     mask_zero = RZSM_validation_obs.squeeze()\n",
    "    \n",
    "#     for file in file_list:\n",
    "#         print(f'Working on file experiment {file}')\n",
    "#         try:\n",
    "#             testing_input,ex_num = return_the_experiment_input(exps,file,lead)\n",
    "#             channel_list = f.load_channel_list_permutation(ex_num, lead)\n",
    "#             dont_continue=False\n",
    "            \n",
    "#         except IndexError:\n",
    "#             dont_continue = True\n",
    "\n",
    "#         if dont_continue:\n",
    "#             pass\n",
    "#         else:\n",
    "#             if len(channel_list) == testing_input.shape[-1]:\n",
    "#                 model = load_model(file,compile=False) \n",
    "#                 model_name = file.split('/')[-1].split('_testing')[0]\n",
    "                \n",
    "#                 #These will contain the average MAE and RMSE across CONUS to plot\n",
    "#                 save_for_plot_mae = {}\n",
    "#                 save_for_plot_rmse = {}\n",
    "                \n",
    "#                 for idx,channel in enumerate(channel_list):\n",
    "#                     '''Now add to the dictionary'''\n",
    "#                     if ex_num in OBS:\n",
    "#                         try:\n",
    "#                             rmse_output['OBS'][channel]['Value'] = rmse_output['OBS'][channel]['Value'] + RZSM_rmse\n",
    "#                             rmse_output['OBS'][channel]['Num_experiments'] = rmse_output['OBS'][channel]['Num_experiments'] + 1\n",
    "#                         except KeyError:\n",
    "#                             rmse_output['OBS'][channel] = {'Num_experiments':1, 'Value':RZSM_rmse}\n",
    "#                     elif ex_num in HYB:\n",
    "                        \n",
    "                \n",
    "#                     # idx,channel = 6, 'pwat_obs_lag-1'\n",
    "#                     # idx, channel = 0, 'RZSM_obs_lag-1'\n",
    "                    \n",
    "#                     new_input_with_noise,reforecast_nan,var_noise_min,var_noise_max,var_ = f.load_min_max_files_and_rescale_data(testing_input,channel,idx,file,region_name,day_num,test_year,lead)\n",
    "\n",
    "#                     try:\n",
    "#                         prediction_ = np.array(model.predict(new_input_with_noise))\n",
    "#                         prediction_.shape\n",
    "                        \n",
    "#                         '''Just choose the very last prediction made'''\n",
    "#                         prediction_ = prediction_[-1,:,:,:,0]\n",
    "        \n",
    "#                         yhat = verifications.reverse_min_max_scaling_for_permutations(prediction_,region_name,day_num,'GEFSv12',test_year,'soilw_bgrnd')\n",
    "        \n",
    "#                         yhat = np.where(np.isnan(reforecast_nan),np.nan,yhat)\n",
    "#                         yhat = np.where(mask_zero == 0, np.nan, yhat)\n",
    "#                         # yhat = np.where(np.isnan(reforecast_nan),np.nan,yhat.squeeze())\n",
    "#                         yhat = np.reshape(yhat,(yhat.shape[0]//11,11,yhat.shape[1],yhat.shape[2]))\n",
    "            \n",
    "#                         RZSM_mae =np.nanmean(np.abs(obs_final_testing_arr -  yhat),axis=(0,1))\n",
    "            \n",
    "#                         RZSM_rmse = np.nanmean((obs_final_testing_arr -  yhat)**2,axis=(0,1))\n",
    "    \n",
    "#                         save_for_plot_rmse[channel] = np.nanmean(RZSM_rmse)\n",
    "#                         save_for_plot_mae[channel] = np.nanmean(RZSM_mae)\n",
    "                        \n",
    "#                         '''Now add to the dictionary'''\n",
    "#                         if ex_num in OBS:\n",
    "#                             try:\n",
    "#                                 rmse_output['OBS'][channel]['Value'] = rmse_output['OBS'][channel]['Value'] + RZSM_rmse\n",
    "#                                 rmse_output['OBS'][channel]['Num_experiments'] = rmse_output['OBS'][channel]['Num_experiments'] + 1\n",
    "#                             except KeyError:\n",
    "#                                 rmse_output['OBS'][channel] = {'Num_experiments':1, 'Value':RZSM_rmse}\n",
    "#                         elif ex_num in HYB:\n",
    "#                             try:\n",
    "#                                 rmse_output['HYB'][channel]['Value'] = rmse_output['HYB'][channel]['Value'] + RZSM_rmse\n",
    "#                                 rmse_output['HYB'][channel]['Num_experiments'] = rmse_output['HYB'][channel]['Num_experiments'] + 1\n",
    "#                             except KeyError:\n",
    "#                                 rmse_output['HYB'][channel] = {'Num_experiments':1, 'Value':RZSM_rmse}\n",
    "    \n",
    "    \n",
    "#                         '''Now add to the dictionary'''\n",
    "#                         if ex_num in HYB:\n",
    "#                             try:\n",
    "#                                 mae_output['OBS'][channel]['Value'] = mae_output['OBS'][channel]['Value'] + RZSM_mae\n",
    "#                                 mae_output['OBS'][channel]['Num_experiments'] = mae_output['OBS'][channel]['Num_experiments'] + 1\n",
    "#                             except KeyError:\n",
    "#                                 mae_output['OBS'][channel] = {'Num_experiments':1, 'Value':RZSM_mae}\n",
    "#                         elif ex_num in HYB:\n",
    "#                             try:\n",
    "#                                 mae_output['HYB'][channel]['Value'] = mae_output['HYB'][channel]['Value'] + RZSM_mae\n",
    "#                                 mae_output['HYB'][channel]['Num_experiments'] = mae_output['HYB'][channel]['Num_experiments'] + 1\n",
    "#                             except KeyError:\n",
    "#                                 mae_output['HYB'][channel] = {'Num_experiments':1, 'Value':RZSM_mae}\n",
    "\n",
    "#                         continue_ = True\n",
    "                    \n",
    "            \n",
    "                    \n",
    "#                     except ValueError:\n",
    "#                         continue_ = False\n",
    "#                         pass\n",
    "                        \n",
    "#                 if continue_:\n",
    "#                     plot_barplot_mae_rmse(save_for_plot_mae, save_for_plot_rmse, lead, model_name)\n",
    "                    \n",
    "\n",
    "#     return(f'Completed week {lead}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5b03ba3d-c7da-44b0-88b6-2640278ec02c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def run_model_and_prediction(experiment):\n",
    "    global lead_week\n",
    "    for lead_week in [1]:\n",
    "        global lead\n",
    "        lead=lead_week\n",
    "        day_lead = (lead*7)-1\n",
    "    \n",
    "        generate_model_inputs(region_name=experiment['region_name'], lead = lead_week, num_lags_obs_RZSM=experiment['num_lags_obs_RZSM'],\n",
    "                              include_lags_obs_pwat_spfh_tmax=experiment['include_lags_obs_pwat_spfh_tmax'],include_reforecast_or_not=experiment['include_reforecast_or_not'], \n",
    "                              addtl_experiment = experiment['addtl_experiment'], experiment_test = experiment['experiment_test'])\n",
    "    \n",
    "        run_EXPERIMENT(region_name=experiment['region_name'], lead = lead_week, num_lags_obs_RZSM=experiment['num_lags_obs_RZSM'],\n",
    "                              include_lags_obs_pwat_spfh_tmax=experiment['include_lags_obs_pwat_spfh_tmax'],include_reforecast_or_not=experiment['include_reforecast_or_not'], \n",
    "                              addtl_experiment = experiment['addtl_experiment'], experiment_test = experiment['experiment_test'])\n",
    "\n",
    "        def open_min_max_GEFS(train_start, train_end, val_start, val_end, test_start, test_end,day_lead):\n",
    "            print('Loading GEFSv12 min max files')\n",
    "            file = xr.open_mfdataset('Data/GEFSv12_reforecast/soilw_bgrnd/min_max_RZSM/*')\n",
    "            train = file.sel(S=slice(train_start,train_end)).sel(L=day_lead).stack(combine_models=['S','M']).transpose('combine_models','Y','X').to_array().squeeze().values\n",
    "            val = file.sel(S=slice(val_start,val_end)).sel(L=day_lead).stack(combine_models=['S','M']).transpose('combine_models','Y','X').to_array().squeeze().values\n",
    "            test = file.sel(S=slice(test_start,test_end)).sel(L=day_lead).stack(combine_models=['S','M']).transpose('combine_models','Y','X').to_array().squeeze().values\n",
    "            return(train,test,val)\n",
    "\n",
    "        train,test,val = open_min_max_GEFS(train_start, train_end, val_start, val_end, test_start, test_end,day_lead)\n",
    "            \n",
    "    \n",
    "        make_single_predictions_training_validation(region_name=experiment['region_name'], lead = lead_week, num_lags_obs_RZSM=experiment['num_lags_obs_RZSM'],\n",
    "                              include_lags_obs_pwat_spfh_tmax=experiment['include_lags_obs_pwat_spfh_tmax'],include_reforecast_or_not=experiment['include_reforecast_or_not'], \n",
    "                              addtl_experiment = experiment['addtl_experiment'], experiment_test = experiment['experiment_test'], train=train, val = val)\n",
    "\n",
    "        make_single_predictions_testing(region_name=experiment['region_name'], lead = lead_week, num_lags_obs_RZSM=experiment['num_lags_obs_RZSM'],\n",
    "                              include_lags_obs_pwat_spfh_tmax=experiment['include_lags_obs_pwat_spfh_tmax'],include_reforecast_or_not=experiment['include_reforecast_or_not'], \n",
    "                              addtl_experiment = experiment['addtl_experiment'], experiment_test = experiment['experiment_test'], test = test)\n",
    "        \n",
    "    print(f'Completed {experiment}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3478ef11-68a7-4bf3-9120-4268c2e6d85f",
   "metadata": {},
   "outputs": [],
   "source": [
    "EX9 ={'region_name':region_name, 'num_lags_obs_RZSM': 3, 'include_lags_obs_pwat_spfh_tmax': True, 'include_reforecast_or_not': True, 'addtl_experiment': False, 'experiment_test':0 }\n",
    "experiment=EX9\n",
    "#for testing\n",
    "lead,lead_week =1,1\n",
    "\n",
    "experiment['region_name']\n",
    "lead = lead_week\n",
    "num_lags_obs_RZSM=experiment['num_lags_obs_RZSM']\n",
    "include_lags_obs_pwat_spfh_tmax=experiment['include_lags_obs_pwat_spfh_tmax']\n",
    "include_reforecast_or_not=experiment['include_reforecast_or_not']\n",
    "addtl_experiment = experiment['addtl_experiment']\n",
    "experiment_test = experiment['experiment_test']\n",
    "\n",
    "epochs = 150\n",
    "batch_size = 66\n",
    "initial_learning_rate=0.0001\n",
    "beta_1 = 0.9\n",
    "shuffle=False\n",
    "patience=10\n",
    "kernel_norm = None\n",
    "deep_supervision = True\n",
    "number_of_UNET_backbone_max_pool=4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0b57dc8b-f694-441a-80bd-edd4772afeb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Now loading Verification Data from Observations.\n",
      "\n",
      "Loading previously created data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "run_model_and_prediction(experiment)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "tt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "110a899c-af06-4aab-af94-3015304a2f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "run_model_and_prediction(experiment)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "490e59a0-196a-4d88-a0ce-5e011b656d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_exps= [EX0,EX1,EX2,EX3,EX4,EX5,EX6,EX7,EX8,EX9,EX10,EX11,EX13,EX14,EX15,EX16,EX17,EX18,EX19,EX20,EX21,EX22,EX23,EX24,EX25,EX27,EX28]\n",
    "\n",
    "'''We are not testing EX12 or EX26'''\n",
    "for idx,experiment in enumerate(all_exps):\n",
    "    run_model_and_prediction(experiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa6dcbd7-01be-4793-98cc-0800a1e7270b",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "'''Run the single prediction tests'''\n",
    "        \n",
    "%load_ext autoreload \n",
    "%autoreload 2\n",
    "%reload_ext autoreload\n",
    "    \n",
    "testing_scenarios = ['dense', 'regular', 'transformer', 'super_pixel', 'attention', 'denseLarge', 'basic']\n",
    "\n",
    "for testing_scenario in testing_scenarios:\n",
    "    #removed EX12 and EX26\n",
    "    all_exps= [EX0,EX1,EX2,EX3,EX4,EX5,EX6,EX7,EX8,EX9,EX10,EX11,EX13,EX14,EX15,EX16,EX17,EX18,EX19,EX20,EX21,EX22,EX23,EX24,EX25,EX27,EX28]\n",
    "\n",
    "    \n",
    "    global save_loss_name, loss_fn\n",
    "    \n",
    "    if testing_scenario == 'dense':\n",
    "        import modelRzsmDenseRelu as UNETRzsm\n",
    "        \n",
    "        save_loss_name = 'denseLoss'\n",
    "        loss_fn = losses.crps2d_tf_dense_test2\n",
    "        \n",
    "    elif testing_scenario == 'regular':\n",
    "        import modelRzsmReluExtraConv as UNETRzsm\n",
    "    \n",
    "        save_loss_name = 'regular'\n",
    "        loss_fn = losses.crps2d_tf\n",
    "    \n",
    "    elif testing_scenario == 'transformer':\n",
    "        import modelRzsmReluTransformer as UNETRzsm\n",
    "        \n",
    "        save_loss_name = 'transformer'\n",
    "        loss_fn = losses.crps2d_tf_dense_test2\n",
    "    \n",
    "    elif testing_scenario == 'super_pixel':\n",
    "        import modelRzsmReluPixelSuper as UNETRzsm\n",
    "        \n",
    "        save_loss_name = 'supPixel'\n",
    "        loss_fn = losses.crps2d_tf_dense_test2\n",
    "    \n",
    "    elif testing_scenario == 'attention':\n",
    "        import modelRzsmReluAttention as UNETRzsm\n",
    "        \n",
    "        save_loss_name = 'attention'\n",
    "        loss_fn = losses.crps2d_tf_dense_test2\n",
    "        \n",
    "    elif testing_scenario == 'None':\n",
    "        import modelRzsm2DdropoutRelu as UNETRzsm\n",
    "        \n",
    "        save_loss_name = ''\n",
    "        loss_fn = losses.crps2d_tf\n",
    "    \n",
    "    elif testing_scenario == 'denseLarge':\n",
    "        import modelRzsmReluExtraConv as UNETRzsm\n",
    "    \n",
    "        save_loss_name = 'denseLarge'\n",
    "        loss_fn = losses.crps2d_tf_dense_test2\n",
    "        \n",
    "    elif testing_scenario == 'basic':\n",
    "        import basicUNET as UNETRzsm\n",
    "    \n",
    "        save_loss_name = testing_scenario\n",
    "        loss_fn = losses.crps2d_tf\n",
    "\n",
    "    for idx,experiment in enumerate(all_exps):\n",
    "        run_model_and_prediction(experiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2768ac13-e1ff-4ab5-95d6-08081f4bac2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_exps= [EX0,EX1,EX2,EX3,EX4,EX5,EX6,EX7,EX8,EX9,EX10,EX11,EX12,EX13,EX14,EX15,EX16,EX17,EX18,EX19,EX20,EX21,EX22,EX23,EX24,EX25,EX27,EX28]\n",
    "for idx,experiment in enumerate(all_exps):\n",
    "    run_model_and_prediction(experiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c83bd3e-d864-4824-931b-bd029194d083",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx,experiment in enumerate(all_exps):\n",
    "    run_model_and_prediction(experiment)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53d20619-f47f-4545-a680-f7e1b68cec51",
   "metadata": {},
   "source": [
    "# After all the experiments are completed, now do a permutation test\n",
    "## Save the results for each type (observation or hybrid driven) only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "694c9281-da90-4cc5-8f23-8f650ab0675e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for lead in [1,2]:\n",
    "    permutation_test_by_lead(lead=lead, test_year=2019)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65f08ca1-b5df-4fb5-9cfd-a27dac6da755",
   "metadata": {},
   "outputs": [],
   "source": [
    "for lead in [1]:\n",
    "    permutation_test_by_lead_by_experiment(lead=lead, test_year=2019, experiment_number = 'EX1')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tf212gpu_new]",
   "language": "python",
   "name": "conda-env-tf212gpu_new-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
